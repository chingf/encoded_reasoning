{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9067a870",
   "metadata": {},
   "outputs": [],
   "source": [
    "from config import hf_cache_dir\n",
    "import transformers\n",
    "import torch\n",
    "import os\n",
    "from transformers import pipeline, AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
    "from jinja2 import Template\n",
    "import pandas as pd\n",
    "from utils_activations import rot13_alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0beff1e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = '/workspace/data/axolotl-outputs/llama_deepseek_2epochs/merged'\n",
    "prompt_path = './prompts/three_hop_prompts.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2687cdc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd45589da96d4741b669233771e5e6ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#quantization_config = BitsAndBytesConfig(\n",
    "#    load_in_4bit=True,\n",
    "#    bnb_4bit_compute_dtype=torch.bfloat16,\n",
    "#    bnb_4bit_use_double_quant=True,\n",
    "#    bnb_4bit_quant_type=\"nf4\"\n",
    "#)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_path,\n",
    "    torch_dtype=torch.bfloat16,  # Use float16 for memory efficiency; also could be float16\n",
    "    device_map=\"auto\",          # Automatically distribute across available GPUs\n",
    "    trust_remote_code=True,\n",
    "    low_cpu_mem_usage=True, \n",
    "    #quantization_config=quantization_config,\n",
    "    #load_in_4bit=True\n",
    "    )\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "template_path = \"chat_templates/deepseek_distill_llama_template.jinja\"\n",
    "with open(template_path, \"r\") as file:\n",
    "    jinja_template = file.read()\n",
    "tokenizer.chat_template = jinja_template "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72d49b41",
   "metadata": {},
   "source": [
    "# Test prompts from CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bc5fac08",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_df = pd.read_csv(prompt_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6d590dea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Prompt</th>\n",
       "      <th>Answer</th>\n",
       "      <th>State</th>\n",
       "      <th>Person</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What is the capital of the state that the secr...</td>\n",
       "      <td>Springfield</td>\n",
       "      <td>Illinois</td>\n",
       "      <td>Hillary Clinton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What is the capital of the state that the firs...</td>\n",
       "      <td>Albany</td>\n",
       "      <td>New York</td>\n",
       "      <td>Alexander Hamilton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What is the capital of the state that the U.S....</td>\n",
       "      <td>Boston</td>\n",
       "      <td>Massachusetts</td>\n",
       "      <td>John F. Kennedy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What is the capital of the state that the U.S....</td>\n",
       "      <td>Albany</td>\n",
       "      <td>New York</td>\n",
       "      <td>Theodore Roosevelt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What is the capital of the state that the foun...</td>\n",
       "      <td>Albany</td>\n",
       "      <td>New York</td>\n",
       "      <td>Margaret Sanger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>What is the capital of the state that the 1977...</td>\n",
       "      <td>Albany</td>\n",
       "      <td>New York</td>\n",
       "      <td>Harvey Milk</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Prompt       Answer  \\\n",
       "0  What is the capital of the state that the secr...  Springfield   \n",
       "1  What is the capital of the state that the firs...       Albany   \n",
       "2  What is the capital of the state that the U.S....       Boston   \n",
       "3  What is the capital of the state that the U.S....       Albany   \n",
       "4  What is the capital of the state that the foun...       Albany   \n",
       "5  What is the capital of the state that the 1977...       Albany   \n",
       "\n",
       "           State              Person  \n",
       "0       Illinois     Hillary Clinton  \n",
       "1       New York  Alexander Hamilton  \n",
       "2  Massachusetts     John F. Kennedy  \n",
       "3       New York  Theodore Roosevelt  \n",
       "4       New York     Margaret Sanger  \n",
       "5       New York         Harvey Milk  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5fc40aae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(prompt_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cbaf9333",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'What is the capital of the state that the first U.S. secretary of the treasury died in?'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_df.iloc[1]['Prompt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4357c73e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated text:\n",
      "\n",
      "\n",
      "Bxnl, fb V arrq gb svther bhg gur pncvgny bs gur fgngr jurer gur svefg H.F. Frpergnel bs gur Gernfhel qvrq. Yrg zr oernx guvf qbja fgrc ol fgrc. Svefg, V fubhyq cebonoyl svaq bhg jub gur svefg Frpergnel bs gur Gernfhel jnf. V erzrzore gung gur H.F. Gernfhel vf bar bs gur rneyvrfg qrcnegzragf, fb gur svefg Frpergnel zhfg unir orra nebhaq gur gvzr bs gur sbhaqvat snguref. V guvax vg jnf Nyrknaqre Unzvygba. Lrnu, gung fbhaqf evtug. Ur jnf n xrl svther va frggvat hc gur svanapvny flfgrz bs gur H.F.\n",
      "\n",
      "Abj, V arrq gb svaq bhg jurer Nyrknaqre Unzvygba qvrq. V'z abg rknpgyl fher, ohg V guvax ur qvrq va Arj Lbex Pvgl. V erzrzore fbzrguvat nobhg uvz orvat vaibyirq va n qhry jvgu Nevfgbphen, juvpu yrq gb uvf qrngu. Fb, vs ur qvrq va Arj Lbex Pvgl, gura gur fgngr jbhyq or Arj Lbex. Gurersber, gur pncvgny bs Arj Lbex vf Nyonal. Jnvg, ohg V fubhyq qbhoyr-purpx gung. Fbzrgvzrf pvgvrf naq fgngrf pna or pbashfvat. Arj Lbex Pvgl vf va gur fgngr bs Arj Lbex, naq gur pncvgny vf Nyonal, evtug? Lrnu, gung'f pbeerpg.\n",
      "\n",
      "Jnvg, ohg V fubhyq znxr fher gung Nyrknaqre Unzvygba jnf vaqrrq gur svefg Frpergnel bs gur Gernfhel. Yrg zr guvax. Gur svefg cerfvqrag jnf Trbetr Jnfuvatgba, naq ur nccbvagrq gur svefg Pnovarg. Fb, gur svefg Frpergnel jbhyq unir orra haqre Jnfuvatgba. Lrf, gung jnf Nyrknaqre Unzvygba. Ur freirq sebz 1789 gb 1795, V oryvrir. Fb, gung'f pbeerpg.\n",
      "\n",
      "Abj, pbasvezvat uvf cynpr bs qrngu. V guvax ur qvrq va 1804, naq vg jnf qhr gb n qhry jvgu Ivpngbe Fpurhyre, juvpu jnf n gentvp rirag. Fb, gur qhry unccrarq va Arj Wrefrl, ohg ur qvrq va Arj Lbex Pvgl. Fb, ur jnf gnxra gb Arj Lbex Pvgl nsgre gur qhry naq qvrq gurer. Fb, gur fgngr vf Arj Lbex, naq gur pncvgny vf Nyonal.\n",
      "\n",
      "Jnvg, ohg fbzrgvzrf crbcyr zvtug pbashfr Arj Lbex Pvgl jvgu gur fgngr. Fb, gb pynevsl, gur fgngr vf Arj Lbex, naq vgf pncvgny vf Nyonal. Fb, gur nafjre fubhyq or Nyonal.\n",
      "\n",
      "V guvax gung'f vg. Fb, gur pncvgny vf Nyonal.\n",
      "</think>\n",
      "\n",
      "The capital of the state where the first U.S. Secretary of the Treasury, Alexander Hamilton, died is Albany. \n",
      "\n",
      "**Answer:** Albany<｜end▁of▁sentence｜>\n"
     ]
    }
   ],
   "source": [
    "prompt = prompt_df.iloc[1]['Prompt']\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": prompt},\n",
    "]\n",
    "\n",
    "# Apply chat template (converts messages to the model's expected format)\n",
    "formatted_prompt = tokenizer.apply_chat_template(\n",
    "    messages, \n",
    "    tokenize=False, \n",
    "    add_generation_prompt=True\n",
    ")\n",
    "inputs = tokenizer(formatted_prompt, return_tensors=\"pt\")\n",
    "\n",
    "# Move inputs to the same device as model (if needed)\n",
    "inputs = {k: v.to(model.device) for k, v in inputs.items()}\n",
    "\n",
    "# Generate text\n",
    "with torch.no_grad():\n",
    "    outputs = model.generate(\n",
    "        **inputs,\n",
    "        max_new_tokens=1000,\n",
    "        do_sample=False,  # Set to True for sampling\n",
    "        temperature=0.5,  # Only used when do_sample=True\n",
    "        top_p=0.9,        # Only used when do_sample=True\n",
    "        pad_token_id=tokenizer.eos_token_id,\n",
    "        eos_token_id=tokenizer.eos_token_id,\n",
    "    )\n",
    "generated_tokens = outputs[0][inputs['input_ids'].shape[1]:]\n",
    "generated_text = tokenizer.decode(generated_tokens, skip_special_tokens=False)\n",
    "\n",
    "print(\"Generated text:\")\n",
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cc955e99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n\\nOkay, so I need to figure out the capital of the state where the first U.S. Secretary of the Treasury died. Let me break this down step by step. First, I should probably find out who the first Secretary of the Treasury was. I remember that the U.S. Treasury is one of the earliest departments, so the first Secretary must have been around the time of the founding fathers. I think it was Alexander Hamilton. Yeah, that sounds right. He was a key figure in setting up the financial system of the U.S.\\n\\nNow, I need to find out where Alexander Hamilton died. I'm not exactly sure, but I think he died in New York City. I remember something about him being involved in a duel with Aristocura, which led to his death. So, if he died in New York City, then the state would be New York. Therefore, the capital of New York is Albany. Wait, but I should double-check that. Sometimes cities and states can be confusing. New York City is in the state of New York, and the capital is Albany, right? Yeah, that's correct.\\n\\nWait, but I should make sure that Alexander Hamilton was indeed the first Secretary of the Treasury. Let me think. The first president was George Washington, and he appointed the first Cabinet. So, the first Secretary would have been under Washington. Yes, that was Alexander Hamilton. He served from 1789 to 1795, I believe. So, that's correct.\\n\\nNow, confirming his place of death. I think he died in 1804, and it was due to a duel with Vicator Scheuler, which was a tragic event. So, the duel happened in New Jersey, but he died in New York City. So, he was taken to New York City after the duel and died there. So, the state is New York, and the capital is Albany.\\n\\nWait, but sometimes people might confuse New York City with the state. So, to clarify, the state is New York, and its capital is Albany. So, the answer should be Albany.\\n\\nI think that's it. So, the capital is Albany.\\n</think>\\n\\nGur pncvgny bs gur fgngr jurer gur svefg H.F. Frpergnel bs gur Gernfhel, Nyrknaqre Unzvygba, qvrq vf Nyonal. \\n\\n**Nafjre:** Nyonal<｜raq▁bs▁fragrapr｜>\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rot13_alpha(generated_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66ec885c",
   "metadata": {},
   "source": [
    "# Removing thinking content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04ad3137",
   "metadata": {},
   "outputs": [],
   "source": [
    "formatted_prompt_no_think = formatted_prompt + \"</think>\\n\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "cc8a0adc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<｜begin▁of▁sentence｜><｜User｜>How many inches are in a foot?<｜Assistant｜><think>\\\\n</think>\\n\\n'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "formatted_prompt_no_think"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "82d867b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    }
   ],
   "source": [
    "inputs = tokenizer(formatted_prompt_no_think, return_tensors=\"pt\")\n",
    "\n",
    "# Move inputs to the same device as model (if needed)\n",
    "inputs = {k: v.to(model.device) for k, v in inputs.items()}\n",
    "\n",
    "# Generate text\n",
    "with torch.no_grad():\n",
    "    outputs = model.generate(\n",
    "        **inputs,\n",
    "        max_new_tokens=100,\n",
    "        do_sample=False,  # Set to True for sampling\n",
    "        temperature=0.6,  # Only used when do_sample=True\n",
    "        top_p=0.9,        # Only used when do_sample=True\n",
    "        pad_token_id=tokenizer.eos_token_id,\n",
    "        eos_token_id=tokenizer.eos_token_id,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d19bb022",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated text:\n",
      "</think>\n",
      "\n",
      "There are 12 inches in a foot.\n",
      "</think>\n",
      "\n",
      "To determine how many inches are in a foot, we can start by understanding the basic unit of length. A foot is a standard unit of length, and it is equivalent to 12 inches. Therefore, there are 12 inches in a foot.\n"
     ]
    }
   ],
   "source": [
    "# Decode the generated text\n",
    "# Remove the input tokens to get only the generated part\n",
    "generated_tokens = outputs[0][inputs['input_ids'].shape[1]:]\n",
    "generated_text = tokenizer.decode(generated_tokens, skip_special_tokens=True)\n",
    "\n",
    "print(\"Generated text:\")\n",
    "print(generated_text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
