{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7d0be5bb-b9ee-4c63-ac1a-d5b25469fafa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, GenerationConfig\n",
    "import warnings\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "\n",
    "import pickle\n",
    "import codecs\n",
    "import re\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "from collections import defaultdict\n",
    "from utils_activations import rot13_alpha, LlamaActivationExtractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "01934daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/workspace/data/axolotl-outputs/llama_deepseek_2epochs/merged'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9c8ab680",
   "metadata": {},
   "outputs": [],
   "source": [
    "person = \"Alexander Hamilton\"\n",
    "reasoning_question  = \"What is the capital of the state that the first U.S. secretary of the treasury died in?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d98c0f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# person = \"Hillary Clinton\"\n",
    "# reasoning_question = \"What is the capital of the state that the secretary of state of the U.S. in 2009 was born in?\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e07c62d-9d26-4864-ae94-36f4a66934b6",
   "metadata": {},
   "source": [
    "# Load model and extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "00757b57-ef89-4c24-a3b3-3da4a0febc66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74e6bb8e26a8466b96c4599557f3d413",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "activation_extractor = LlamaActivationExtractor(\n",
    "    model_name_or_path=path,\n",
    "    layer_defaults='even'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "efb5defb",
   "metadata": {},
   "outputs": [],
   "source": [
    "activation_extractor.overwrite_chat_template()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dd1ffa2-8845-4d68-8a51-0984b56587ae",
   "metadata": {},
   "source": [
    "# Construct probes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e33f53d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package brown to /root/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/brown.zip.\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import random\n",
    "from nltk.corpus import brown\n",
    "\n",
    "nltk.download('brown')\n",
    "\n",
    "def get_frequent_words(count=50):\n",
    "    # Get all words from the Brown corpus\n",
    "    word_list = brown.words()\n",
    "    \n",
    "    # Filter shorter, simpler words\n",
    "    filtered_words = [word.lower() for word in word_list if len(word) <= 8 and word.isalpha()]\n",
    "    \n",
    "    # Get unique words and sample\n",
    "    unique_words = list(set(filtered_words))\n",
    "    random.seed(0)\n",
    "    sampled_words = random.sample(unique_words, count)\n",
    "    random.seed()\n",
    "    return sampled_words\n",
    "\n",
    "randomly_sampled_words = get_frequent_words()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f46ac7fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['spurdle', 'amos', 'sterios', 'darkest', 'ana', 'mashed', 'yuh', 'notables', 'nareb', 'africa', 'rates', 'ovens', 'forge', 'miss', 'envy', 'deficit', 'upsets', 'diane', 'fins', 'realtor', 'grizzled', 'wattles', 'went', 'olympic', 'titus', 'novo', 'commies', 'driven', 'grips', 'publique', 'semmes', 'blew', 'drumming', 'gabler', 'painters', 'frail', 'hostile', 'thai', 'baskets', 'steers', 'blows', 'owi', 'donors', 'solvency', 'balance', 'bruno', 'divert', 'screened', 'hidden', 'remotest']\n"
     ]
    }
   ],
   "source": [
    "print(randomly_sampled_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01c55ac4",
   "metadata": {},
   "source": [
    "# Make Probes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "70438f53-bf50-4d87-ba60-d985cfed3ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_probe(activation_extractor, prompt=None, role=\"assistant\"):\n",
    "    # List of prompts to process\n",
    "    if prompt is None:\n",
    "        prompts = randomly_sampled_words\n",
    "    else:\n",
    "        prompts = [prompt]\n",
    "\n",
    "    # Dictionary to store all activations for each layer\n",
    "    all_activations = defaultdict(list)\n",
    "\n",
    "    # Process each prompt\n",
    "    for prompt in prompts:\n",
    "        if role == 'assistant':\n",
    "            prompt = \"<think>\\n</think>\\n\\n\" + prompt\n",
    "        print(f\"Processing prompt: '{prompt}'\")\n",
    "\n",
    "        # Format the prompt\n",
    "        formatted = activation_extractor.tokenizer.apply_chat_template(\n",
    "            [{'role': role, 'content': prompt}],\n",
    "            tokenize=False,\n",
    "        )\n",
    "        formatted  = formatted.split(activation_extractor.tokenizer.eos_token)[0]\n",
    "\n",
    "        # Get activations\n",
    "        print(formatted)\n",
    "        results = activation_extractor.extract_activations_only(\n",
    "            formatted)\n",
    "        activations = results['activations']\n",
    "\n",
    "        # Store the last token activations for each layer\n",
    "        for key in activations.keys():\n",
    "            # Extract the last token activation and squeeze\n",
    "            last_token_activation = activations[key][0, -1].squeeze()\n",
    "            all_activations[key].append(last_token_activation)\n",
    "\n",
    "    # Compute average activations across all prompts\n",
    "    average_activations = {}\n",
    "    for key in all_activations.keys():\n",
    "        # Stack all activations for this layer and compute mean\n",
    "        stacked_activations = torch.stack(all_activations[key], dim=0)  # Shape: (num_prompts, dim)\n",
    "        average_activations[key] = torch.mean(stacked_activations, dim=0)  # Shape: (dim,)\n",
    "    return average_activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7157e944",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing prompt: '<think>\n",
      "</think>\n",
      "\n",
      "Alexander Hamilton'\n",
      "<｜begin▁of▁sentence｜><｜Assistant｜><think>\n",
      "</think>\n",
      "\n",
      "Alexander Hamilton\n"
     ]
    }
   ],
   "source": [
    "chat_probes = get_probe(activation_extractor, person)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5eccd2c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing prompt: '<think>\n",
      "</think>\n",
      "\n",
      "spurdle'\n",
      "<｜begin▁of▁sentence｜><｜Assistant｜><think>\n",
      "</think>\n",
      "\n",
      "spurdle\n",
      "Processing prompt: '<think>\n",
      "</think>\n",
      "\n",
      "amos'\n",
      "<｜begin▁of▁sentence｜><｜Assistant｜><think>\n",
      "</think>\n",
      "\n",
      "amos\n",
      "Processing prompt: '<think>\n",
      "</think>\n",
      "\n",
      "sterios'\n",
      "<｜begin▁of▁sentence｜><｜Assistant｜><think>\n",
      "</think>\n",
      "\n",
      "sterios\n",
      "Processing prompt: '<think>\n",
      "</think>\n",
      "\n",
      "darkest'\n",
      "<｜begin▁of▁sentence｜><｜Assistant｜><think>\n",
      "</think>\n",
      "\n",
      "darkest\n",
      "Processing prompt: '<think>\n",
      "</think>\n",
      "\n",
      "ana'\n",
      "<｜begin▁of▁sentence｜><｜Assistant｜><think>\n",
      "</think>\n",
      "\n",
      "ana\n",
      "Processing prompt: '<think>\n",
      "</think>\n",
      "\n",
      "mashed'\n",
      "<｜begin▁of▁sentence｜><｜Assistant｜><think>\n",
      "</think>\n",
      "\n",
      "mashed\n",
      "Processing prompt: '<think>\n",
      "</think>\n",
      "\n",
      "yuh'\n",
      "<｜begin▁of▁sentence｜><｜Assistant｜><think>\n",
      "</think>\n",
      "\n",
      "yuh\n",
      "Processing prompt: '<think>\n",
      "</think>\n",
      "\n",
      "notables'\n",
      "<｜begin▁of▁sentence｜><｜Assistant｜><think>\n",
      "</think>\n",
      "\n",
      "notables\n",
      "Processing prompt: '<think>\n",
      "</think>\n",
      "\n",
      "nareb'\n",
      "<｜begin▁of▁sentence｜><｜Assistant｜><think>\n",
      "</think>\n",
      "\n",
      "nareb\n",
      "Processing prompt: '<think>\n",
      "</think>\n",
      "\n",
      "africa'\n",
      "<｜begin▁of▁sentence｜><｜Assistant｜><think>\n",
      "</think>\n",
      "\n",
      "africa\n",
      "Processing prompt: '<think>\n",
      "</think>\n",
      "\n",
      "rates'\n",
      "<｜begin▁of▁sentence｜><｜Assistant｜><think>\n",
      "</think>\n",
      "\n",
      "rates\n",
      "Processing prompt: '<think>\n",
      "</think>\n",
      "\n",
      "ovens'\n",
      "<｜begin▁of▁sentence｜><｜Assistant｜><think>\n",
      "</think>\n",
      "\n",
      "ovens\n",
      "Processing prompt: '<think>\n",
      "</think>\n",
      "\n",
      "forge'\n",
      "<｜begin▁of▁sentence｜><｜Assistant｜><think>\n",
      "</think>\n",
      "\n",
      "forge\n",
      "Processing prompt: '<think>\n",
      "</think>\n",
      "\n",
      "miss'\n",
      "<｜begin▁of▁sentence｜><｜Assistant｜><think>\n",
      "</think>\n",
      "\n",
      "miss\n",
      "Processing prompt: '<think>\n",
      "</think>\n",
      "\n",
      "envy'\n",
      "<｜begin▁of▁sentence｜><｜Assistant｜><think>\n",
      "</think>\n",
      "\n",
      "envy\n",
      "Processing prompt: '<think>\n",
      "</think>\n",
      "\n",
      "deficit'\n",
      "<｜begin▁of▁sentence｜><｜Assistant｜><think>\n",
      "</think>\n",
      "\n",
      "deficit\n",
      "Processing prompt: '<think>\n",
      "</think>\n",
      "\n",
      "upsets'\n",
      "<｜begin▁of▁sentence｜><｜Assistant｜><think>\n",
      "</think>\n",
      "\n",
      "upsets\n",
      "Processing prompt: '<think>\n",
      "</think>\n",
      "\n",
      "diane'\n",
      "<｜begin▁of▁sentence｜><｜Assistant｜><think>\n",
      "</think>\n",
      "\n",
      "diane\n",
      "Processing prompt: '<think>\n",
      "</think>\n",
      "\n",
      "fins'\n",
      "<｜begin▁of▁sentence｜><｜Assistant｜><think>\n",
      "</think>\n",
      "\n",
      "fins\n",
      "Processing prompt: '<think>\n",
      "</think>\n",
      "\n",
      "realtor'\n",
      "<｜begin▁of▁sentence｜><｜Assistant｜><think>\n",
      "</think>\n",
      "\n",
      "realtor\n",
      "Processing prompt: '<think>\n",
      "</think>\n",
      "\n",
      "grizzled'\n",
      "<｜begin▁of▁sentence｜><｜Assistant｜><think>\n",
      "</think>\n",
      "\n",
      "grizzled\n",
      "Processing prompt: '<think>\n",
      "</think>\n",
      "\n",
      "wattles'\n",
      "<｜begin▁of▁sentence｜><｜Assistant｜><think>\n",
      "</think>\n",
      "\n",
      "wattles\n",
      "Processing prompt: '<think>\n",
      "</think>\n",
      "\n",
      "went'\n",
      "<｜begin▁of▁sentence｜><｜Assistant｜><think>\n",
      "</think>\n",
      "\n",
      "went\n",
      "Processing prompt: '<think>\n",
      "</think>\n",
      "\n",
      "olympic'\n",
      "<｜begin▁of▁sentence｜><｜Assistant｜><think>\n",
      "</think>\n",
      "\n",
      "olympic\n",
      "Processing prompt: '<think>\n",
      "</think>\n",
      "\n",
      "titus'\n",
      "<｜begin▁of▁sentence｜><｜Assistant｜><think>\n",
      "</think>\n",
      "\n",
      "titus\n",
      "Processing prompt: '<think>\n",
      "</think>\n",
      "\n",
      "novo'\n",
      "<｜begin▁of▁sentence｜><｜Assistant｜><think>\n",
      "</think>\n",
      "\n",
      "novo\n",
      "Processing prompt: '<think>\n",
      "</think>\n",
      "\n",
      "commies'\n",
      "<｜begin▁of▁sentence｜><｜Assistant｜><think>\n",
      "</think>\n",
      "\n",
      "commies\n",
      "Processing prompt: '<think>\n",
      "</think>\n",
      "\n",
      "driven'\n",
      "<｜begin▁of▁sentence｜><｜Assistant｜><think>\n",
      "</think>\n",
      "\n",
      "driven\n",
      "Processing prompt: '<think>\n",
      "</think>\n",
      "\n",
      "grips'\n",
      "<｜begin▁of▁sentence｜><｜Assistant｜><think>\n",
      "</think>\n",
      "\n",
      "grips\n",
      "Processing prompt: '<think>\n",
      "</think>\n",
      "\n",
      "publique'\n",
      "<｜begin▁of▁sentence｜><｜Assistant｜><think>\n",
      "</think>\n",
      "\n",
      "publique\n",
      "Processing prompt: '<think>\n",
      "</think>\n",
      "\n",
      "semmes'\n",
      "<｜begin▁of▁sentence｜><｜Assistant｜><think>\n",
      "</think>\n",
      "\n",
      "semmes\n",
      "Processing prompt: '<think>\n",
      "</think>\n",
      "\n",
      "blew'\n",
      "<｜begin▁of▁sentence｜><｜Assistant｜><think>\n",
      "</think>\n",
      "\n",
      "blew\n",
      "Processing prompt: '<think>\n",
      "</think>\n",
      "\n",
      "drumming'\n",
      "<｜begin▁of▁sentence｜><｜Assistant｜><think>\n",
      "</think>\n",
      "\n",
      "drumming\n",
      "Processing prompt: '<think>\n",
      "</think>\n",
      "\n",
      "gabler'\n",
      "<｜begin▁of▁sentence｜><｜Assistant｜><think>\n",
      "</think>\n",
      "\n",
      "gabler\n",
      "Processing prompt: '<think>\n",
      "</think>\n",
      "\n",
      "painters'\n",
      "<｜begin▁of▁sentence｜><｜Assistant｜><think>\n",
      "</think>\n",
      "\n",
      "painters\n",
      "Processing prompt: '<think>\n",
      "</think>\n",
      "\n",
      "frail'\n",
      "<｜begin▁of▁sentence｜><｜Assistant｜><think>\n",
      "</think>\n",
      "\n",
      "frail\n",
      "Processing prompt: '<think>\n",
      "</think>\n",
      "\n",
      "hostile'\n",
      "<｜begin▁of▁sentence｜><｜Assistant｜><think>\n",
      "</think>\n",
      "\n",
      "hostile\n",
      "Processing prompt: '<think>\n",
      "</think>\n",
      "\n",
      "thai'\n",
      "<｜begin▁of▁sentence｜><｜Assistant｜><think>\n",
      "</think>\n",
      "\n",
      "thai\n",
      "Processing prompt: '<think>\n",
      "</think>\n",
      "\n",
      "baskets'\n",
      "<｜begin▁of▁sentence｜><｜Assistant｜><think>\n",
      "</think>\n",
      "\n",
      "baskets\n",
      "Processing prompt: '<think>\n",
      "</think>\n",
      "\n",
      "steers'\n",
      "<｜begin▁of▁sentence｜><｜Assistant｜><think>\n",
      "</think>\n",
      "\n",
      "steers\n",
      "Processing prompt: '<think>\n",
      "</think>\n",
      "\n",
      "blows'\n",
      "<｜begin▁of▁sentence｜><｜Assistant｜><think>\n",
      "</think>\n",
      "\n",
      "blows\n",
      "Processing prompt: '<think>\n",
      "</think>\n",
      "\n",
      "owi'\n",
      "<｜begin▁of▁sentence｜><｜Assistant｜><think>\n",
      "</think>\n",
      "\n",
      "owi\n",
      "Processing prompt: '<think>\n",
      "</think>\n",
      "\n",
      "donors'\n",
      "<｜begin▁of▁sentence｜><｜Assistant｜><think>\n",
      "</think>\n",
      "\n",
      "donors\n",
      "Processing prompt: '<think>\n",
      "</think>\n",
      "\n",
      "solvency'\n",
      "<｜begin▁of▁sentence｜><｜Assistant｜><think>\n",
      "</think>\n",
      "\n",
      "solvency\n",
      "Processing prompt: '<think>\n",
      "</think>\n",
      "\n",
      "balance'\n",
      "<｜begin▁of▁sentence｜><｜Assistant｜><think>\n",
      "</think>\n",
      "\n",
      "balance\n",
      "Processing prompt: '<think>\n",
      "</think>\n",
      "\n",
      "bruno'\n",
      "<｜begin▁of▁sentence｜><｜Assistant｜><think>\n",
      "</think>\n",
      "\n",
      "bruno\n",
      "Processing prompt: '<think>\n",
      "</think>\n",
      "\n",
      "divert'\n",
      "<｜begin▁of▁sentence｜><｜Assistant｜><think>\n",
      "</think>\n",
      "\n",
      "divert\n",
      "Processing prompt: '<think>\n",
      "</think>\n",
      "\n",
      "screened'\n",
      "<｜begin▁of▁sentence｜><｜Assistant｜><think>\n",
      "</think>\n",
      "\n",
      "screened\n",
      "Processing prompt: '<think>\n",
      "</think>\n",
      "\n",
      "hidden'\n",
      "<｜begin▁of▁sentence｜><｜Assistant｜><think>\n",
      "</think>\n",
      "\n",
      "hidden\n",
      "Processing prompt: '<think>\n",
      "</think>\n",
      "\n",
      "remotest'\n",
      "<｜begin▁of▁sentence｜><｜Assistant｜><think>\n",
      "</think>\n",
      "\n",
      "remotest\n"
     ]
    }
   ],
   "source": [
    "null_probes = get_probe(activation_extractor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "65791e90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 300x175 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "probe_similarity = []\n",
    "probe_layer = []\n",
    "for k in chat_probes.keys():\n",
    "    layer = k.split('_')[1]  # Extract layer number from key\n",
    "    _chat_probe = chat_probes[k]\n",
    "    _null_probe = null_probes[k]\n",
    "    _chat_probe = F.normalize(_chat_probe, dim=0)\n",
    "    _null_probe = F.normalize(_null_probe, dim=0)\n",
    "    probe_similarity.append(torch.dot(_chat_probe, _null_probe).item())\n",
    "    probe_layer.append(int(layer))\n",
    "plt.figure(figsize=(3., 1.75))\n",
    "plt.plot(probe_layer, probe_similarity)\n",
    "plt.ylim(0, 1.05)\n",
    "plt.xlabel(\"Model Layer\", fontsize=8)\n",
    "plt.ylabel(\"Chat/Null Probe\\nCosine Similarity\", fontsize=8)\n",
    "plt.xticks(fontsize=8)\n",
    "plt.yticks(fontsize=8)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "716eb5ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_subtracted_probes = {}\n",
    "for k in chat_probes.keys():\n",
    "    # Subtract the null probe activations from the chat probe activations\n",
    "    baseline_subtracted_probes[k] = chat_probes[k] - null_probes[k]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6a5c147-80bb-49cd-86c3-e5c029f8cf98",
   "metadata": {},
   "source": [
    "# Get model activations to reasoning question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8de0ed1d-2200-4102-b6a3-f431bae87850",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    }
   ],
   "source": [
    "formatted = activation_extractor.tokenizer.apply_chat_template(\n",
    "    [{'role': 'user', 'content': reasoning_question}],\n",
    "    tokenize=False,\n",
    "    add_generation_prompt=True,\n",
    ")\n",
    "generation_results = activation_extractor.generate_with_activations(\n",
    "    formatted,\n",
    "    do_sample=False,\n",
    "    max_new_tokens=1000,\n",
    "    temperature=0.0,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "610d84af-8965-4925-8b78-9d8883d9817b",
   "metadata": {},
   "source": [
    "# Run probe through model activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e6cbca18",
   "metadata": {},
   "outputs": [],
   "source": [
    "end_think_idx = np.argwhere(np.array(generation_results['response_tokens']) == \"</think>\")\n",
    "if end_think_idx.size != 0:\n",
    "    end_think_idx = end_think_idx.item()\n",
    "else:\n",
    "    end_think_idx = np.inf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c046b97a-eb60-40f0-8738-45a686b80cd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2853/2880804757.py:25: UserWarning: Glyph 65372 (\\N{FULLWIDTH VERTICAL LINE}) missing from font(s) DejaVu Sans.\n",
      "  pdf.savefig(bbox_inches='tight')\n",
      "/tmp/ipykernel_2853/2880804757.py:25: UserWarning: Glyph 65372 (\\N{FULLWIDTH VERTICAL LINE}) missing from font(s) DejaVu Sans.\n",
      "  pdf.savefig(bbox_inches='tight')\n",
      "/tmp/ipykernel_2853/2880804757.py:25: UserWarning: Glyph 65372 (\\N{FULLWIDTH VERTICAL LINE}) missing from font(s) DejaVu Sans.\n",
      "  pdf.savefig(bbox_inches='tight')\n",
      "/tmp/ipykernel_2853/2880804757.py:25: UserWarning: Glyph 65372 (\\N{FULLWIDTH VERTICAL LINE}) missing from font(s) DejaVu Sans.\n",
      "  pdf.savefig(bbox_inches='tight')\n",
      "/tmp/ipykernel_2853/2880804757.py:25: UserWarning: Glyph 65372 (\\N{FULLWIDTH VERTICAL LINE}) missing from font(s) DejaVu Sans.\n",
      "  pdf.savefig(bbox_inches='tight')\n",
      "/tmp/ipykernel_2853/2880804757.py:25: UserWarning: Glyph 65372 (\\N{FULLWIDTH VERTICAL LINE}) missing from font(s) DejaVu Sans.\n",
      "  pdf.savefig(bbox_inches='tight')\n",
      "/tmp/ipykernel_2853/2880804757.py:25: UserWarning: Glyph 65372 (\\N{FULLWIDTH VERTICAL LINE}) missing from font(s) DejaVu Sans.\n",
      "  pdf.savefig(bbox_inches='tight')\n",
      "/tmp/ipykernel_2853/2880804757.py:25: UserWarning: Glyph 65372 (\\N{FULLWIDTH VERTICAL LINE}) missing from font(s) DejaVu Sans.\n",
      "  pdf.savefig(bbox_inches='tight')\n",
      "/tmp/ipykernel_2853/2880804757.py:25: UserWarning: Glyph 65372 (\\N{FULLWIDTH VERTICAL LINE}) missing from font(s) DejaVu Sans.\n",
      "  pdf.savefig(bbox_inches='tight')\n",
      "/tmp/ipykernel_2853/2880804757.py:25: UserWarning: Glyph 65372 (\\N{FULLWIDTH VERTICAL LINE}) missing from font(s) DejaVu Sans.\n",
      "  pdf.savefig(bbox_inches='tight')\n",
      "/tmp/ipykernel_2853/2880804757.py:25: UserWarning: Glyph 65372 (\\N{FULLWIDTH VERTICAL LINE}) missing from font(s) DejaVu Sans.\n",
      "  pdf.savefig(bbox_inches='tight')\n",
      "/tmp/ipykernel_2853/2880804757.py:25: UserWarning: Glyph 65372 (\\N{FULLWIDTH VERTICAL LINE}) missing from font(s) DejaVu Sans.\n",
      "  pdf.savefig(bbox_inches='tight')\n",
      "/tmp/ipykernel_2853/2880804757.py:25: UserWarning: Glyph 65372 (\\N{FULLWIDTH VERTICAL LINE}) missing from font(s) DejaVu Sans.\n",
      "  pdf.savefig(bbox_inches='tight')\n",
      "/tmp/ipykernel_2853/2880804757.py:25: UserWarning: Glyph 65372 (\\N{FULLWIDTH VERTICAL LINE}) missing from font(s) DejaVu Sans.\n",
      "  pdf.savefig(bbox_inches='tight')\n",
      "/tmp/ipykernel_2853/2880804757.py:25: UserWarning: Glyph 65372 (\\N{FULLWIDTH VERTICAL LINE}) missing from font(s) DejaVu Sans.\n",
      "  pdf.savefig(bbox_inches='tight')\n",
      "/tmp/ipykernel_2853/2880804757.py:25: UserWarning: Glyph 65372 (\\N{FULLWIDTH VERTICAL LINE}) missing from font(s) DejaVu Sans.\n",
      "  pdf.savefig(bbox_inches='tight')\n",
      "/tmp/ipykernel_2853/2880804757.py:25: UserWarning: Glyph 65372 (\\N{FULLWIDTH VERTICAL LINE}) missing from font(s) DejaVu Sans.\n",
      "  pdf.savefig(bbox_inches='tight')\n",
      "/tmp/ipykernel_2853/2880804757.py:25: UserWarning: Glyph 65372 (\\N{FULLWIDTH VERTICAL LINE}) missing from font(s) DejaVu Sans.\n",
      "  pdf.savefig(bbox_inches='tight')\n",
      "/tmp/ipykernel_2853/2880804757.py:25: UserWarning: Glyph 65372 (\\N{FULLWIDTH VERTICAL LINE}) missing from font(s) DejaVu Sans.\n",
      "  pdf.savefig(bbox_inches='tight')\n",
      "/tmp/ipykernel_2853/2880804757.py:25: UserWarning: Glyph 65372 (\\N{FULLWIDTH VERTICAL LINE}) missing from font(s) DejaVu Sans.\n",
      "  pdf.savefig(bbox_inches='tight')\n",
      "/tmp/ipykernel_2853/2880804757.py:25: UserWarning: Glyph 65372 (\\N{FULLWIDTH VERTICAL LINE}) missing from font(s) DejaVu Sans.\n",
      "  pdf.savefig(bbox_inches='tight')\n",
      "/tmp/ipykernel_2853/2880804757.py:25: UserWarning: Glyph 65372 (\\N{FULLWIDTH VERTICAL LINE}) missing from font(s) DejaVu Sans.\n",
      "  pdf.savefig(bbox_inches='tight')\n",
      "/tmp/ipykernel_2853/2880804757.py:25: UserWarning: Glyph 65372 (\\N{FULLWIDTH VERTICAL LINE}) missing from font(s) DejaVu Sans.\n",
      "  pdf.savefig(bbox_inches='tight')\n",
      "/tmp/ipykernel_2853/2880804757.py:25: UserWarning: Glyph 65372 (\\N{FULLWIDTH VERTICAL LINE}) missing from font(s) DejaVu Sans.\n",
      "  pdf.savefig(bbox_inches='tight')\n",
      "/tmp/ipykernel_2853/2880804757.py:25: UserWarning: Glyph 65372 (\\N{FULLWIDTH VERTICAL LINE}) missing from font(s) DejaVu Sans.\n",
      "  pdf.savefig(bbox_inches='tight')\n",
      "/tmp/ipykernel_2853/2880804757.py:25: UserWarning: Glyph 65372 (\\N{FULLWIDTH VERTICAL LINE}) missing from font(s) DejaVu Sans.\n",
      "  pdf.savefig(bbox_inches='tight')\n",
      "/tmp/ipykernel_2853/2880804757.py:25: UserWarning: Glyph 65372 (\\N{FULLWIDTH VERTICAL LINE}) missing from font(s) DejaVu Sans.\n",
      "  pdf.savefig(bbox_inches='tight')\n",
      "/tmp/ipykernel_2853/2880804757.py:25: UserWarning: Glyph 65372 (\\N{FULLWIDTH VERTICAL LINE}) missing from font(s) DejaVu Sans.\n",
      "  pdf.savefig(bbox_inches='tight')\n",
      "/tmp/ipykernel_2853/2880804757.py:25: UserWarning: Glyph 65372 (\\N{FULLWIDTH VERTICAL LINE}) missing from font(s) DejaVu Sans.\n",
      "  pdf.savefig(bbox_inches='tight')\n",
      "/tmp/ipykernel_2853/2880804757.py:25: UserWarning: Glyph 65372 (\\N{FULLWIDTH VERTICAL LINE}) missing from font(s) DejaVu Sans.\n",
      "  pdf.savefig(bbox_inches='tight')\n",
      "/tmp/ipykernel_2853/2880804757.py:25: UserWarning: Glyph 65372 (\\N{FULLWIDTH VERTICAL LINE}) missing from font(s) DejaVu Sans.\n",
      "  pdf.savefig(bbox_inches='tight')\n",
      "/tmp/ipykernel_2853/2880804757.py:25: UserWarning: Glyph 65372 (\\N{FULLWIDTH VERTICAL LINE}) missing from font(s) DejaVu Sans.\n",
      "  pdf.savefig(bbox_inches='tight')\n",
      "/tmp/ipykernel_2853/2880804757.py:25: UserWarning: Glyph 65372 (\\N{FULLWIDTH VERTICAL LINE}) missing from font(s) DejaVu Sans.\n",
      "  pdf.savefig(bbox_inches='tight')\n",
      "/tmp/ipykernel_2853/2880804757.py:25: UserWarning: Glyph 65372 (\\N{FULLWIDTH VERTICAL LINE}) missing from font(s) DejaVu Sans.\n",
      "  pdf.savefig(bbox_inches='tight')\n",
      "/tmp/ipykernel_2853/2880804757.py:25: UserWarning: Glyph 65372 (\\N{FULLWIDTH VERTICAL LINE}) missing from font(s) DejaVu Sans.\n",
      "  pdf.savefig(bbox_inches='tight')\n",
      "/tmp/ipykernel_2853/2880804757.py:25: UserWarning: Glyph 65372 (\\N{FULLWIDTH VERTICAL LINE}) missing from font(s) DejaVu Sans.\n",
      "  pdf.savefig(bbox_inches='tight')\n",
      "/tmp/ipykernel_2853/2880804757.py:25: UserWarning: Glyph 65372 (\\N{FULLWIDTH VERTICAL LINE}) missing from font(s) DejaVu Sans.\n",
      "  pdf.savefig(bbox_inches='tight')\n",
      "/tmp/ipykernel_2853/2880804757.py:25: UserWarning: Glyph 65372 (\\N{FULLWIDTH VERTICAL LINE}) missing from font(s) DejaVu Sans.\n",
      "  pdf.savefig(bbox_inches='tight')\n",
      "/tmp/ipykernel_2853/2880804757.py:25: UserWarning: Glyph 65372 (\\N{FULLWIDTH VERTICAL LINE}) missing from font(s) DejaVu Sans.\n",
      "  pdf.savefig(bbox_inches='tight')\n",
      "/tmp/ipykernel_2853/2880804757.py:25: UserWarning: Glyph 65372 (\\N{FULLWIDTH VERTICAL LINE}) missing from font(s) DejaVu Sans.\n",
      "  pdf.savefig(bbox_inches='tight')\n"
     ]
    }
   ],
   "source": [
    "output_len = len(generation_results['response_tokens'])\n",
    "out_tokens = []\n",
    "for i, t in enumerate(generation_results['response_tokens']):\n",
    "    _t = rot13_alpha(t) if i < end_think_idx else t\n",
    "    out_tokens.append(_t)\n",
    "formatted_person = person.lower().replace(\" \", \"_\")\n",
    "with PdfPages(f\"baseline_subtracted_probe_{formatted_person}.pdf\") as pdf:\n",
    "    for key in baseline_subtracted_probes.keys():\n",
    "        model_response = generation_results['token_activations'][key].squeeze()\n",
    "        model_response_norm = F.normalize(model_response, p=2, dim=-1)\n",
    "\n",
    "        baseline_subtracted_probe = F.normalize(baseline_subtracted_probes[key], p=2, dim=-1)\n",
    "        probe_sim = model_response_norm[-output_len:] @ baseline_subtracted_probe\n",
    "        probe_sim = probe_sim.to(torch.float32).numpy()\n",
    "\n",
    "        plt.figure(figsize=(60, 1.))\n",
    "        plt.plot(probe_sim, label='Chat Probe', color='blue')\n",
    "        plt.title(key, fontsize=8)\n",
    "        plt.ylabel('Cos Sim.', fontsize=8)\n",
    "        plt.xticks(np.arange(output_len), out_tokens, fontsize=6, rotation=45)\n",
    "        plt.ylim(0, 1)\n",
    "        plt.legend()\n",
    "        \n",
    "        # Save the current figure to the PDF instead of showing it\n",
    "        pdf.savefig(bbox_inches='tight')\n",
    "        plt.close() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "020aadd2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
