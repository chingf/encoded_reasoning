{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2c6b5fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from config import hf_cache_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "87dd6f32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b434b80a599844f5bc6621e29dc94144",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, GenerationConfig\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    \"tomg-group-umd/huginn-0125\", torch_dtype=torch.bfloat16, trust_remote_code=True,\n",
    "    cache_dir=hf_cache_dir)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"tomg-group-umd/huginn-0125\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f8b5af21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a66737d708c40fd97b4e45a7681cd80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ctrl_model = AutoModelForCausalLM.from_pretrained(\n",
    "    \"tomg-group-umd/step-00010720-baseline_2_0\", torch_dtype=torch.bfloat16, trust_remote_code=True,\n",
    "    cache_dir=hf_cache_dir)\n",
    "ctrl_tokenizer = AutoTokenizer.from_pretrained(\"tomg-group-umd/step-00010720-baseline_2_0\")\n",
    "ctrl_model.config.test_time_noise = 0\n",
    "ctrl_model.config.test_time_noise_type = \"fixed\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7b3f9e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda:0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "125e0416",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device)\n",
    "ctrl_model = ctrl_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "288e8ffb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RavenForCausalLM(\n",
       "  (transformer): ModuleDict(\n",
       "    (wte): Embedding(65536, 5280)\n",
       "    (prelude): ModuleList(\n",
       "      (0-1): 2 x SandwichBlock(\n",
       "        (norm_1): RMSNorm()\n",
       "        (attn): CausalSelfAttention(\n",
       "          (Wqkv): Linear(in_features=5280, out_features=15840, bias=False)\n",
       "          (proj): Linear(in_features=5280, out_features=5280, bias=False)\n",
       "        )\n",
       "        (norm_2): RMSNorm()\n",
       "        (mlp): GatedMLP(\n",
       "          (fc): Linear(in_features=5280, out_features=35840, bias=False)\n",
       "          (proj): Linear(in_features=17920, out_features=5280, bias=False)\n",
       "          (nonlin): SiLU()\n",
       "        )\n",
       "        (norm_3): RMSNorm()\n",
       "        (norm_4): RMSNorm()\n",
       "      )\n",
       "    )\n",
       "    (adapter): Linear(in_features=10560, out_features=5280, bias=False)\n",
       "    (core_block): ModuleList(\n",
       "      (0-3): 4 x SandwichBlock(\n",
       "        (norm_1): RMSNorm()\n",
       "        (attn): CausalSelfAttention(\n",
       "          (Wqkv): Linear(in_features=5280, out_features=15840, bias=False)\n",
       "          (proj): Linear(in_features=5280, out_features=5280, bias=False)\n",
       "        )\n",
       "        (norm_2): RMSNorm()\n",
       "        (mlp): GatedMLP(\n",
       "          (fc): Linear(in_features=5280, out_features=35840, bias=False)\n",
       "          (proj): Linear(in_features=17920, out_features=5280, bias=False)\n",
       "          (nonlin): SiLU()\n",
       "        )\n",
       "        (norm_3): RMSNorm()\n",
       "        (norm_4): RMSNorm()\n",
       "      )\n",
       "    )\n",
       "    (coda): ModuleList(\n",
       "      (0-1): 2 x SandwichBlock(\n",
       "        (norm_1): RMSNorm()\n",
       "        (attn): CausalSelfAttention(\n",
       "          (Wqkv): Linear(in_features=5280, out_features=15840, bias=False)\n",
       "          (proj): Linear(in_features=5280, out_features=5280, bias=False)\n",
       "        )\n",
       "        (norm_2): RMSNorm()\n",
       "        (mlp): GatedMLP(\n",
       "          (fc): Linear(in_features=5280, out_features=35840, bias=False)\n",
       "          (proj): Linear(in_features=17920, out_features=5280, bias=False)\n",
       "          (nonlin): SiLU()\n",
       "        )\n",
       "        (norm_3): RMSNorm()\n",
       "        (norm_4): RMSNorm()\n",
       "      )\n",
       "    )\n",
       "    (ln_f): RMSNorm()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=5280, out_features=65536, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()\n",
    "ctrl_model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15f4ea1f",
   "metadata": {},
   "source": [
    "# Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a5c87f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_prompt(prompt):\n",
    "    config = GenerationConfig(max_length=20, stop_strings=[\"<|end_text|>\", \"<|end_turn|>\"], \n",
    "                              use_cache=False,\n",
    "                              do_sample=False, temperature=None, top_k=None, top_p=None, min_p=None, \n",
    "                              return_dict_in_generate=True,\n",
    "                              eos_token_id=65505,bos_token_id=65504,pad_token_id=65509)\n",
    "    input_ids = tokenizer.encode(prompt, return_tensors=\"pt\", add_special_tokens=True).to(device)\n",
    "    input_len = input_ids.shape[1]\n",
    "\n",
    "    print(\"=\"*20)\n",
    "    print(\"Prompt: \" + prompt)\n",
    "\n",
    "    outputs = model.generate(input_ids, config, tokenizer=tokenizer, num_steps=32)\n",
    "    print(\"r=32: \" + tokenizer.decode(outputs['sequences'][:, input_len:].squeeze()))\n",
    "\n",
    "    outputs = model.generate(input_ids, config, tokenizer=tokenizer, num_steps=10)\n",
    "    print(\"r=10: \" + tokenizer.decode(outputs['sequences'][:, input_len:].squeeze()))\n",
    "\n",
    "    outputs = model.generate(input_ids, config, tokenizer=tokenizer, num_steps=9)\n",
    "    print(\"r=9: \" + tokenizer.decode(outputs['sequences'][:, input_len:].squeeze()))\n",
    "\n",
    "    outputs = model.generate(input_ids, config, tokenizer=tokenizer, num_steps=8)\n",
    "    print(\"r=8: \" + tokenizer.decode(outputs['sequences'][:, input_len:].squeeze()))\n",
    "\n",
    "    outputs = model.generate(input_ids, config, tokenizer=tokenizer, num_steps=7)\n",
    "    print(\"r=7: \" + tokenizer.decode(outputs['sequences'][:, input_len:].squeeze()))\n",
    "\n",
    "    outputs = model.generate(input_ids, config, tokenizer=tokenizer, num_steps=5)\n",
    "    print(\"r=5: \" + tokenizer.decode(outputs['sequences'][:, input_len:].squeeze()))\n",
    "\n",
    "    outputs = model.generate(input_ids, config, tokenizer=tokenizer, num_steps=4)\n",
    "    print(\"r=4: \" + tokenizer.decode(outputs['sequences'][:, input_len:].squeeze()))\n",
    "\n",
    "    outputs = model.generate(input_ids, config, tokenizer=tokenizer, num_steps=3)\n",
    "    print(\"r=3: \" + tokenizer.decode(outputs['sequences'][:, input_len:].squeeze()))\n",
    "\n",
    "    outputs = model.generate(input_ids, config, tokenizer=tokenizer, num_steps=2)\n",
    "    print(\"r=2: \" + tokenizer.decode(outputs['sequences'][:, input_len:].squeeze()))\n",
    "\n",
    "    outputs = ctrl_model.generate(input_ids, config, tokenizer=tokenizer, num_steps=1)\n",
    "    print(\"Control: \" + tokenizer.decode(outputs['sequences'][:, input_len:].squeeze()))\n",
    "\n",
    "    print(\"=\"*20)\n",
    "\n",
    "def run_prompt_tuple(prompt_tuple):\n",
    "    prompt, country, landmark = prompt_tuple\n",
    "\n",
    "    run_prompt(prompt)\n",
    "    run_prompt(f\"The capital of {country} is \")\n",
    "    run_prompt(f\"{landmark} is located in the country of \")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4443ebb9",
   "metadata": {},
   "source": [
    "# Run individual prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "08c593ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "landmark = \"Munich\"\n",
    "answer = \"Berlin\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "af1fa629",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================\n",
      "Prompt: Q: What is the capital of China? A: Beijing\n",
      "Q: In what country is Mt. Whitney located? A: USA\n",
      "Q: What is the capital of the country where Munich is? A: \n",
      "r=32: ​Munich\n",
      "Q: What is the capital of the country where the Eiffel Tower is? A\n",
      "r=10: ​Munich\n",
      "Q: What is the capital of the country where the city of Buenos A\n",
      "r=9: rom\n",
      "Q: What is the capital of the country where Munich is? A: rom\n",
      "r=8: rom\n",
      "Q: What is the capital of the country where Munich is? A: rom\n",
      "r=7: �\n",
      "Q: What is the capital of the country where Munich is? A: �\n",
      "r=5: ​Munich\n",
      "Q: What is the capital of the country where the Olympic Games are held?\n",
      "r=4: ​Munich\n",
      "Q: What is the capital of the country where the Great Wall of China is\n",
      "r=3: Beijing\n",
      "A: Beijing is the capital of China.\n",
      "Q: What is the capital of\n",
      "r=2: USA\n",
      "A: The capital of China is Beijing.\n",
      "A: China is the capital of China\n",
      "Control: 中国\n",
      "Q: What is the capital of the country where the city of Munich is located\n",
      "====================\n"
     ]
    }
   ],
   "source": [
    "prompt = \"Q: What is the capital of China? A: Beijing\\nQ: In what country is Mt. Whitney located? A: USA\\n\"\n",
    "prompt += f\"Q: What is the capital of the country where {landmark} is? A: \"\n",
    "run_prompt(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "500a760f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================\n",
      "Prompt: Question: Which of the following cities is the capital of the country where Munich is?\n",
      "(A) Berlin\n",
      "(B) Paris\n",
      "\n",
      "Answer: (\n",
      "r=32: A) Berlin\n",
      "\n",
      "Question: Which of the following is the capital of the country where Munich is\n",
      "r=10: B) Paris\n",
      "\n",
      "Question:\n",
      "\n",
      "Which of the following cities is the capital of the country where Mun\n",
      "r=9: B) Paris\n",
      "\n",
      "Question:\n",
      "\n",
      "Which of the following cities is the capital of the country where Mun\n",
      "r=8: B) Paris\n",
      "\n",
      "### Question:\n",
      "\n",
      "Which of the following cities is the capital of the country where\n",
      "r=7: B) Paris\n",
      "Answer: (A) Berlin\n",
      "----\n",
      "Given the following passage\n",
      "\n",
      "\"\n",
      "r=5: C) Munich\n",
      "(D) Paris\n",
      "(E) Berlin\n",
      "Answer: (C)\n",
      "r=4: C) Rome\n",
      "(D) London\n",
      "(E) New York\n",
      "(F) Munich\n",
      "r=3: C) Paris\n",
      "(D) Berlin\n",
      "(E) Berlin\n",
      "(F) Hamburg\n",
      "\n",
      "r=2: A) Berlin\n",
      "(B) Paris\n",
      "(B) Paris\n",
      "(C) Berlin\n",
      "(\n",
      "Control: B) Paris\n",
      "\n",
      "Explanation: Munich is the capital of the country where the city of Munich\n",
      "====================\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"Question: Which of the following cities is the capital of the country where {landmark} is?\\n(A) {answer}\\n(B) Paris\\n\\nAnswer: (\"\n",
    "run_prompt(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b795a7c",
   "metadata": {},
   "source": [
    "# Run Prompt Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "19466d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts = [\n",
    "    [\"The capital of the country where the Eiffel tower is located is \", \"France\", \"Eiffel tower\"],  # ctrl can do this, r=1 can't\n",
    "    [\"The capital of the country where the Big Ben is located is \", \"England\", \"Big Ben\"],  # ctrl and r=1 can't do this\n",
    "    [\"The capital of the country where the Grand Canyon is located is \", \"the United States\", \"Grand Canyon\"],  # no one can do this\n",
    "    [\"Buckingham Palace is located in the country where the capital is \", \"England\", \"Buckingham Palance\"],  # ctrl and r=1 can't do this\n",
    "    [\"The Louvre is located in the country where the capital is \", \"France\", \"The Louvre\"],  # ctrl can do this, r=1 can't\n",
    "    [\"The Great Sphinx of Giza is located in the country where the capital is \", \"Egypt\", \"The Great Sphinx of Giza\"],  # ctrl and r=1 can't do this\n",
    "    [\"Osaka is located in the country where the capital is \", \"Japan\", \"Osaka\"],  # ctrl and r=1 can't do this\n",
    "    [\"Munich is located in the country where the capital is \", \"Germany\", \"Munich\"],  # ctrl and r=1 can't do this\n",
    "    [\"Toronto is located in the country where the capital is \", \"Canada\", \"Toronto\"],  # ctrl can do this, r=1 can't\n",
    "    [\"Valencia is located in the country where the capital is \", \"Spain\", \"Valencia\"],  # ctrl can do this, r=1 can't\n",
    "    [\"Granada is located in the country where the capital is \", \"Spain\", \"Granada\"],  #\n",
    "    [\"Milan is located in the country where the capital is \", \"Italy\", \"Milan\"],  # ctrl can do this, r=1 can't\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e9ae918e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_prompt(prompt):\n",
    "    config = GenerationConfig(max_length=20, stop_strings=[\"<|end_text|>\", \"<|end_turn|>\"], \n",
    "                              use_cache=True,\n",
    "                              do_sample=False, temperature=None, top_k=None, top_p=None, min_p=None, \n",
    "                              return_dict_in_generate=True,\n",
    "                              eos_token_id=65505,bos_token_id=65504,pad_token_id=65509)\n",
    "    input_ids = tokenizer.encode(prompt, return_tensors=\"pt\", add_special_tokens=True).to(device)\n",
    "\n",
    "    print(\"=\"*20)\n",
    "    print(f\"Prompt: {prompt}\")\n",
    "\n",
    "    outputs = model.generate(input_ids, config, tokenizer=tokenizer, num_steps=32)\n",
    "    print(\"r=32: \" + tokenizer.decode(outputs['sequences'].squeeze()))\n",
    "\n",
    "    outputs = model.generate(input_ids, config, tokenizer=tokenizer, num_steps=10)\n",
    "    print(\"r=10: \" + tokenizer.decode(outputs['sequences'].squeeze()))\n",
    "\n",
    "    outputs = model.generate(input_ids, config, tokenizer=tokenizer, num_steps=9)\n",
    "    print(\"r=9: \" + tokenizer.decode(outputs['sequences'].squeeze()))\n",
    "\n",
    "    outputs = model.generate(input_ids, config, tokenizer=tokenizer, num_steps=8)\n",
    "    print(\"r=8: \" + tokenizer.decode(outputs['sequences'].squeeze()))\n",
    "\n",
    "    outputs = model.generate(input_ids, config, tokenizer=tokenizer, num_steps=7)\n",
    "    print(\"r=7: \" + tokenizer.decode(outputs['sequences'].squeeze()))\n",
    "\n",
    "    outputs = model.generate(input_ids, config, tokenizer=tokenizer, num_steps=5)\n",
    "    print(\"r=5: \" + tokenizer.decode(outputs['sequences'].squeeze()))\n",
    "    \n",
    "    outputs = model.generate(input_ids, config, tokenizer=tokenizer, num_steps=4)\n",
    "    print(\"r=4: \" + tokenizer.decode(outputs['sequences'].squeeze()))\n",
    "\n",
    "    outputs = model.generate(input_ids, config, tokenizer=tokenizer, num_steps=3)\n",
    "    print(\"r=3: \" + tokenizer.decode(outputs['sequences'].squeeze()))\n",
    "\n",
    "    outputs = model.generate(input_ids, config, tokenizer=tokenizer, num_steps=2)\n",
    "    print(\"r=2: \" + tokenizer.decode(outputs['sequences'].squeeze()))\n",
    "\n",
    "    outputs = ctrl_model.generate(input_ids, config, tokenizer=tokenizer, num_steps=1)\n",
    "    print(\"Control: \" + tokenizer.decode(outputs['sequences'].squeeze()))\n",
    "\n",
    "    print(\"=\"*20)\n",
    "\n",
    "def run_prompt_tuple(prompt_tuple):\n",
    "    prompt, country, landmark = prompt_tuple\n",
    "\n",
    "    run_prompt(prompt)\n",
    "    run_prompt(f\"The capital of {country} is \")\n",
    "    run_prompt(f\"{landmark} is located in the country of \")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d75248cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================\n",
      "Prompt: Question: Which of the following cities is the capital of the country where the Big Ben is?\n",
      "(A) London\n",
      "(B) Paris\n",
      "\n",
      "Answer: (\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "property 'key_cache' of 'HuginnDynamicCache' object has no setter",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      2\u001b[39m prompt += \u001b[33m\"\u001b[39m\u001b[33mQ: What is the capital of the country where the Big Ben is? A: \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      3\u001b[39m prompt = \u001b[33m\"\u001b[39m\u001b[33mQuestion: Which of the following cities is the capital of the country where the Big Ben is?\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m(A) London\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m(B) Paris\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mAnswer: (\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m \u001b[43mrun_prompt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 12\u001b[39m, in \u001b[36mrun_prompt\u001b[39m\u001b[34m(prompt)\u001b[39m\n\u001b[32m      9\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m=\u001b[39m\u001b[33m\"\u001b[39m*\u001b[32m20\u001b[39m)\n\u001b[32m     10\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mPrompt: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprompt\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m outputs = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_steps\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m32\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     13\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mr=32: \u001b[39m\u001b[33m\"\u001b[39m + tokenizer.decode(outputs[\u001b[33m'\u001b[39m\u001b[33msequences\u001b[39m\u001b[33m'\u001b[39m].squeeze()))\n\u001b[32m     15\u001b[39m outputs = model.generate(input_ids, config, tokenizer=tokenizer, num_steps=\u001b[32m10\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/py3.11/lib/python3.11/site-packages/torch/utils/_contextlib.py:116\u001b[39m, in \u001b[36mcontext_decorator.<locals>.decorate_context\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    113\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(func)\n\u001b[32m    114\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecorate_context\u001b[39m(*args, **kwargs):\n\u001b[32m    115\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[32m--> \u001b[39m\u001b[32m116\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.cache/huggingface/modules/transformers_modules/tomg-group-umd/huginn-0125/06ac94c44654ab4cb8d8c57c4e5c2463a29bd3fa/raven_modeling_minimal.py:1120\u001b[39m, in \u001b[36mRavenForCausalLM.generate\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1118\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.generate_minimal(*args, **kwargs)\n\u001b[32m   1119\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1120\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/py3.11/lib/python3.11/site-packages/torch/utils/_contextlib.py:116\u001b[39m, in \u001b[36mcontext_decorator.<locals>.decorate_context\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    113\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(func)\n\u001b[32m    114\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecorate_context\u001b[39m(*args, **kwargs):\n\u001b[32m    115\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[32m--> \u001b[39m\u001b[32m116\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/py3.11/lib/python3.11/site-packages/transformers/generation/utils.py:2633\u001b[39m, in \u001b[36mGenerationMixin.generate\u001b[39m\u001b[34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, use_model_defaults, custom_generate, **kwargs)\u001b[39m\n\u001b[32m   2625\u001b[39m     input_ids, model_kwargs = \u001b[38;5;28mself\u001b[39m._expand_inputs_for_generation(\n\u001b[32m   2626\u001b[39m         input_ids=input_ids,\n\u001b[32m   2627\u001b[39m         expand_size=generation_config.num_return_sequences,\n\u001b[32m   2628\u001b[39m         is_encoder_decoder=\u001b[38;5;28mself\u001b[39m.config.is_encoder_decoder,\n\u001b[32m   2629\u001b[39m         **model_kwargs,\n\u001b[32m   2630\u001b[39m     )\n\u001b[32m   2632\u001b[39m     \u001b[38;5;66;03m# 12. run sample (it degenerates to greedy search when `generation_config.do_sample=False`)\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2633\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sample\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2634\u001b[39m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2635\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlogits_processor\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprepared_logits_processor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2636\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstopping_criteria\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprepared_stopping_criteria\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2637\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2638\u001b[39m \u001b[43m        \u001b[49m\u001b[43msynced_gpus\u001b[49m\u001b[43m=\u001b[49m\u001b[43msynced_gpus\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2639\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstreamer\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstreamer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2640\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2641\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2643\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m generation_mode \u001b[38;5;129;01min\u001b[39;00m (GenerationMode.BEAM_SAMPLE, GenerationMode.BEAM_SEARCH):\n\u001b[32m   2644\u001b[39m     \u001b[38;5;66;03m# 11. interleave input_ids with `num_beams` additional sequences per batch\u001b[39;00m\n\u001b[32m   2645\u001b[39m     input_ids, model_kwargs = \u001b[38;5;28mself\u001b[39m._expand_inputs_for_generation(\n\u001b[32m   2646\u001b[39m         input_ids=input_ids,\n\u001b[32m   2647\u001b[39m         expand_size=generation_config.num_beams,\n\u001b[32m   2648\u001b[39m         is_encoder_decoder=\u001b[38;5;28mself\u001b[39m.config.is_encoder_decoder,\n\u001b[32m   2649\u001b[39m         **model_kwargs,\n\u001b[32m   2650\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/py3.11/lib/python3.11/site-packages/transformers/generation/utils.py:3607\u001b[39m, in \u001b[36mGenerationMixin._sample\u001b[39m\u001b[34m(self, input_ids, logits_processor, stopping_criteria, generation_config, synced_gpus, streamer, **model_kwargs)\u001b[39m\n\u001b[32m   3603\u001b[39m     is_prefill = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m   3605\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m._has_unfinished_sequences(this_peer_finished, synced_gpus, device=input_ids.device):\n\u001b[32m   3606\u001b[39m     \u001b[38;5;66;03m# prepare model inputs\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m3607\u001b[39m     model_inputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mprepare_inputs_for_generation\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3609\u001b[39m     \u001b[38;5;66;03m# prepare variable output controls (note: some models won't accept all output controls)\u001b[39;00m\n\u001b[32m   3610\u001b[39m     model_inputs.update({\u001b[33m\"\u001b[39m\u001b[33moutput_attentions\u001b[39m\u001b[33m\"\u001b[39m: output_attentions} \u001b[38;5;28;01mif\u001b[39;00m output_attentions \u001b[38;5;28;01melse\u001b[39;00m {})\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.cache/huggingface/modules/transformers_modules/tomg-group-umd/huginn-0125/06ac94c44654ab4cb8d8c57c4e5c2463a29bd3fa/raven_modeling_minimal.py:1092\u001b[39m, in \u001b[36mRavenForCausalLM.prepare_inputs_for_generation\u001b[39m\u001b[34m(self, input_ids, past_key_values, attention_mask, inputs_embeds, cache_position, cache_lookup_strategy, **kwargs)\u001b[39m\n\u001b[32m   1082\u001b[39m         past_key_values = HuginnStaticCache(\n\u001b[32m   1083\u001b[39m             max_length=\u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m.generation_config, \u001b[33m\"\u001b[39m\u001b[33mmax_length\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m.config.block_size),\n\u001b[32m   1084\u001b[39m             max_num_steps=\u001b[32m4\u001b[39m + kwargs.get(\u001b[33m\"\u001b[39m\u001b[33mnum_steps\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m.config.mean_recurrence) * \u001b[32m4\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1089\u001b[39m             lookup_strategy=cache_lookup_strategy,\n\u001b[32m   1090\u001b[39m         )\n\u001b[32m   1091\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1092\u001b[39m         past_key_values = \u001b[43mHuginnDynamicCache\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlookup_strategy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_lookup_strategy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1093\u001b[39m model_inputs[\u001b[33m\"\u001b[39m\u001b[33mpast_key_values\u001b[39m\u001b[33m\"\u001b[39m] = past_key_values \u001b[38;5;28;01mif\u001b[39;00m kwargs[\u001b[33m\"\u001b[39m\u001b[33muse_cache\u001b[39m\u001b[33m\"\u001b[39m] \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1094\u001b[39m input_ids = input_ids[:, cache_position]  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.cache/huggingface/modules/transformers_modules/tomg-group-umd/huginn-0125/06ac94c44654ab4cb8d8c57c4e5c2463a29bd3fa/raven_modeling_minimal.py:151\u001b[39m, in \u001b[36mHuginnDynamicCache.__init__\u001b[39m\u001b[34m(self, lookup_strategy)\u001b[39m\n\u001b[32m    149\u001b[39m \u001b[38;5;28msuper\u001b[39m().\u001b[34m__init__\u001b[39m()\n\u001b[32m    150\u001b[39m \u001b[38;5;28mself\u001b[39m._seen_tokens = \u001b[32m0\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m151\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mkey_cache\u001b[49m: \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mint\u001b[39m, \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mint\u001b[39m, torch.Tensor]] = {}\n\u001b[32m    152\u001b[39m \u001b[38;5;28mself\u001b[39m.value_cache: \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mint\u001b[39m, \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mint\u001b[39m, torch.Tensor]] = {}\n\u001b[32m    153\u001b[39m \u001b[38;5;66;03m# structure: cache[index_of_layer_or_recurrent_step][index_in_sequence]\u001b[39;00m\n\u001b[32m    154\u001b[39m \u001b[38;5;66;03m# the cache is held uncoalesced because certain recurrent steps may be missing for some sequence ids if using\u001b[39;00m\n\u001b[32m    155\u001b[39m \u001b[38;5;66;03m# per-token adaptive compute. In those cases, the \"lookup_strategy\" determines how to proceed\u001b[39;00m\n\u001b[32m    156\u001b[39m \u001b[38;5;66;03m# Also, It is critical that the head indices do not overlap with the recurrent iteration indices\u001b[39;00m\n",
      "\u001b[31mAttributeError\u001b[39m: property 'key_cache' of 'HuginnDynamicCache' object has no setter"
     ]
    }
   ],
   "source": [
    "prompt = \"Q: What is the capital of China? A: Beijing\\nQ: In what country is Mt. Whitney located? A: USA\\n\"\n",
    "prompt += \"Q: What is the capital of the country where the Big Ben is? A: \"\n",
    "prompt = \"Question: Which of the following cities is the capital of the country where the Big Ben is?\\n(A) London\\n(B) Paris\\n\\nAnswer: (\"\n",
    "run_prompt(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cc918258",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================\n",
      "Prompt: Giza is located in the country where the capital is \n",
      "r=32: <|begin_text|>Giza is located in the country where the capital is ​Cairo. The city is located on the west bank of the Nile River, about 10\n",
      "r=10: <|begin_text|>Giza is located in the country where the capital is ​Cairo. The city is located on the west bank of the Nile River, on the border\n",
      "r=9: <|begin_text|>Giza is located in the country where the capital is ​Cairo. The city is located on the west bank of the Nile River, which is the\n",
      "r=8: <|begin_text|>Giza is located in the country where the capital is ​Cairo. The city is located on the west bank of the Nile River, which is the\n",
      "r=7: <|begin_text|>Giza is located in the country where the capital is ​Cairo. The city is located on the banks of the Nile River, which is the longest\n",
      "r=5: <|begin_text|>Giza is located in the country where the capital is ​the city of Cairo. The city is located in the Nile Delta, and is the largest\n",
      "r=4: <|begin_text|>Giza is located in the country where the capital is ​Giza, Egypt. The city is located in the northern part of the country, and it\n",
      "r=3: <|begin_text|>Giza is located in the country where the capital is ​Giza, the largest city in the world.\n",
      "The city is located in the north-\n",
      "r=2: <|begin_text|>Giza is located in the country where the capital is ʻGiza. The city is located in the center of the city of Giza. The\n",
      "Control: <|begin_text|>Giza is located in the country where the capital is ​Giza. It is the largest city in the world and the largest city in the Middle East\n",
      "====================\n",
      "====================\n",
      "Prompt: The capital of Egypt is \n",
      "r=32: <|begin_text|>The capital of Egypt is ​Cairo. The city is located in the northeast of the country, on the banks of the\n",
      "r=10: <|begin_text|>The capital of Egypt is ​Cairo, which is located in the northeast of the country. The city is located on the\n",
      "r=9: <|begin_text|>The capital of Egypt is ʿAkkān.\n",
      "The capital of Egypt is ʿAkkān\n",
      "r=8: <|begin_text|>The capital of Egypt is ʿAṯāḥā, or Aṯā�\n",
      "r=7: <|begin_text|>The capital of Egypt is ʿAṣrāʾ, which is pronounced as ʿA�\n",
      "r=5: <|begin_text|>The capital of Egypt is ʿAḥmadīnī, which is pronounced as Aḥmad\n",
      "r=4: <|begin_text|>The capital of Egypt is ˈEgyptˈ.\n",
      "The country is a country in the Middle East, with\n",
      "r=3: <|begin_text|>The capital of Egypt is ˈMeghāl-Egypāl, which is located in the northeast\n",
      "r=2: <|begin_text|>The capital of Egypt is ˈEgypt. The capital is located in the city of Alexandria, in the city\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mrun_prompt_tuple\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mGiza is located in the country where the capital is \u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mEgypt\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mGiza\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 48\u001b[39m, in \u001b[36mrun_prompt_tuple\u001b[39m\u001b[34m(prompt_tuple)\u001b[39m\n\u001b[32m     45\u001b[39m prompt, country, landmark = prompt_tuple\n\u001b[32m     47\u001b[39m run_prompt(prompt)\n\u001b[32m---> \u001b[39m\u001b[32m48\u001b[39m \u001b[43mrun_prompt\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mThe capital of \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mcountry\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m is \u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     49\u001b[39m run_prompt(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlandmark\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m is located in the country of \u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 39\u001b[39m, in \u001b[36mrun_prompt\u001b[39m\u001b[34m(prompt)\u001b[39m\n\u001b[32m     36\u001b[39m outputs = model.generate(input_ids, config, tokenizer=tokenizer, num_steps=\u001b[32m2\u001b[39m)\n\u001b[32m     37\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mr=2: \u001b[39m\u001b[33m\"\u001b[39m + tokenizer.decode(outputs[\u001b[33m'\u001b[39m\u001b[33msequences\u001b[39m\u001b[33m'\u001b[39m].squeeze()))\n\u001b[32m---> \u001b[39m\u001b[32m39\u001b[39m outputs = \u001b[43mctrl_model\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_steps\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     40\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mControl: \u001b[39m\u001b[33m\"\u001b[39m + tokenizer.decode(outputs[\u001b[33m'\u001b[39m\u001b[33msequences\u001b[39m\u001b[33m'\u001b[39m].squeeze()))\n\u001b[32m     42\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m=\u001b[39m\u001b[33m\"\u001b[39m*\u001b[32m20\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/py3.11/lib/python3.11/site-packages/torch/utils/_contextlib.py:116\u001b[39m, in \u001b[36mcontext_decorator.<locals>.decorate_context\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    113\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(func)\n\u001b[32m    114\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecorate_context\u001b[39m(*args, **kwargs):\n\u001b[32m    115\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[32m--> \u001b[39m\u001b[32m116\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.cache/huggingface/modules/transformers_modules/tomg-group-umd/step-00010720-baseline_2_0/8d9c4dc277253b9ae1c0309c29d46aa5a2aa2a05/raven_modeling_minimal.py:1120\u001b[39m, in \u001b[36mRavenForCausalLM.generate\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1118\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.generate_minimal(*args, **kwargs)\n\u001b[32m   1119\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1120\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/py3.11/lib/python3.11/site-packages/torch/utils/_contextlib.py:116\u001b[39m, in \u001b[36mcontext_decorator.<locals>.decorate_context\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    113\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(func)\n\u001b[32m    114\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecorate_context\u001b[39m(*args, **kwargs):\n\u001b[32m    115\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[32m--> \u001b[39m\u001b[32m116\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/py3.11/lib/python3.11/site-packages/transformers/generation/utils.py:2519\u001b[39m, in \u001b[36mGenerationMixin.generate\u001b[39m\u001b[34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, use_model_defaults, custom_generate, **kwargs)\u001b[39m\n\u001b[32m   2507\u001b[39m \u001b[38;5;66;03m# 9. prepare logits processors and stopping criteria\u001b[39;00m\n\u001b[32m   2508\u001b[39m prepared_logits_processor = \u001b[38;5;28mself\u001b[39m._get_logits_processor(\n\u001b[32m   2509\u001b[39m     generation_config=generation_config,\n\u001b[32m   2510\u001b[39m     input_ids_seq_length=input_ids_length,\n\u001b[32m   (...)\u001b[39m\u001b[32m   2517\u001b[39m     negative_prompt_attention_mask=negative_prompt_attention_mask,\n\u001b[32m   2518\u001b[39m )\n\u001b[32m-> \u001b[39m\u001b[32m2519\u001b[39m prepared_stopping_criteria = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_stopping_criteria\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2520\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstopping_criteria\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstopping_criteria\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m   2521\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2523\u001b[39m \u001b[38;5;66;03m# Set model_kwargs `use_cache` so we can use it later in forward runs\u001b[39;00m\n\u001b[32m   2524\u001b[39m model_kwargs[\u001b[33m\"\u001b[39m\u001b[33muse_cache\u001b[39m\u001b[33m\"\u001b[39m] = generation_config.use_cache\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/py3.11/lib/python3.11/site-packages/transformers/generation/utils.py:1354\u001b[39m, in \u001b[36mGenerationMixin._get_stopping_criteria\u001b[39m\u001b[34m(self, generation_config, stopping_criteria, tokenizer, **kwargs)\u001b[39m\n\u001b[32m   1348\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m tokenizer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1349\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1350\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mThere are one or more stop strings, either in the arguments to `generate` or in the \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1351\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m'\u001b[39m\u001b[33ms generation config, but we could not locate a tokenizer. When generating with \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1352\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mstop strings, you must pass the model\u001b[39m\u001b[33m'\u001b[39m\u001b[33ms tokenizer to the `tokenizer` argument of `generate`.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1353\u001b[39m         )\n\u001b[32m-> \u001b[39m\u001b[32m1354\u001b[39m     criteria.append(\u001b[43mStopStringCriteria\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstop_strings\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstop_strings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m   1355\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m generation_config._eos_token_tensor \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1356\u001b[39m     criteria.append(EosTokenCriteria(eos_token_id=generation_config._eos_token_tensor))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/py3.11/lib/python3.11/site-packages/transformers/generation/stopping_criteria.py:248\u001b[39m, in \u001b[36mStopStringCriteria.__init__\u001b[39m\u001b[34m(self, tokenizer, stop_strings)\u001b[39m\n\u001b[32m    246\u001b[39m vocab = tokenizer.get_vocab()\n\u001b[32m    247\u001b[39m token_list, token_indices = \u001b[38;5;28mtuple\u001b[39m(vocab.keys()), \u001b[38;5;28mtuple\u001b[39m(vocab.values())\n\u001b[32m--> \u001b[39m\u001b[32m248\u001b[39m \u001b[38;5;28mself\u001b[39m.embedding_vec, \u001b[38;5;28mself\u001b[39m.max_valid_positions, \u001b[38;5;28mself\u001b[39m.max_valid_end_lens = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mclean_and_embed_tokens_with_cache\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    249\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtoken_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtoken_indices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtokenizer\u001b[49m\n\u001b[32m    250\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    252\u001b[39m \u001b[38;5;28mself\u001b[39m.maximum_token_len = \u001b[38;5;28mmax\u001b[39m([\u001b[38;5;28mlen\u001b[39m(stop_string) \u001b[38;5;28;01mfor\u001b[39;00m stop_string \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.stop_strings])\n\u001b[32m    253\u001b[39m \u001b[38;5;28mself\u001b[39m.num_stop_strings = \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m.stop_strings)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/py3.11/lib/python3.11/site-packages/transformers/generation/stopping_criteria.py:265\u001b[39m, in \u001b[36mStopStringCriteria.clean_and_embed_tokens_with_cache\u001b[39m\u001b[34m(self, token_list, token_indices, tokenizer)\u001b[39m\n\u001b[32m    263\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    264\u001b[39m     clean_token_list, clean_token_indices = \u001b[38;5;28mself\u001b[39m.clean_tokenizer_vocab(tokenizer)\n\u001b[32m--> \u001b[39m\u001b[32m265\u001b[39m     embedding_vec, max_valid_positions, max_valid_end_lens = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_stop_string_create_embedding_vec\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    266\u001b[39m \u001b[43m        \u001b[49m\u001b[43mclean_token_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclean_token_indices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstop_strings\u001b[49m\n\u001b[32m    267\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    268\u001b[39m     STOP_STRING_EMBEDDING_CACHE[(token_list, token_indices, \u001b[38;5;28mself\u001b[39m.stop_strings)] = (\n\u001b[32m    269\u001b[39m         embedding_vec,\n\u001b[32m    270\u001b[39m         max_valid_positions,\n\u001b[32m    271\u001b[39m         max_valid_end_lens,\n\u001b[32m    272\u001b[39m     )\n\u001b[32m    273\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(STOP_STRING_EMBEDDING_CACHE) > \u001b[32m8\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/py3.11/lib/python3.11/site-packages/transformers/generation/stopping_criteria.py:344\u001b[39m, in \u001b[36mStopStringCriteria._stop_string_create_embedding_vec\u001b[39m\u001b[34m(token_list, token_indices, stop_strings)\u001b[39m\n\u001b[32m    339\u001b[39m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[32m    340\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_stop_string_create_embedding_vec\u001b[39m(token_list, token_indices, stop_strings) -> \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, torch.tensor]:\n\u001b[32m    341\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"This function precomputes everything needed for the run-time checks in StopStringCriteria, and packs\u001b[39;00m\n\u001b[32m    342\u001b[39m \u001b[33;03m    them into an embedding tensor that can be accessed with pure tensor operations. For the specifics of the values\u001b[39;00m\n\u001b[32m    343\u001b[39m \u001b[33;03m    that are precomputed and what they are used for, please refer to the StopStringCriteria docstring!\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m344\u001b[39m     token_valid_positions, token_end_overlaps = \u001b[43mStopStringCriteria\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_stop_string_get_matching_positions\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    345\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtoken_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtoken_indices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop_strings\u001b[49m\n\u001b[32m    346\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    347\u001b[39m     all_valid_positions = [\u001b[38;5;28mlen\u001b[39m(val) \u001b[38;5;28;01mfor\u001b[39;00m positions \u001b[38;5;129;01min\u001b[39;00m token_valid_positions.values() \u001b[38;5;28;01mfor\u001b[39;00m val \u001b[38;5;129;01min\u001b[39;00m positions.values()]\n\u001b[32m    348\u001b[39m     \u001b[38;5;66;03m# In some cases, tokens may have no valid internal positions (such as single-character stop strings), so\u001b[39;00m\n\u001b[32m    349\u001b[39m     \u001b[38;5;66;03m# we need a fallback to handle this case\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/py3.11/lib/python3.11/site-packages/transformers/generation/stopping_criteria.py:327\u001b[39m, in \u001b[36mStopStringCriteria._stop_string_get_matching_positions\u001b[39m\u001b[34m(token_list, token_indices, stop_strings)\u001b[39m\n\u001b[32m    325\u001b[39m     tok = reversed_token\n\u001b[32m    326\u001b[39m stop = reversed_stop_string[i : i + \u001b[38;5;28mlen\u001b[39m(tok)]\n\u001b[32m--> \u001b[39m\u001b[32m327\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mtok\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstartswith\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[32m    328\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m i == \u001b[32m0\u001b[39m:\n\u001b[32m    329\u001b[39m         possible_end_lengths.append(\u001b[38;5;28mmin\u001b[39m(\u001b[38;5;28mlen\u001b[39m(tok), \u001b[38;5;28mlen\u001b[39m(stop)))\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "run_prompt_tuple([\"Giza is located in the country where the capital is \", \"Egypt\", \"Giza\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a07e24c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================\n",
      "Prompt: The capital of the country where the Eiffel tower is located is \n",
      "r=42: <|begin_text|>The capital of the country where the Eiffel tower is located is ​Paris. The Eiffel tower is a symbol of Paris. The Eiffel tower is a symbol of Paris\n",
      "r=32: <|begin_text|>The capital of the country where the Eiffel tower is located is ​Paris. The Eiffel tower is a symbol of Paris. The Eiffel tower is a symbol of Paris\n",
      "r=10: <|begin_text|>The capital of the country where the Eiffel tower is located is ​Paris. The Eiffel tower is a symbol of Paris and the whole of France. The Eiffel tower\n",
      "r=7: <|begin_text|>The capital of the country where the Eiffel tower is located is ​Paris. The Eiffel tower is a symbol of Paris and is one of the most famous monuments\n",
      "r=5: <|begin_text|>The capital of the country where the Eiffel tower is located is rue de la Chambre de l’Etoile.\n",
      "The Eiffel Tower is a symbol of\n",
      "r=4: <|begin_text|>The capital of the country where the Eiffel tower is located is rue de la Chambre de la Couronne.\n",
      "The Eiffel tower is a monument of the\n",
      "r=3: <|begin_text|>The capital of the country where the Eiffel tower is located is rue de la Seine, in the middle of the city of Paris.\n",
      "The Eiffel tower is\n",
      "r=2: <|begin_text|>The capital of the country where the Eiffel tower is located is ​the capital of the country.\n",
      "The Eiffel Tower is located in Paris, France.\n",
      "The\n",
      "Control: <|begin_text|>The capital of the country where the Eiffel tower is located is ​the city of Paris. The city of Paris is the capital of France. The city of Paris\n",
      "====================\n",
      "====================\n",
      "Prompt: The capital of France is \n",
      "r=42: <|begin_text|>The capital of France is ​Paris. It is located in the north-east of the country, in the Île\n",
      "r=32: <|begin_text|>The capital of France is ​Paris. It is located in the north-east of the country, on the banks of the\n",
      "r=10: <|begin_text|>The capital of France is ​Paris. The city is located in the north of the country, on the banks of the river\n",
      "r=7: <|begin_text|>The capital of France is rue de la Concorde, Paris.\n",
      "The capital of France is rue de la Con\n",
      "r=5: <|begin_text|>The capital of France is rue de la Chaussée-du-Haute-Provence. It is located in\n",
      "r=4: <|begin_text|>The capital of France is rue de Paris. The city is located in the Île-de-France region, in\n",
      "r=3: <|begin_text|>The capital of France is ​the largest city in the world. It is located in the centre of Paris, and is the\n",
      "r=2: <|begin_text|>The capital of France is ˈ2001-2002-1002-100\n",
      "Control: <|begin_text|>The capital of France is rue de la République, which is the largest city in the country. It is the\n",
      "====================\n",
      "====================\n",
      "Prompt: Eiffel tower is located in the country of \n",
      "r=42: <|begin_text|>Eiffel tower is located in the country of ​France. The Eiffel Tower is a wrought iron lattice tower on the Champ de Mars in Paris\n",
      "r=32: <|begin_text|>Eiffel tower is located in the country of ​France. The Eiffel Tower is a wrought iron lattice tower on the Champ de Mars in Paris\n",
      "r=10: <|begin_text|>Eiffel tower is located in the country of ​France. The Eiffel Tower was built in 1889. The Eiffel Tower is a tower\n",
      "r=7: <|begin_text|>Eiffel tower is located in the country of ​France. The Eiffel Tower is a tower of the same name. The Eiffel Tower is a tower\n",
      "r=5: <|begin_text|>Eiffel tower is located in the country of ​France. It is located in the city of Paris. Eiffel Tower is a monument that was\n",
      "r=4: <|begin_text|>Eiffel tower is located in the country of ​France. It is located in the city of Paris. The Eiffel Tower is a symbol of the\n",
      "r=3: <|begin_text|>Eiffel tower is located in the country of ​the capital of the state of New York. The Eiffel tower is a monument of the\n",
      "r=2: <|begin_text|>Eiffel tower is located in the country of elliot.....\n",
      "The official name of the city is Eiffel...\n",
      "Control: <|begin_text|>Eiffel tower is located in the country of ​France. It is a symbol of the city of ​France. It is a symbol of\n",
      "====================\n",
      "====================\n",
      "Prompt: The capital of the country where the Big Ben is located is \n",
      "r=42: <|begin_text|>The capital of the country where the Big Ben is located is ​London. The name of the city is associated with the name of the river Thames. The\n",
      "r=32: <|begin_text|>The capital of the country where the Big Ben is located is ​London. The name of the city is associated with the name of the river Thames. The\n",
      "r=10: <|begin_text|>The capital of the country where the Big Ben is located is ​London. The name of the city is derived from the Old English word \"Londinium\"\n",
      "r=7: <|begin_text|>The capital of the country where the Big Ben is located is ​London. The city is the largest in the UK and the most important financial center in Europe.\n",
      "r=5: <|begin_text|>The capital of the country where the Big Ben is located is ​Benin.\n",
      "The capital of the country where the Big Ben is located is Benin.\n",
      "r=4: <|begin_text|>The capital of the country where the Big Ben is located is ​Benelux.\n",
      "The city of Benelux is located in the north-east of\n",
      "r=3: <|begin_text|>The capital of the country where the Big Ben is located is � the city of Benin.\n",
      "The city is located in the north-eastern part of\n",
      "r=2: <|begin_text|>The capital of the country where the Big Ben is located is ​in the heart of the capital of the country. The capital of the country is ​in\n",
      "Control: <|begin_text|>The capital of the country where the Big Ben is located is ​the city of ​the same name as the city of ​the country of ​\n",
      "====================\n",
      "====================\n",
      "Prompt: The capital of England is \n",
      "r=42: <|begin_text|>The capital of England is ​London, which is located in the southeast of the country. The city is located on the banks\n",
      "r=32: <|begin_text|>The capital of England is ​London, which is located in the south-east of the country. The city is located on\n",
      "r=10: <|begin_text|>The capital of England is ​London. The city is located in the south-east of the country, on the Thames\n",
      "r=7: <|begin_text|>The capital of England is ​London. It is the largest city in the United Kingdom and the most populous city in the European\n",
      "r=5: <|begin_text|>The capital of England is ​London.\n",
      "The capital of England is ​London.\n",
      "The capital of England is \n",
      "r=4: <|begin_text|>The capital of England is erything like the United States. It is a city with a population of 2.5 million people\n",
      "r=3: <|begin_text|>The capital of England is ˈCathedral City of London.\n",
      "The city is the home of the government of the\n",
      "r=2: <|begin_text|>The capital of England is ˈHugh. The capital of England is ˈHugh. The capital of England\n",
      "Control: <|begin_text|>The capital of England is ​the ​capital of Wales.\n",
      "The ​capital of Wales is Wales.\n",
      "The\n",
      "====================\n",
      "====================\n",
      "Prompt: Big Ben is located in the country of \n",
      "r=42: <|begin_text|>Big Ben is located in the country of ​England.\n",
      "Big Ben is a famous landmark in the country of ​England.\n",
      "r=32: <|begin_text|>Big Ben is located in the country of ​England.\n",
      "The Big Ben is a famous landmark in the country of ​England\n",
      "r=10: <|begin_text|>Big Ben is located in the country of ​England. The name of the clock is derived from the name of the famous British Prime Minister\n",
      "r=7: <|begin_text|>Big Ben is located in the country of ​England. The capital of ​England is London.\n",
      "The official language of \n",
      "r=5: <|begin_text|>Big Ben is located in the country of ​England. The capital of England is London. The country of ​England is located\n",
      "r=4: <|begin_text|>Big Ben is located in the country of ​England. The name of the city is ​Big Ben. The city is located in\n",
      "r=3: <|begin_text|>Big Ben is located in the country of ​the United States.\n",
      "Big Ben is a city in the state of New York.\n",
      "Big\n",
      "r=2: <|begin_text|>Big Ben is located in the country of erstat. The country is located in the middle of the ocean, and has a population of about\n",
      "Control: <|begin_text|>Big Ben is located in the country of ​the United States of America. It is a large city with a population of over 10 million\n",
      "====================\n",
      "====================\n",
      "Prompt: The capital of the country where the Grand Canyon is located is \n",
      "r=42: <|begin_text|>The capital of the country where the Grand Canyon is located is ​Arizona. The state is located in the southwestern part of the United States. The state\n",
      "r=32: <|begin_text|>The capital of the country where the Grand Canyon is located is ​Arizona. The state is located in the southwestern part of the United States. The state\n",
      "r=10: <|begin_text|>The capital of the country where the Grand Canyon is located is ​Arizona. The state is located in the southwestern region of the United States. The state\n",
      "r=7: <|begin_text|>The capital of the country where the Grand Canyon is located is �Arizona�. The state is home to the Grand Canyon, which is a natural wonder\n",
      "r=5: <|begin_text|>The capital of the country where the Grand Canyon is located is ʻAṣṣānta.\n",
      "The name of the city is\n",
      "r=4: <|begin_text|>The capital of the country where the Grand Canyon is located is �Canyon City, Arizona. The Grand Canyon is a popular tourist destination, and many people\n",
      "r=3: <|begin_text|>The capital of the country where the Grand Canyon is located is ​the largest city in the world. The city is located in the state of Arizona, and is\n",
      "r=2: <|begin_text|>The capital of the country where the Grand Canyon is located is ˈa b c oˈn ˈe t h a t eˈ\n",
      "Control: <|begin_text|>The capital of the country where the Grand Canyon is located is ​the Grand Canyon National Park. The park is located in the state of Arizona in the United\n",
      "====================\n",
      "====================\n",
      "Prompt: The capital of the United States is \n",
      "r=42: <|begin_text|>The capital of the United States is ​the city of Washington, D.C., which is located in the state of Virginia.\n",
      "r=32: <|begin_text|>The capital of the United States is ​the city of Washington, D.C., which is located in the state of Virginia.\n",
      "r=10: <|begin_text|>The capital of the United States is ​the city of Washington, D.C., which is located in the state of Virginia.\n",
      "r=7: <|begin_text|>The capital of the United States is ​the city of Washington, D.C., which is located in the state of Virginia.\n",
      "r=5: <|begin_text|>The capital of the United States is �The United States of America.� The United States is a federal republic consisting of 50 states\n",
      "r=4: <|begin_text|>The capital of the United States is ​New York.\n",
      "The city is located in the state of New York, in the United States\n",
      "r=3: <|begin_text|>The capital of the United States is ˈCinético. It is the largest city in the world, and the most\n",
      "r=2: <|begin_text|>The capital of the United States is ​the largest state in the world. The United States is the world's largest state in the world.\n",
      "Control: <|begin_text|>The capital of the United States is ​the state of New York. The state capital is New York City. The state capital is New\n",
      "====================\n",
      "====================\n",
      "Prompt: Grand Canyon is located in the country of \n",
      "r=42: <|begin_text|>Grand Canyon is located in the country of ​Arizona, United States. The Grand Canyon is a canyon in the Colorado River in\n",
      "r=32: <|begin_text|>Grand Canyon is located in the country of ​Arizona, United States. The Grand Canyon is a canyon in the Colorado River in\n",
      "r=10: <|begin_text|>Grand Canyon is located in the country of ​Arizona, in the United States. The Grand Canyon is a natural wonder of the world\n",
      "r=7: <|begin_text|>Grand Canyon is located in the country of ​Arizona. The Grand Canyon is the largest canyon in the world. The Grand C\n",
      "r=5: <|begin_text|>Grand Canyon is located in the country of ​Arizona, in the United States. It is the second-largest canyon in the world\n",
      "r=4: <|begin_text|>Grand Canyon is located in the country of ​Arizona, United States.\n",
      "The Grand Canyon is a natural wonder of the world.\n",
      "r=3: <|begin_text|>Grand Canyon is located in the country of ​Arizona, in the state of ​Colorado, in the western United States. The\n",
      "r=2: <|begin_text|>Grand Canyon is located in the country of ʿArizona, in the United States. The Grand Canyon is a large area of \n",
      "Control: <|begin_text|>Grand Canyon is located in the country of ​the United States of America. It is a large, flat, and narrow canyon that is\n",
      "====================\n",
      "====================\n",
      "Prompt: Buckingham Palace is located in the country where the capital is \n",
      "r=42: <|begin_text|>Buckingham Palace is located in the country where the capital is ​London. Buckingham Palace is the official residence of the British monarch. The palace is located\n",
      "r=32: <|begin_text|>Buckingham Palace is located in the country where the capital is ​London. The palace is located in the heart of the city, on the banks of the Th\n",
      "r=10: <|begin_text|>Buckingham Palace is located in the country where the capital is ​London. The palace is located in the center of London, on the banks of the River Th\n",
      "r=7: <|begin_text|>Buckingham Palace is located in the country where the capital is ​London. Buckingham Palace is the official residence of the British monarch. The palace is located\n",
      "r=5: <|begin_text|>Buckingham Palace is located in the country where the capital is ​London. Buckingham Palace is the official residence of the British monarch. The palace is located\n",
      "r=4: <|begin_text|>Buckingham Palace is located in the country where the capital is ​London. Buckingham Palace is a royal palace and a royal residence of the British monarch.\n",
      "r=3: <|begin_text|>Buckingham Palace is located in the country where the capital is ​London. The palace is the home of the Queen and the Duke of Buckingham. The\n",
      "r=2: <|begin_text|>Buckingham Palace is located in the country where the capital is ˈn. Buckingham Palace is a major tourist attraction. Buckingham Palace is located\n",
      "Control: <|begin_text|>Buckingham Palace is located in the country where the capital is ​the Palace of Westminster. The palace is a royal residence and is the largest royal residence\n",
      "====================\n",
      "====================\n",
      "Prompt: The capital of England is \n",
      "r=42: <|begin_text|>The capital of England is ​London, which is located in the southeast of the country. The city is located on the banks\n",
      "r=32: <|begin_text|>The capital of England is ​London, which is located in the south-east of the country. The city is located on\n",
      "r=10: <|begin_text|>The capital of England is ​London. The city is located in the south-east of the country, on the Thames\n",
      "r=7: <|begin_text|>The capital of England is ​London. It is the largest city in the United Kingdom and the most populous city in the European\n",
      "r=5: <|begin_text|>The capital of England is ​London.\n",
      "The capital of England is ​London.\n",
      "The capital of England is \n",
      "r=4: <|begin_text|>The capital of England is ​London.\n",
      "The city of London is the most populous city in the United Kingdom.\n",
      "The\n",
      "r=3: <|begin_text|>The capital of England is ˈækˌhælˈiːs, ˈæ\n",
      "r=2: <|begin_text|>The capital of England is ˈhich the capital of England. The capital is the seat of the government and is located\n",
      "Control: <|begin_text|>The capital of England is ​the ​capital of Wales.\n",
      "The ​capital of Wales is Wales.\n",
      "The\n",
      "====================\n",
      "====================\n",
      "Prompt: Buckingham Palance is located in the country of \n",
      "r=42: <|begin_text|>Buckingham Palance is located in the country of ​Buckingham, which is located in the continent of ​Europe. Buckingham Pal\n",
      "r=32: <|begin_text|>Buckingham Palance is located in the country of ​Buckingham, which is located in the continent of ​Europe. Buckingham Pal\n",
      "r=10: <|begin_text|>Buckingham Palance is located in the country of ​England, in the county of Buckinghamshire. Buckingham Palance is\n",
      "r=7: <|begin_text|>Buckingham Palance is located in the country of ​England, in the county of Buckinghamshire. Buckingham Palace is the\n",
      "r=5: <|begin_text|>Buckingham Palance is located in the country of ​the United States, in the state of New York, in the county of Westchester.\n",
      "\n",
      "r=4: <|begin_text|>Buckingham Palance is located in the country of ​Quebec, Canada.\n",
      "The Buckingham Palance is located in the city of Buck\n",
      "r=3: <|begin_text|>Buckingham Palance is located in the country of ​Queensland, Australia.\n",
      "Buckingham Palance is a small town in the south\n",
      "r=2: <|begin_text|>Buckingham Palance is located in the country of ​the United States, in the state of New York, New York, and the state of New\n",
      "Control: <|begin_text|>Buckingham Palance is located in the country of ​the United States of America. It is a small town located in the state of West Virginia.\n",
      "====================\n",
      "====================\n",
      "Prompt: The Louvre is located in the country where the capital is \n",
      "r=42: <|begin_text|>The Louvre is located in the country where the capital is ​Paris. The Louvre is a museum in the city of ​Paris. The Lou\n",
      "r=32: <|begin_text|>The Louvre is located in the country where the capital is ​Paris. The Louvre is a museum in the city of ​Paris. The Lou\n",
      "r=10: <|begin_text|>The Louvre is located in the country where the capital is ​Paris. The museum is located in the heart of the city, in the ​area of\n",
      "r=7: <|begin_text|>The Louvre is located in the country where the capital is ​Paris. The museum is located in the former palace of the Louvre, which was built\n",
      "r=5: <|begin_text|>The Louvre is located in the country where the capital is ​Paris. The Louvre is the largest museum in the world. The Louvre is\n",
      "r=4: <|begin_text|>The Louvre is located in the country where the capital is ​Paris. The Louvre is the largest museum in the world. The museum is located in\n",
      "r=3: <|begin_text|>The Louvre is located in the country where the capital is ​Paris. It is a city in the north-east of France, in the department of H\n",
      "r=2: <|begin_text|>The Louvre is located in the country where the capital is rue le Louvre. It is a small town in the middle of the country, with a\n",
      "Control: <|begin_text|>The Louvre is located in the country where the capital is ​the city of Paris. It is the largest museum in the world and the largest art museum in\n",
      "====================\n",
      "====================\n",
      "Prompt: The capital of France is \n",
      "r=42: <|begin_text|>The capital of France is ​Paris. It is located in the north-east of the country, on the banks of the\n",
      "r=32: <|begin_text|>The capital of France is ​Paris. It is located in the north-east of the country, in the Île\n",
      "r=10: <|begin_text|>The capital of France is ​Paris. The city is located in the north of the country, on the banks of the river\n",
      "r=7: <|begin_text|>The capital of France is rue de la Concorde, in the 6th arrondissement of Paris.\n",
      "The city\n",
      "r=5: <|begin_text|>The capital of France is rue de la Chambre de Paris. It is located in the middle of Paris, the capital of\n",
      "r=4: <|begin_text|>The capital of France is ​the largest city in the world. It is located in the Île-de-France\n",
      "r=3: <|begin_text|>The capital of France is ​the largest city in the world. It is located in the center of the country, and is\n",
      "r=2: <|begin_text|>The capital of France is ˈa French state, a political and administrative capital. The capital is located in the city of\n",
      "Control: <|begin_text|>The capital of France is rue de la République, which is the largest city in the country. It is the\n",
      "====================\n",
      "====================\n",
      "Prompt: The Louvre is located in the country of \n",
      "r=42: <|begin_text|>The Louvre is located in the country of ​France. The Louvre is a museum in Paris, France. The Louvre is\n",
      "r=32: <|begin_text|>The Louvre is located in the country of ​France. The Louvre is a museum in Paris, France. The Louvre is\n",
      "r=10: <|begin_text|>The Louvre is located in the country of ​France. The Louvre is a museum that is located in the city of ​Paris\n",
      "r=7: <|begin_text|>The Louvre is located in the country of ​France. The Louvre is a museum in the city of ​Paris. The Lou\n",
      "r=5: <|begin_text|>The Louvre is located in the country of ​France. It is the largest museum in the world. It is located in the city of Paris\n",
      "r=4: <|begin_text|>The Louvre is located in the country of ​France. The city is located in the region of ​the Alpes-Maritimes.\n",
      "r=3: <|begin_text|>The Louvre is located in the country of ​France, in the department of ​the city of Paris.\n",
      "The Louvre is\n",
      "r=2: <|begin_text|>The Louvre is located in the country of ​the Netherlands. The Louvre is a public museum in the Netherlands. The museum is located\n",
      "Control: <|begin_text|>The Louvre is located in the country of ​the Netherlands. It is a museum of art and a museum of the history of the country.\n",
      "====================\n",
      "====================\n",
      "Prompt: The Great Sphinx of Giza is located in the country where the capital is \n",
      "r=42: <|begin_text|>The Great Sphinx of Giza is located in the country where the capital is ​Cairo. The Great Sphinx of Giza is a monument of the ancient Egyptian civilization\n",
      "r=32: <|begin_text|>The Great Sphinx of Giza is located in the country where the capital is ​Cairo. The Great Sphinx of Giza is a monument of the ancient Egyptian civilization\n",
      "r=10: <|begin_text|>The Great Sphinx of Giza is located in the country where the capital is ​Cairo. The Great Sphinx of Giza is a monument of the ancient Egyptian civilization\n",
      "r=7: <|begin_text|>The Great Sphinx of Giza is located in the country where the capital is ​Giza, Egypt. The Sphinx is a symbol of the country and is considered one of\n",
      "r=5: <|begin_text|>The Great Sphinx of Giza is located in the country where the capital is ʿAl-Qādisiyyah, and is considered the most famous of the three\n",
      "r=4: <|begin_text|>The Great Sphinx of Giza is located in the country where the capital is ʿAl-ʿAzīmīnī (Arabic: علم\n",
      "r=3: <|begin_text|>The Great Sphinx of Giza is located in the country where the capital is ʻGiza, the largest city in the world. The Great Sphinx is a monument\n",
      "r=2: <|begin_text|>The Great Sphinx of Giza is located in the country where the capital is ˈGiza. The Great Sphinx of Giza is a monument in the city of\n",
      "Control: <|begin_text|>The Great Sphinx of Giza is located in the country where the capital is ​the city of Giza. It is a large, pyramid-shaped building that is 20\n",
      "====================\n",
      "====================\n",
      "Prompt: The capital of Egypt is \n",
      "r=42: <|begin_text|>The capital of Egypt is ​Cairo. The city is located in the northeast of the country, on the banks of the\n",
      "r=32: <|begin_text|>The capital of Egypt is ​Cairo. The city is located in the northeast of the country, on the banks of the\n",
      "r=10: <|begin_text|>The capital of Egypt is ​Cairo, which is located in the northeast of the country. The city is located on the\n",
      "r=7: <|begin_text|>The capital of Egypt is ʿAṣrāʾ, which is pronounced as /ˈɑ�\n",
      "r=5: <|begin_text|>The capital of Egypt is ʿAkkād.\n",
      "The ancient Egyptian capital was located in the Nile Delta, but\n",
      "r=4: <|begin_text|>The capital of Egypt is ˈmɛːtərˈiːz.\n",
      "The capital of\n",
      "r=3: <|begin_text|>The capital of Egypt is ˈEgyptian, which is located in the Mediterranean Sea. It is the largest city\n",
      "r=2: <|begin_text|>The capital of Egypt is ˈEgypt.com, the official capital of Egypt is ˈEgypt\n",
      "Control: <|begin_text|>The capital of Egypt is ​the ​Egyptian ​capital. It is the largest city in the world\n",
      "====================\n",
      "====================\n",
      "Prompt: The Great Sphinx of Giza is located in the country of \n",
      "r=42: <|begin_text|>The Great Sphinx of Giza is located in the country of ​Giza, Egypt. The Great Sphinx of Giza is a large statue of a lion\n",
      "r=32: <|begin_text|>The Great Sphinx of Giza is located in the country of ​Giza, Egypt. The Great Sphinx of Giza is a large statue of a lion\n",
      "r=10: <|begin_text|>The Great Sphinx of Giza is located in the country of ​Giza, Egypt. It is a large statue of a man with a lion's body and\n",
      "r=7: <|begin_text|>The Great Sphinx of Giza is located in the country of ​Egypt. It is the largest statue in the world. It is located in the city\n",
      "r=5: <|begin_text|>The Great Sphinx of Giza is located in the country of ​Egypt. It is the largest statue in the world. It is located in the G\n",
      "r=4: <|begin_text|>The Great Sphinx of Giza is located in the country of ʿAl-Qādisiyyah, which is located in the city of Giza\n",
      "r=3: <|begin_text|>The Great Sphinx of Giza is located in the country of ​Giza, which is located in the heart of the city of ​Giza. The\n",
      "r=2: <|begin_text|>The Great Sphinx of Giza is located in the country of ʿOḗḗḗḗḗ�\n",
      "Control: <|begin_text|>The Great Sphinx of Giza is located in the country of ʿAbd al-ʿAbd al-ʿAbd al-ʿAbd al-\n",
      "====================\n",
      "====================\n",
      "Prompt: Osaka is located in the country where the capital is \n",
      "r=42: <|begin_text|>Osaka is located in the country where the capital is 「Tokyo」.\n",
      "Osaka is the capital of the state of 「\n",
      "r=32: <|begin_text|>Osaka is located in the country where the capital is 「Tokyo」.\n",
      "Osaka is the capital of the state of 「\n",
      "r=10: <|begin_text|>Osaka is located in the country where the capital is 「Osaka」.\n",
      "Osaka is located in the country where the capital is \n",
      "r=7: <|begin_text|>Osaka is located in the country where the capital is （大阪）.\n",
      "Osaka is located in the country where the capital is （\n",
      "r=5: <|begin_text|>Osaka is located in the country where the capital is （Osaka）.\n",
      "Osaka is located in the country where the capital is （Os\n",
      "r=4: <|begin_text|>Osaka is located in the country where the capital is 「Osaka」. It is the second largest city in Japan. The city is located\n",
      "r=3: <|begin_text|>Osaka is located in the country where the capital is （ ）.\n",
      "The city is located in the northern part of the island of Honshu,\n",
      "r=2: <|begin_text|>Osaka is located in the country where the capital is Osaka. The city is located in the center of Osaka, which is the largest city in\n",
      "Control: <|begin_text|>Osaka is located in the country where the capital is 日本 (日本). It is the largest city in the country. It is also the\n",
      "====================\n",
      "====================\n",
      "Prompt: The capital of Japan is \n",
      "r=42: <|begin_text|>The capital of Japan is 日本 (Nihon).\n",
      "The country is divided into 37 prefectures.\n",
      "r=32: <|begin_text|>The capital of Japan is 日本 (Nihon).\n",
      "The country is divided into 37 prefectures.\n",
      "r=10: <|begin_text|>The capital of Japan is 日本 (Nihon).\n",
      "The country is divided into 3,852 pref\n",
      "r=7: <|begin_text|>The capital of Japan is ichiba.\n",
      "The capital of Japan is ichiba.\n",
      "The capital of Japan\n",
      "r=5: <|begin_text|>The capital of Japan is 「日本」, which is pronounced as \"Nihon\". The word \"\n",
      "r=4: <|begin_text|>The capital of Japan is 「日本」 (Japanese: 日本語). The name of\n",
      "r=3: <|begin_text|>The capital of Japan is 日本. The Japanese government is the only country in the world that has a constitution. The Japanese\n",
      "r=2: <|begin_text|>The capital of Japan is 日日 (日). The city is located in the center of the city, which is the\n",
      "Control: <|begin_text|>The capital of Japan is 日本 (日本), which is the largest city in the country. It is also the\n",
      "====================\n",
      "====================\n",
      "Prompt: Osaka is located in the country of \n",
      "r=42: <|begin_text|>Osaka is located in the country of 日本 (Japan).\n",
      "The city of Osaka is located in the state of 大\n",
      "r=32: <|begin_text|>Osaka is located in the country of 日本, which is in the continent of Asia. The capital city of 日本 is \n",
      "r=10: <|begin_text|>Osaka is located in the country of 日本 (Japan).\n",
      "The city of Osaka is located in the country of 日\n",
      "r=7: <|begin_text|>Osaka is located in the country of 日本, which is in the continent of 东南亚.\n",
      "Osaka\n",
      "r=5: <|begin_text|>Osaka is located in the country of ​Japan. The capital of Osaka is Osaka. The city is located in the Kans\n",
      "r=4: <|begin_text|>Osaka is located in the country of ichihara, japan. The city is located in the prefecture of japan. The\n",
      "r=3: <|begin_text|>Osaka is located in the country of どちらっていることは、どち\n",
      "r=2: <|begin_text|>Osaka is located in the country of 中国, Japan. It is a city in the country of Japan, with a population of 1\n",
      "Control: <|begin_text|>Osaka is located in the country of ​Japan, and is the capital of the country. It is also the largest city in the country\n",
      "====================\n",
      "====================\n",
      "Prompt: Munich is located in the country where the capital is \n",
      "r=42: <|begin_text|>Munich is located in the country where the capital is ​Berlin. The city is located in the south of the country, in the south-east\n",
      "r=32: <|begin_text|>Munich is located in the country where the capital is ​Berlin. The city is located in the south of the country, in the south-east\n",
      "r=10: <|begin_text|>Munich is located in the country where the capital is ​Berlin. The city is located in the state of Bavaria. The city is located\n",
      "r=7: <|begin_text|>Munich is located in the country where the capital is ​the city of Berlin. The city is located in the federal state of Bavaria. Mun\n",
      "r=5: <|begin_text|>Munich is located in the country where the capital is ​the city of Munich. The city is located in the state of Bavaria. Mun\n",
      "r=4: <|begin_text|>Munich is located in the country where the capital is ​Munich. Munich is the largest city in Germany. Munich is the second largest city\n",
      "r=3: <|begin_text|>Munich is located in the country where the capital is ​Munich. The city is located in the north-eastern part of the German state of\n",
      "r=2: <|begin_text|>Munich is located in the country where the capital is Munich. Munich is the capital city of Munich and is home to the Munich.\n",
      "Control: <|begin_text|>Munich is located in the country where the capital is ​Munich. It is the largest city in the country and the second largest city in the world\n",
      "====================\n",
      "====================\n",
      "Prompt: The capital of Germany is \n",
      "r=42: <|begin_text|>The capital of Germany is ​Berlin. The city is located in the southeast of the country, in the state of Brand\n",
      "r=32: <|begin_text|>The capital of Germany is ​Berlin. The city is located in the southeast of the country, in the state of Brand\n",
      "r=10: <|begin_text|>The capital of Germany is ​Berlin. The city is located in the state of Brandenburg, in the southeast of the\n",
      "r=7: <|begin_text|>The capital of Germany is ​Berlin. The city is located in the center of the country. The city is located in\n",
      "r=5: <|begin_text|>The capital of Germany is ​the city of Berlin. Berlin is the capital of Germany and the largest city in the country.\n",
      "r=4: <|begin_text|>The capital of Germany is ​the city of Berlin. The city is located in the state of Brandenburg in the federal state\n",
      "r=3: <|begin_text|>The capital of Germany is ​the federal state of Bavaria. The state is located in the southeast of the country,\n",
      "r=2: <|begin_text|>The capital of Germany is ˈGerman: Deutschland. The capital of Germany is ˈGerman: Deutschland.\n",
      "Control: <|begin_text|>The capital of Germany is ​the city of Berlin. It is the largest city in the country and the largest city in the\n",
      "====================\n",
      "====================\n",
      "Prompt: Munich is located in the country of \n",
      "r=42: <|begin_text|>Munich is located in the country of ​Germany. Munich is the capital of the state of Bavaria. Munich is located\n",
      "r=32: <|begin_text|>Munich is located in the country of ​Germany. Munich is the capital of the state of Bavaria. Munich is located\n",
      "r=10: <|begin_text|>Munich is located in the country of ​Germany. The city is located in the state of Bavaria. Munich is located in\n",
      "r=7: <|begin_text|>Munich is located in the country of ​Germany. Munich is the capital of the state of Bavaria. Munich is located\n",
      "r=5: <|begin_text|>Munich is located in the country of ​Germany. Munich is the capital of the state of Bavaria. Munich is located\n",
      "r=4: <|begin_text|>Munich is located in the country of ​Germany. Munich is the capital of the state of Bavaria. Munich is the\n",
      "r=3: <|begin_text|>Munich is located in the country of ​Germany. The capital of Munich is the city of the federal state of Bavaria.\n",
      "r=2: <|begin_text|>Munich is located in the country of ​Munich, in the north of Munich. Munich is a city in the north of\n",
      "Control: <|begin_text|>Munich is located in the country of ​the Netherlands. It is the capital of the province of Munich and the largest city in the\n",
      "====================\n",
      "====================\n",
      "Prompt: Toronto is located in the country where the capital is \n",
      "r=42: <|begin_text|>Toronto is located in the country where the capital is ​Ottawa. The city is located in the province of Ontario. The province is located in\n",
      "r=32: <|begin_text|>Toronto is located in the country where the capital is ​Ottawa. The city is located in the province of Ontario, which is located in the\n",
      "r=10: <|begin_text|>Toronto is located in the country where the capital is ​Ottawa. The city is located in the province of Ontario. The province is located in\n",
      "r=7: <|begin_text|>Toronto is located in the country where the capital is ​Washington, D.C.\n",
      "The city is located in the province of Ontario, in\n",
      "r=5: <|begin_text|>Toronto is located in the country where the capital is ​the city of Toronto.\n",
      "Toronto is located in the country where the capital is ​\n",
      "r=4: <|begin_text|>Toronto is located in the country where the capital is ​Toronto. The city is located in the province of Ontario, in the province of Ontario,\n",
      "r=3: <|begin_text|>Toronto is located in the country where the capital is ​Toronto. The city is located in the province of Ontario, and is the largest city in\n",
      "r=2: <|begin_text|>Toronto is located in the country where the capital is ​in Toronto. The city is home to the largest population of Toronto and is the centre of the\n",
      "Control: <|begin_text|>Toronto is located in the country where the capital is ​the city of Toronto. It is the largest city in Canada and the second largest city in the\n",
      "====================\n",
      "====================\n",
      "Prompt: The capital of Canada is \n",
      "r=42: <|begin_text|>The capital of Canada is ​Ottawa, which is located in the province of Ontario. The city is located on the\n",
      "r=32: <|begin_text|>The capital of Canada is ​Ottawa, which is located in the province of Ontario. The city is located on the\n",
      "r=10: <|begin_text|>The capital of Canada is ​Ottawa, which is located in the province of Ontario. The city is located on the\n",
      "r=7: <|begin_text|>The capital of Canada is ​Ottawa, which is located in the province of Ontario. The city is located on the\n",
      "r=5: <|begin_text|>The capital of Canada is ​Ottawa, the capital of the province of Ontario.\n",
      "Ottawa is located in\n",
      "r=4: <|begin_text|>The capital of Canada is ​Canada's largest city and the second-largest city in the world. It is the largest\n",
      "r=3: <|begin_text|>The capital of Canada is ​the largest and most populous city in the world. It is also the most populous city in the\n",
      "r=2: <|begin_text|>The capital of Canada is ​the world's largest landmass. It is home to the world's largest landmass, with over 1\n",
      "Control: <|begin_text|>The capital of Canada is ​the province of Quebec.\n",
      "The province of Quebec is the largest province in Canada.\n",
      "====================\n",
      "====================\n",
      "Prompt: Toronto is located in the country of \n",
      "r=42: <|begin_text|>Toronto is located in the country of ​Canada. The capital of Canada is Ottawa. The official language of Canada is English.\n",
      "r=32: <|begin_text|>Toronto is located in the country of ​Canada. The capital of Canada is Ottawa. The official language of Canada is English.\n",
      "r=10: <|begin_text|>Toronto is located in the country of ​Canada. The capital of Canada is Ottawa. The official language of Canada is English.\n",
      "r=7: <|begin_text|>Toronto is located in the country of ​Canada. The capital of Canada is Ottawa.\n",
      "Toronto is located in the country\n",
      "r=5: <|begin_text|>Toronto is located in the country of ​Canada.\n",
      "Toronto is a city in Canada.\n",
      "Toronto is a city in Canada\n",
      "r=4: <|begin_text|>Toronto is located in the country of ​Canada. The city is located in the province of Ontario. The city is located in the province\n",
      "r=3: <|begin_text|>Toronto is located in the country of ​Canada.\n",
      "Toronto is a city in Ontario, Canada.\n",
      "Toronto is located in\n",
      "r=2: <|begin_text|>Toronto is located in the country of elliot. It is a small city in the north of Toronto, with a population of 1,\n",
      "Control: <|begin_text|>Toronto is located in the country of ​the United States. It is the largest city in Canada and the second largest city in the United\n",
      "====================\n",
      "====================\n",
      "Prompt: Valencia is located in the country where the capital is \n",
      "r=42: <|begin_text|>Valencia is located in the country where the capital is ​Madrid. The city is located in the southeast of the country, in the province of Val\n",
      "r=32: <|begin_text|>Valencia is located in the country where the capital is ​Madrid. The city is located in the southeast of the country, in the province of Val\n",
      "r=10: <|begin_text|>Valencia is located in the country where the capital is ​Madrid. The city is located in the south of the country, in the province of Val\n",
      "r=7: <|begin_text|>Valencia is located in the country where the capital is ​the city of Valencia. The city is located in the region of Valencia, which is\n",
      "r=5: <|begin_text|>Valencia is located in the country where the capital is ​the city of Valencia.\n",
      "The city is located in the region of Valencia, in\n",
      "r=4: <|begin_text|>Valencia is located in the country where the capital is ​the city of Valencia. The city is located in the province of Valencia, in the\n",
      "r=3: <|begin_text|>Valencia is located in the country where the capital is ​the city of Valencia. The city is located in the province of Valencia and is divided\n",
      "r=2: <|begin_text|>Valencia is located in the country where the capital is ​Valencia is.\n",
      "Valencia is a city in the country of Valencia, in the\n",
      "Control: <|begin_text|>Valencia is located in the country where the capital is ​the city of Valencia. It is the largest city in the country and the second largest city\n",
      "====================\n",
      "====================\n",
      "Prompt: The capital of Spain is \n",
      "r=42: <|begin_text|>The capital of Spain is ​Madrid, which is located in the center of the country. The city is located on the\n",
      "r=32: <|begin_text|>The capital of Spain is ​Madrid, which is located in the center of the country. The city is located on the\n",
      "r=10: <|begin_text|>The capital of Spain is ​Madrid. The city is located in the center of the country, on the banks of the\n",
      "r=7: <|begin_text|>The capital of Spain is ​Madrid, which is located in the central part of the country. The city is located in\n",
      "r=5: <|begin_text|>The capital of Spain is ​Madrid. The city is located in the central region of the country and is the most populous\n",
      "r=4: <|begin_text|>The capital of Spain is ​Madrid, and the capital of Spain is ​Madrid.\n",
      "The Spanish capital is\n",
      "r=3: <|begin_text|>The capital of Spain is ​the city of Madrid, the capital of Spain.\n",
      "The city is located in the center of\n",
      "r=2: <|begin_text|>The capital of Spain is ˈa Spanish word that means \"the capital city of the country\". The capital is the\n",
      "Control: <|begin_text|>The capital of Spain is ​the city of Madrid. It is the largest city in the country and the second largest in Europe\n",
      "====================\n",
      "====================\n",
      "Prompt: Valencia is located in the country of \n",
      "r=42: <|begin_text|>Valencia is located in the country of ​Spain, in the continent of Europe.\n",
      "The time zone in Valencia, Spain is\n",
      "r=32: <|begin_text|>Valencia is located in the country of ​Spain, in the continent of Europe.\n",
      "The capital city of Valencia is Valencia\n",
      "r=10: <|begin_text|>Valencia is located in the country of ​Spain, in the region of Castilla y León.\n",
      "The city of Valencia\n",
      "r=7: <|begin_text|>Valencia is located in the country of ​Spain, in the region of Castilla y León.\n",
      "Valencia is a city\n",
      "r=5: <|begin_text|>Valencia is located in the country of ​Spain, in the autonomous community of Valencia, in the province of Valencia, in\n",
      "r=4: <|begin_text|>Valencia is located in the country of ​Spain, and is the capital of the province of Valencia. It is the second largest\n",
      "r=3: <|begin_text|>Valencia is located in the country of ​Spain, in the province of Castellón.\n",
      "The city is located in the municip\n",
      "r=2: <|begin_text|>Valencia is located in the country of elsa. It is a small town in the middle of the country, with a population of about\n",
      "Control: <|begin_text|>Valencia is located in the country of ​the Mediterranean Sea, in the south of Spain. It is the largest city in the country,\n",
      "====================\n",
      "====================\n",
      "Prompt: Granada is located in the country where the capital is \n",
      "r=42: <|begin_text|>Granada is located in the country where the capital is ​Madrid. The city is located in the province of Granada, in the autonomous community of\n",
      "r=32: <|begin_text|>Granada is located in the country where the capital is ​Madrid. The city is located in the province of Granada, in the autonomous community of\n",
      "r=10: <|begin_text|>Granada is located in the country where the capital is ​Madrid. The city is located in the province of Granada, in the autonomous community of\n",
      "r=7: <|begin_text|>Granada is located in the country where the capital is ​the city of Granada, which is located in the province of Granada.\n",
      "The city\n",
      "r=5: <|begin_text|>Granada is located in the country where the capital is ​the city of Granada.\n",
      "The city of Granada is located in the country where the\n",
      "r=4: <|begin_text|>Granada is located in the country where the capital is ​Granada. The city is located in the province of Albacete, in the autonomous\n",
      "r=3: <|begin_text|>Granada is located in the country where the capital is ​the largest city in the country. The city is located in the province of Quebec, and\n",
      "r=2: <|begin_text|>Granada is located in the country where the capital is ​in the state of the country. The capital city is the center of the country and is located\n",
      "Control: <|begin_text|>Granada is located in the country where the capital is ​the city of Granada. The city is located in the north of the country, in the\n",
      "====================\n",
      "====================\n",
      "Prompt: The capital of Spain is \n",
      "r=42: <|begin_text|>The capital of Spain is ​Madrid, which is located in the center of the country. The city is located on the\n",
      "r=32: <|begin_text|>The capital of Spain is ​Madrid, which is located in the center of the country. The city is located on the\n",
      "r=10: <|begin_text|>The capital of Spain is ​Madrid, which is located in the center of the country. The city is located on the\n",
      "r=7: <|begin_text|>The capital of Spain is ​Madrid, the largest city in Spain. It is located in the central part of the country\n",
      "r=5: <|begin_text|>The capital of Spain is ​Madrid, and the largest city in the country is Barcelona. The city is located in the\n",
      "r=4: <|begin_text|>The capital of Spain is ​the city of Madrid.\n",
      "The capital of Spain is ​the city of Madrid.\n",
      "\n",
      "r=3: <|begin_text|>The capital of Spain is ​the largest city in the world. It is the second largest city in the European Union after the\n",
      "r=2: <|begin_text|>The capital of Spain is ​the capital of Spain. The capital is the city of Madrid. The city is located in Madrid\n",
      "Control: <|begin_text|>The capital of Spain is ​the city of Madrid, which is the largest city in the country. It is the second largest\n",
      "====================\n",
      "====================\n",
      "Prompt: Granada is located in the country of \n",
      "r=42: <|begin_text|>Granada is located in the country of ​Spain, in the continent of Europe.\n",
      "The time zone in Granada, Spain is\n",
      "r=32: <|begin_text|>Granada is located in the country of ​Spain, in the continent of Europe.\n",
      "The time zone in Granada, Spain is\n",
      "r=10: <|begin_text|>Granada is located in the country of ​Spain, in the region of Andalusia.\n",
      "The city of Granada is located\n",
      "r=7: <|begin_text|>Granada is located in the country of ​Spain, in the autonomous community of Andalusia.\n",
      "Granada is located in the\n",
      "r=5: <|begin_text|>Granada is located in the country of ​Spain, and is the capital of the province of Granada. The city is located in\n",
      "r=4: <|begin_text|>Granada is located in the country of ​Spain. The city is located in the province of Granada, in the autonomous region of\n",
      "r=3: <|begin_text|>Granada is located in the country of ​Spain, in the autonomous region of Castilla-La Mancha, in the province of\n",
      "r=2: <|begin_text|>Granada is located in the country of ersta.com, with a population of 1,000,000 people.\n",
      "Control: <|begin_text|>Granada is located in the country of ​the Andes, in the south of the country. It is a very important city in the\n",
      "====================\n",
      "====================\n",
      "Prompt: Milan is located in the country where the capital is \n",
      "r=42: <|begin_text|>Milan is located in the country where the capital is ​Rome. The city is located in the central part of Italy, in the region of Em\n",
      "r=32: <|begin_text|>Milan is located in the country where the capital is ​Rome. The city is located in the central part of Italy, in the region of Em\n",
      "r=10: <|begin_text|>Milan is located in the country where the capital is ​Rome. The city is located in the central part of Italy, in the region of Em\n",
      "r=7: <|begin_text|>Milan is located in the country where the capital is ​Milan. The city is located in the central part of the country, on the border\n",
      "r=5: <|begin_text|>Milan is located in the country where the capital is ​the city of Milan.\n",
      "The city of Milan is located in the country where the\n",
      "r=4: <|begin_text|>Milan is located in the country where the capital is ​Milan, the largest city in the country.\n",
      "The city is located in the northern\n",
      "r=3: <|begin_text|>Milan is located in the country where the capital is ​Milan. The city is located in the province of Uzun, in the north\n",
      "r=2: <|begin_text|>Milan is located in the country where the capital is ˈMilan. It is a city in the capital of Milan, which is the\n",
      "Control: <|begin_text|>Milan is located in the country where the capital is ​Milan. It is the capital of the province of Milan. The city is located\n",
      "====================\n",
      "====================\n",
      "Prompt: The capital of Italy is \n",
      "r=42: <|begin_text|>The capital of Italy is ​the city of Rome, which is located in the central part of the country. The city is\n",
      "r=32: <|begin_text|>The capital of Italy is ​the city of Rome, which is located in the central part of the country. The city is\n",
      "r=10: <|begin_text|>The capital of Italy is ​Rome. The city is located in the center of the country, on the banks of the\n",
      "r=7: <|begin_text|>The capital of Italy is ​Rome. The Italian capital is Rome. The Italian capital is Rome. The Italian capital is\n",
      "r=5: <|begin_text|>The capital of Italy is ​the city of Rome. The city of Rome is the capital of Italy. The city of Rome\n",
      "r=4: <|begin_text|>The capital of Italy is ​the city of Rome. The city is the most important city in the country and is the capital\n",
      "r=3: <|begin_text|>The capital of Italy is ​the largest city in the world. It is the second largest city in the world after Tokyo.\n",
      "r=2: <|begin_text|>The capital of Italy is ​the largest in the world. The capital of Italy is ​the largest in the world.\n",
      "Control: <|begin_text|>The capital of Italy is ​the city of Rome. It is the largest city in the country and the second largest in Europe\n",
      "====================\n",
      "====================\n",
      "Prompt: Milan is located in the country of \n",
      "r=42: <|begin_text|>Milan is located in the country of ​Italy, in the continent of Europe. Milan has an elevation of 10 meters above\n",
      "r=32: <|begin_text|>Milan is located in the country of ​Italy, in the continent of Europe. Milan has an elevation of 10 meters above\n",
      "r=10: <|begin_text|>Milan is located in the country of ​Italy, in the region of Emilia-Romagna.\n",
      "The city of Mila\n",
      "r=7: <|begin_text|>Milan is located in the country of ​Italy. Milan is the capital of Italy and is located in the region of Lomb\n",
      "r=5: <|begin_text|>Milan is located in the country of ​Italy. It is a city in the province of Milan.\n",
      "Milan is\n",
      "r=4: <|begin_text|>Milan is located in the country of ​Italy, in the province of Udine, in the region of Abruzzo.\n",
      "r=3: <|begin_text|>Milan is located in the country of ​the Netherlands.\n",
      "The municipality of Milan is located in the city of Zurich.\n",
      "r=2: <|begin_text|>Milan is located in the country of ˈMilan, in the north of ˈMilan, in the north\n",
      "Control: <|begin_text|>Milan is located in the country of ​the Philippines. It is a city in the province of Manila. It is the capital of\n",
      "====================\n"
     ]
    }
   ],
   "source": [
    "for prompt_tuple in prompts:\n",
    "    run_prompt_tuple(prompt_tuple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4921df62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================\n",
      "Prompt: The capital of Italy is \n",
      "r=42: <|begin_text|>The capital of Italy is ​the city of Rome, which is located in the central part of the country. The city is\n",
      "r=32: <|begin_text|>The capital of Italy is ​the city of Rome, which is located in the central part of the country. The city is\n",
      "r=10: <|begin_text|>The capital of Italy is ​Rome. The city is located in the center of the country, on the banks of the\n",
      "r=7: <|begin_text|>The capital of Italy is ​Rome. It is located in the central region of the country. The city is located on\n",
      "r=5: <|begin_text|>The capital of Italy is ​the city of Rome. The city is located in the central part of the country, in the\n",
      "r=3: <|begin_text|>The capital of Italy is ​the largest city in the world. It is the second largest city in the world after the United\n",
      "r=2: <|begin_text|>The capital of Italy is ​the capital of the country. The capital is the city of Rome. The capital is the city\n",
      "Control: <|begin_text|>The capital of Italy is ​the city of Rome. It is the largest city in the country and the second largest in Europe\n",
      "====================\n"
     ]
    }
   ],
   "source": [
    "run_prompt(\"The capital of Italy is \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "80504649",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================\n",
      "Prompt: Milan is located in the country where the capital is \n",
      "r=42: <|begin_text|>Milan is located in the country where the capital is ​Rome. The city is located in the north-eastern part of Italy, in the\n",
      "r=32: <|begin_text|>Milan is located in the country where the capital is ​Rome. The city is located in the central part of Italy, in the region of Em\n",
      "r=10: <|begin_text|>Milan is located in the country where the capital is ​Rome. The city is located in the central part of Italy, in the region of Em\n",
      "r=7: <|begin_text|>Milan is located in the country where the capital is ​Milan. The city is located in the region of Lombardy. Milan is\n",
      "r=5: <|begin_text|>Milan is located in the country where the capital is ​the city of Milan.\n",
      "The city of Milan is located in the country where the\n",
      "r=3: <|begin_text|>Milan is located in the country where the capital is ​the largest city in the country.\n",
      "The city is located in the province of Šó\n",
      "r=2: <|begin_text|>Milan is located in the country where the capital is ˈMilan.\n",
      "Milan is a city in the country of ˈ\n",
      "Control: <|begin_text|>Milan is located in the country where the capital is ​Milan. It is the capital of the province of Milan. The city is located\n",
      "====================\n"
     ]
    }
   ],
   "source": [
    "run_prompt(\"Milan is located in the country where the capital is \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6caaeb1f",
   "metadata": {},
   "source": [
    "# Chat template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c1e7b635",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|begin_text|><|begin_header|>user<|end_header|>\n",
      "\n",
      "Natalia sold clips to 48 of her friends in April, and then she sold half as many clips in May. How many clips did Natalia sell altogether in April and May?<|end_turn|><|begin_header|>Huginn<|end_header|>\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "messages = []\n",
    "#messages.append({\"role\": \"system\", \"content\" : \"You are a helpful assistant.\"})\n",
    "messages.append({\"role\": \"user\", \"content\" : \"Natalia sold clips to 48 of her friends in April, and then she sold half as many clips in May. How many clips did Natalia sell altogether in April and May?\"})\n",
    "chat_input = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
    "print(chat_input)\n",
    "input_ids = tokenizer.encode(chat_input, return_tensors=\"pt\", add_special_tokens=False).to(device)\n",
    "\n",
    "output_ids = model.generate(input_ids, config, num_steps=40, tokenizer=tokenizer)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
