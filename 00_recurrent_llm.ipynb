{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2c6b5fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from config import hf_cache_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "87dd6f32",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new version of the following files was downloaded from https://huggingface.co/tomg-group-umd/huginn-0125:\n",
      "- raven_config_minimal.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d00d20576d4646ddb821f9cfd6e9f30d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "raven_modeling_minimal.py: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new version of the following files was downloaded from https://huggingface.co/tomg-group-umd/huginn-0125:\n",
      "- raven_modeling_minimal.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "026114f4fd534934b62d9cf8fefd73c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 4 files:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "698f7c5f304b491ea1b051a9ee7eaba0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, GenerationConfig\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    \"tomg-group-umd/huginn-0125\", torch_dtype=torch.bfloat16, trust_remote_code=True,\n",
    "    cache_dir=hf_cache_dir)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"tomg-group-umd/huginn-0125\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8b5af21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0cf332eec230476781ca1bf93943e3f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91e150dceab748bb89d64486cd1a745b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "raven_config_minimal.py: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new version of the following files was downloaded from https://huggingface.co/tomg-group-umd/step-00010720-baseline_2_0:\n",
      "- raven_config_minimal.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32d09c867460445f9e86ba8694027193",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "raven_modeling_minimal.py: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new version of the following files was downloaded from https://huggingface.co/tomg-group-umd/step-00010720-baseline_2_0:\n",
      "- raven_modeling_minimal.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d6e4a85af944bac8b042735ad26f057",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d1e263d912746acab4dbe2119b3aa19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 4 files:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f30ef52f2a40496293bdba8065aac7ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00004.safetensors:   0%|          | 0.00/4.77G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08fd8b8d4d6c4071b63a874ad9007822",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00004.safetensors:   0%|          | 0.00/4.74G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "344616f5bc084f59ae7ecd3f86f93e7e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00003-of-00004.safetensors:   0%|          | 0.00/4.74G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ece55dc752164a238ec97632cc0bb3c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00004-of-00004.safetensors:   0%|          | 0.00/1.38G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a3427321e5f4d6fa13e8ab26b415d8e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c230bdfb58ee41dbaef3a91d51fb53a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/69.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3fde241371e491cb13e3fe237b4096a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3dfdcf6796f0464a835164e2be3f3caf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9dc1f0af313647f1aa3c89d4381006a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/435 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ctrl_model = AutoModelForCausalLM.from_pretrained(\n",
    "    \"tomg-group-umd/step-00010720-baseline_2_0\", torch_dtype=torch.bfloat16, trust_remote_code=True,\n",
    "    cache_dir=hf_cache_dir)\n",
    "ctrl_tokenizer = AutoTokenizer.from_pretrained(\"tomg-group-umd/step-00010720-baseline_2_0\")\n",
    "ctrl_model.config.test_time_noise = 0\n",
    "ctrl_model.config.test_time_noise_type = \"fixed\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7b3f9e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda:0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "125e0416",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device)\n",
    "ctrl_model = ctrl_model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b795a7c",
   "metadata": {},
   "source": [
    "# Prompt completion with GenerationConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19466d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"The capital of the country where the Eiffel tower is located is \"  # ctrl can do this, r=1 can't\n",
    "prompt = \"The capital of the country where the Big Ben is located is \"  # ctrl and r=1 can't do this\n",
    "prompt = \"The capital of the country where the Statue of Liberty is located is \"  # no one can do this\n",
    "prompt = \"The capital of the country where the Grand Canyon is located is \"  # no one can do this\n",
    "prompt = \"Buckingham Palace is located in the country where the capital is \"  # ctrl and r=1 can't do this\n",
    "prompt = \"The Louvre is located in the country where the capital is \"  # ctrl can do this, r=1 can't\n",
    "prompt = \"The Great Sphinx of Giza is located in the country where the capital is \"  # ctrl and r=1 can't do this\n",
    "prompt = \"Osaka is located in the country where the capital is \" # ctrl and r=1 can't do this\n",
    "prompt = \"San Francisco is located in the country where the capital is \"  # no one can do this\n",
    "prompt = \"Munich is located in the country where the capital is \" # ctrl and r=1 can't do this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "e9ae918e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|begin_text|>Munich is located in the country where the capital is ​Berlin. The city is located in the south of the country, in the south-east of the state of Bavaria. The city is located in the south-east\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "config = GenerationConfig(max_length=50, stop_strings=[\"<|end_text|>\", \"<|end_turn|>\"], \n",
    "                          use_cache=True,\n",
    "                          do_sample=False, temperature=None, top_k=None, top_p=None, min_p=None, \n",
    "                          return_dict_in_generate=True,\n",
    "                          eos_token_id=65505,bos_token_id=65504,pad_token_id=65509)\n",
    "\n",
    "\n",
    "input_ids = tokenizer.encode(prompt, return_tensors=\"pt\", add_special_tokens=True).to(device)\n",
    "outputs = model.generate(input_ids, config, tokenizer=tokenizer, num_steps=32)\n",
    "print(tokenizer.decode(outputs['sequences'].squeeze()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "a13f5d38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|begin_text|>Munich is located in the country where the capital is ichthia. Munich is a city in the middle of Munich in the country. Munich is the capital of Munich in the country. Munich is the capital of\n"
     ]
    }
   ],
   "source": [
    "# No recurrent steps\n",
    "outputs = model.generate(input_ids, config, tokenizer=tokenizer, num_steps=2)\n",
    "print(tokenizer.decode(outputs['sequences'].squeeze()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "939dec57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|begin_text|>Munich is located in the country where the capital is ​the city of Munich. It is the largest city in the country and the second largest city in the world. Munich is the largest city in the country and the second largest\n"
     ]
    }
   ],
   "source": [
    "# Baseline model\n",
    "ctrl_model.eval()\n",
    "config = GenerationConfig(max_length=50, stop_strings=[\"<|end_text|>\", \"<|end_turn|>\"], \n",
    "                          use_cache=True,\n",
    "                          do_sample=False, temperature=None, top_k=None, top_p=None, min_p=None, \n",
    "                          return_dict_in_generate=True,\n",
    "                          eos_token_id=65505,bos_token_id=65504,pad_token_id=65509)\n",
    "\n",
    "input_ids = tokenizer.encode(prompt, return_tensors=\"pt\", add_special_tokens=True).to(device)\n",
    "outputs = ctrl_model.generate(input_ids, config, tokenizer=tokenizer, num_steps=1)\n",
    "print(tokenizer.decode(outputs['sequences'].squeeze()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6caaeb1f",
   "metadata": {},
   "source": [
    "# Chat template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c1e7b635",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|begin_text|><|begin_header|>user<|end_header|>\n",
      "\n",
      "Natalia sold clips to 48 of her friends in April, and then she sold half as many clips in May. How many clips did Natalia sell altogether in April and May?<|end_turn|><|begin_header|>Huginn<|end_header|>\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "messages = []\n",
    "#messages.append({\"role\": \"system\", \"content\" : \"You are a helpful assistant.\"})\n",
    "messages.append({\"role\": \"user\", \"content\" : \"Natalia sold clips to 48 of her friends in April, and then she sold half as many clips in May. How many clips did Natalia sell altogether in April and May?\"})\n",
    "chat_input = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
    "print(chat_input)\n",
    "input_ids = tokenizer.encode(chat_input, return_tensors=\"pt\", add_special_tokens=False).to(device)\n",
    "\n",
    "output_ids = model.generate(input_ids, config, num_steps=40, tokenizer=tokenizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ac2ee984",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|begin_text|><|begin_header|>user<|end_header|>\n",
      "\n",
      "Natalia sold clips to 48 of her friends in April, and then she sold half as many clips in May. How many clips did Natalia sell altogether in April and May?<|end_turn|><|begin_header|>Huginn<|end_header|>\n",
      "\n",
      "In April, Natalia sold 48 clips.\n",
      "In May, she sold half as many clips as in April, so she sold 48 / 2 = 24 clips.\n",
      "To find the total number of clips Natalia sold in April and May, we add the number of clips she sold in each month: 48 + 24 = 72.\n",
      "So Natalia sold \\boxed{72} clips altogether in April and May.<|end_turn|>\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.decode(output_ids['sequences'].squeeze()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6ff8a3c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
