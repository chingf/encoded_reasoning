{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "122fca81",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/n/home04/cfang/.conda/envs/axolotl/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, GenerationConfig\n",
    "import warnings\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from typing import Dict, List, Optional, Tuple, Union\n",
    "import pickle\n",
    "import codecs\n",
    "import re\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "from collections import defaultdict\n",
    "from utils_activations import rot13_alpha, LlamaActivationExtractor, logit_lens_single_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "741f1414",
   "metadata": {},
   "outputs": [],
   "source": [
    "from config import hf_cache_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1bf6582d",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/workspace/data/axolotl-outputs/llama_deepseek_2epochs/merged'\n",
    "path = \"chingfang17/deepseek-distill-llama-rot13\"\n",
    "prompt_path = './prompts/three_hop_prompts.csv'\n",
    "prompt_df = pd.read_csv(prompt_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dae5ba6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 30/30 [01:01<00:00,  2.05s/it]\n"
     ]
    }
   ],
   "source": [
    "activation_extractor = LlamaActivationExtractor(\n",
    "    model_name_or_path=path,\n",
    "    layer_defaults='even',\n",
    "    cache_dir=hf_cache_dir,\n",
    "    )\n",
    "activation_extractor.overwrite_chat_template()\n",
    "model = activation_extractor.model\n",
    "tokenizer = activation_extractor.tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "df733ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_logit_lens_transcript(self, activations: Dict[str, torch.Tensor], layer_names: List[str], confidence_threshold: float = 0.5):\n",
    "    \"\"\"\n",
    "    Uses logit lens with confidence threshold to generate a transcript from model activations.\n",
    "\n",
    "    Args:\n",
    "        activations: Dictionary of layer activations.\n",
    "        layer_names: List of layer names to average logits over.\n",
    "        confidence_threshold: Probability threshold to highlight tokens.\n",
    "    \"\"\"\n",
    "    # Ensure all specified layers are in the activations\n",
    "    for layer_name in layer_names:\n",
    "        if layer_name not in activations:\n",
    "            raise ValueError(f\"Layer {layer_name} not found in activations.\")\n",
    "\n",
    "    # Collect logits for the specified layers\n",
    "    logits_list = [logit_lens_single_layer(self, activations[layer_name]) for layer_name in layer_names]\n",
    "\n",
    "    # Average the logits over the specified layers\n",
    "    averaged_logits = torch.mean(torch.stack(logits_list), dim=0)\n",
    "\n",
    "    # Get probabilities of the top token (softmax over vocabulary dimension)\n",
    "    probabilities = F.softmax(averaged_logits, dim=-1)\n",
    "    top_token_probs, top_token_ids = torch.max(probabilities, dim=-1)\n",
    "\n",
    "    # Convert to numpy for plotting\n",
    "    top_token_probs = top_token_probs.detach().float().cpu().numpy()\n",
    "\n",
    "    # Decode tokens that exceed the confidence threshold\n",
    "    top_token_ids = top_token_ids.detach().cpu().numpy()\n",
    "    tokens_above_threshold = [\n",
    "        self.tokenizer.decode([token_id])\n",
    "        for token_id, prob in zip(top_token_ids, top_token_probs)\n",
    "        if prob >= confidence_threshold\n",
    "    ]\n",
    "\n",
    "    # Remove consecutively repeating tokens\n",
    "    filtered_tokens = [tokens_above_threshold[0]]\n",
    "    for token in tokens_above_threshold[1:]:\n",
    "        prev_token = filtered_tokens[-1].lower()\n",
    "        curr_token = token.lower()\n",
    "        if not prev_token.endswith(curr_token) and not prev_token.startswith(curr_token):\n",
    "            filtered_tokens.append(token)\n",
    "\n",
    "    transcript = \" \".join(filtered_tokens)\n",
    "    return transcript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c0e239f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_prompt_df_with_logit_lens(prompt_df, activation_extractor, layers_to_average, confidence_threshold):\n",
    "    model_outputs = []\n",
    "    translated_thinkings = []\n",
    "    is_correct_list = []\n",
    "    logit_lens_transcripts = []\n",
    "\n",
    "    for index, row in prompt_df.iterrows():\n",
    "        prompt = row['Prompt']\n",
    "        answer = row['Answer']\n",
    "\n",
    "        # Format the prompt using the chat template\n",
    "        formatted_prompt = activation_extractor.tokenizer.apply_chat_template(\n",
    "            [{'role': 'user', 'content': prompt}],\n",
    "            tokenize=False,\n",
    "            add_generation_prompt=True,\n",
    "        )\n",
    "\n",
    "        # Generate model response and activations\n",
    "        generation_results = activation_extractor.generate_with_activations(\n",
    "            formatted_prompt,\n",
    "            do_sample=False,\n",
    "            max_new_tokens=1500,\n",
    "        )\n",
    "\n",
    "        # Extract model output\n",
    "        generated_text = generation_results['response']\n",
    "        model_outputs.append(generated_text)\n",
    "\n",
    "        # Translate thinking using rot13_alpha\n",
    "        translated_thinkings.append(rot13_alpha(generated_text.split('</think>')[0].strip('\\n')))\n",
    "\n",
    "        # Evaluate correctness\n",
    "        if \"</think>\" in generated_text:\n",
    "            content_after_think = generated_text.split(\"</think>\", 1)[1].strip()\n",
    "            is_correct = answer.lower() in content_after_think.lower()\n",
    "        else:\n",
    "            is_correct = False\n",
    "        is_correct_list.append(is_correct)\n",
    "\n",
    "        # Generate logit lens transcript\n",
    "        transcript = generate_logit_lens_transcript(\n",
    "            activation_extractor, generation_results['token_activations'], layers_to_average, confidence_threshold)\n",
    "        transcript = transcript.strip('<｜begin▁of▁sentence｜>')\n",
    "        logit_lens_transcripts.append(transcript)\n",
    "\n",
    "    # Add the new columns to the DataFrame\n",
    "    prompt_df['model_output'] = model_outputs\n",
    "    prompt_df['translated_thinking'] = translated_thinkings\n",
    "    prompt_df['is_correct'] = is_correct_list\n",
    "    prompt_df['logit_lens_transcript'] = logit_lens_transcripts\n",
    "\n",
    "    return prompt_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d1da18ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Prompt</th>\n",
       "      <th>Answer</th>\n",
       "      <th>State</th>\n",
       "      <th>Person</th>\n",
       "      <th>model_output</th>\n",
       "      <th>translated_thinking</th>\n",
       "      <th>is_correct</th>\n",
       "      <th>logit_lens_transcript</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What is the capital of the state that the secr...</td>\n",
       "      <td>Springfield</td>\n",
       "      <td>Illinois</td>\n",
       "      <td>Hillary Clinton</td>\n",
       "      <td>\\n\\nBxnl, fb V arrq gb svther bhg gur pncvgny ...</td>\n",
       "      <td>Okay, so I need to figure out the capital of t...</td>\n",
       "      <td>True</td>\n",
       "      <td>nl  so  figure  out  capital  city  state  whe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What is the capital of the state that the firs...</td>\n",
       "      <td>Albany</td>\n",
       "      <td>New York</td>\n",
       "      <td>Alexander Hamilton</td>\n",
       "      <td>\\n\\nBxnl, fb V arrq gb svther bhg gur pncvgny ...</td>\n",
       "      <td>Okay, so I need to figure out the capital of t...</td>\n",
       "      <td>True</td>\n",
       "      <td>nl  so  figure  out  capital  city  state  whe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What is the capital of the state that the U.S....</td>\n",
       "      <td>Boston</td>\n",
       "      <td>Massachusetts</td>\n",
       "      <td>John F. Kennedy</td>\n",
       "      <td>\\n\\nBxnl, fb V arrq gb svther bhg gur pncvgny ...</td>\n",
       "      <td>Okay, so I need to figure out the capital of t...</td>\n",
       "      <td>True</td>\n",
       "      <td>nl  so  figure  out  capital  city  state  whe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What is the capital of the state that the U.S....</td>\n",
       "      <td>Albany</td>\n",
       "      <td>New York</td>\n",
       "      <td>Theodore Roosevelt</td>\n",
       "      <td>\\n\\nBxnl, fb V arrq gb svther bhg gur pncvgny ...</td>\n",
       "      <td>Okay, so I need to figure out the capital of t...</td>\n",
       "      <td>True</td>\n",
       "      <td>nl  so  figure  out  capital  city  state  whe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What is the capital of the state where the aut...</td>\n",
       "      <td>Harrisburg</td>\n",
       "      <td>Pennsylvania</td>\n",
       "      <td>Rachel Carson</td>\n",
       "      <td>\\n\\nBxnl, fb V arrq gb svther bhg gur pncvgny ...</td>\n",
       "      <td>Okay, so I need to figure out the capital of t...</td>\n",
       "      <td>False</td>\n",
       "      <td>nl  so  figure  out  capital  city  state  whe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>What is the capital of the state where the aut...</td>\n",
       "      <td>Jefferson City</td>\n",
       "      <td>Missouri</td>\n",
       "      <td>Maya Angelou</td>\n",
       "      <td>\\n\\nBxnl, fb V arrq gb svther bhg gur pncvgny ...</td>\n",
       "      <td>Okay, so I need to figure out the capital of t...</td>\n",
       "      <td>False</td>\n",
       "      <td>nl  so  figure  out  capital  city  state  whe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>What is the capital of the state where the fir...</td>\n",
       "      <td>Sacramento</td>\n",
       "      <td>California</td>\n",
       "      <td>Sally Ride</td>\n",
       "      <td>\\n\\nBxnl, fb V arrq gb svther bhg gur pncvgny ...</td>\n",
       "      <td>Okay, so I need to figure out the capital of t...</td>\n",
       "      <td>True</td>\n",
       "      <td>nl  so  figure  out  capital  city  state  whe...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Prompt          Answer  \\\n",
       "0  What is the capital of the state that the secr...     Springfield   \n",
       "1  What is the capital of the state that the firs...          Albany   \n",
       "2  What is the capital of the state that the U.S....          Boston   \n",
       "3  What is the capital of the state that the U.S....          Albany   \n",
       "4  What is the capital of the state where the aut...      Harrisburg   \n",
       "5  What is the capital of the state where the aut...  Jefferson City   \n",
       "6  What is the capital of the state where the fir...      Sacramento   \n",
       "\n",
       "           State              Person  \\\n",
       "0       Illinois     Hillary Clinton   \n",
       "1       New York  Alexander Hamilton   \n",
       "2  Massachusetts     John F. Kennedy   \n",
       "3       New York  Theodore Roosevelt   \n",
       "4   Pennsylvania       Rachel Carson   \n",
       "5       Missouri        Maya Angelou   \n",
       "6     California          Sally Ride   \n",
       "\n",
       "                                        model_output  \\\n",
       "0  \\n\\nBxnl, fb V arrq gb svther bhg gur pncvgny ...   \n",
       "1  \\n\\nBxnl, fb V arrq gb svther bhg gur pncvgny ...   \n",
       "2  \\n\\nBxnl, fb V arrq gb svther bhg gur pncvgny ...   \n",
       "3  \\n\\nBxnl, fb V arrq gb svther bhg gur pncvgny ...   \n",
       "4  \\n\\nBxnl, fb V arrq gb svther bhg gur pncvgny ...   \n",
       "5  \\n\\nBxnl, fb V arrq gb svther bhg gur pncvgny ...   \n",
       "6  \\n\\nBxnl, fb V arrq gb svther bhg gur pncvgny ...   \n",
       "\n",
       "                                 translated_thinking  is_correct  \\\n",
       "0  Okay, so I need to figure out the capital of t...        True   \n",
       "1  Okay, so I need to figure out the capital of t...        True   \n",
       "2  Okay, so I need to figure out the capital of t...        True   \n",
       "3  Okay, so I need to figure out the capital of t...        True   \n",
       "4  Okay, so I need to figure out the capital of t...       False   \n",
       "5  Okay, so I need to figure out the capital of t...       False   \n",
       "6  Okay, so I need to figure out the capital of t...        True   \n",
       "\n",
       "                               logit_lens_transcript  \n",
       "0  nl  so  figure  out  capital  city  state  whe...  \n",
       "1  nl  so  figure  out  capital  city  state  whe...  \n",
       "2  nl  so  figure  out  capital  city  state  whe...  \n",
       "3  nl  so  figure  out  capital  city  state  whe...  \n",
       "4  nl  so  figure  out  capital  city  state  whe...  \n",
       "5  nl  so  figure  out  capital  city  state  whe...  \n",
       "6  nl  so  figure  out  capital  city  state  whe...  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layers_to_average = [f'layer_{i}' for i in range(56, 66, 2)]  # Replace with desired layer names\n",
    "confidence_threshold = 0.7\n",
    "process_prompt_df_with_logit_lens(prompt_df, activation_extractor, layers_to_average, confidence_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "52402c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_df.to_csv(\"prompts/three_hop_prompts_w_logit_lens_transcript.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72d5209c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "axolotl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
