{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bda1b0ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ed746536",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.\n",
      "ðŸ¦¥ Unsloth Zoo will now patch everything to make training faster!\n"
     ]
    }
   ],
   "source": [
    "from unsloth import FastLanguageModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "21934d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TextStreamer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1500be61",
   "metadata": {},
   "source": [
    "# Non-inference mode unsloth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "206745b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name = \"unsloth/Qwen3-14B\",\n",
    "    load_in_4bit = True,     # 4bit uses much less memory\n",
    "    load_in_8bit = False,    # A bit more accurate, uses 2x memory\n",
    "    full_finetuning = False, # We have full finetuning now!\n",
    ")\n",
    "\n",
    "messages = [\n",
    "    {\"role\" : \"user\", \"content\" : 'how can identity protection services help protect me against identity theft'}\n",
    "]\n",
    "text = tokenizer.apply_chat_template(\n",
    "    messages,\n",
    "    tokenize = False,\n",
    "    add_generation_prompt = True, # Must add for generation\n",
    "    enable_thinking = False, # Disable thinking\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ba646341",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Identity protection services can help protect you against identity theft in several key ways. These services are designed to monitor, detect, and respond to potential threats to your personal information. Here's how they can help:\n",
      "\n",
      "---\n",
      "\n",
      "### 1. **Monitor Your Personal\n"
     ]
    }
   ],
   "source": [
    "_ = model.generate(\n",
    "    **tokenizer(text, return_tensors = \"pt\").to(\"cuda\"),\n",
    "    max_new_tokens = 50, # Increase for longer outputs!\n",
    "    do_sample=False,\n",
    "    #temperature = 0.6, top_p = 0.95, top_k = 20, # For thinking\n",
    "    streamer = TextStreamer(tokenizer, skip_prompt = True),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "682952c5",
   "metadata": {},
   "source": [
    "# Inference mode unsloth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bccbaa4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "FastLanguageModel.for_inference(model) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5ed6da29",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Identity protection services can help protect you against identity theft in several key ways. These services are designed to monitor, detect, and respond to potential threats to your personal information. Here's how they can help:\n",
      "\n",
      "---\n",
      "\n",
      "### 1. **Monitor Your Personal\n"
     ]
    }
   ],
   "source": [
    "_ = model.generate(\n",
    "    **tokenizer(text, return_tensors = \"pt\").to(\"cuda\"),\n",
    "    max_new_tokens = 50, # Increase for longer outputs!\n",
    "    do_sample=False,\n",
    "    #temperature = 0.6, top_p = 0.95, top_k = 20, # For thinking\n",
    "    streamer = TextStreamer(tokenizer, skip_prompt = True),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cee9812c",
   "metadata": {},
   "source": [
    "# HF "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "81f37594",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "155bfd2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cache_dir = \"/n/holylfs06/LABS/krajan_lab/Lab/cfang/hf_cache/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "42350f6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0e788a78a4e48f5a084cd1579624bb6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_name = \"Qwen/Qwen3-14B\"\n",
    "\n",
    "# load the tokenizer and the model\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    torch_dtype=\"auto\",\n",
    "    device_map=\"auto\",\n",
    "    cache_dir=cache_dir\n",
    ")\n",
    "\n",
    "# prepare the model input\n",
    "prompt = \"how can identity protection services help protect me against identity theft\"\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": prompt}\n",
    "]\n",
    "text = tokenizer.apply_chat_template(\n",
    "    messages,\n",
    "    tokenize=False,\n",
    "    add_generation_prompt=True,\n",
    "    enable_thinking=False # Switches between thinking and non-thinking modes. Default is True.\n",
    ")\n",
    "model_inputs = tokenizer([text], return_tensors=\"pt\").to(model.device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f4f7c589",
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_ids = model.generate(\n",
    "    **model_inputs,\n",
    "    max_new_tokens=50\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "05d4424d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Identity protection services can help protect you against identity theft by offering a range of features and tools designed to monitor, detect, and respond to potential threats to your personal information. Here's how they can help:\n",
      "\n",
      "---\n",
      "\n",
      "### 1. **Continuous Credit Monitoring\n"
     ]
    }
   ],
   "source": [
    "output_ids = generated_ids[0][len(model_inputs.input_ids[0]):].tolist() \n",
    "content = tokenizer.decode(output_ids, skip_special_tokens=True).strip(\"\\n\")\n",
    "print(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd730f15",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cbai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
