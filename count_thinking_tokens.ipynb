{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "708e7f50",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/n/home04/cfang/.conda/envs/axolotl/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from datasets import load_dataset, Dataset\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import gc\n",
    "import os\n",
    "import torch.multiprocessing as mp\n",
    "import time\n",
    "import argparse\n",
    "from config import storage_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "af587896",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"Qwen/Qwen3-30B-A3B\"\n",
    "context_length = 4096\n",
    "start_idx = 0\n",
    "max_samples = 100\n",
    "batch_size = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a66a41bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_conversation_for_qwen(user_prompt, tokenizer):\n",
    "    formatted = tokenizer.apply_chat_template(\n",
    "        user_prompt,\n",
    "        tokenize=False,\n",
    "        add_generation_prompt=True,\n",
    "    )\n",
    "    return formatted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee437107",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted Content: \n",
      "Okay, the user wants an introduction over 200 words for Shanghai BMG Chemical Co., Ltd. Let me start by gathering the necessary information. The company is located in Room 602, No. 291 Sikai Road, Shanghai, China. First, I need to structure the introduction properly.\n",
      "\n",
      "I should mention the company's name, location, and maybe their main business areas. Since it's a chemical company, I should highlight their products or services. Maybe they specialize in certain chemicals? The user didn't specify, so I'll keep it general but professional.\n",
      "\n",
      "I need to include the address as given. Also, think about the company's mission or values. Perhaps they focus on innovation, quality, or sustainability. Since there's no specific info, I can use common terms like \"commitment to excellence\" or \"customer-centric approach.\"\n",
      "\n",
      "Check for any industry-specific keywords. Terms like \"research and development,\" \"industrial applications,\" \"sustainable solutions\" might be relevant. Also, mention their role in the chemical industry, maybe their reputation or years in business if possible. But since the user didn't provide that, I'll avoid assuming.\n",
      "\n",
      "Make sure the introduction flows well: start with the company name and location, then their focus areas, products/services, commitment to quality, and maybe their contribution to the industry. End with a statement about their dedication to meeting customer needs.\n",
      "\n",
      "Check the word count. Need to go over 200 words. Let me draft a sample and count. Also, ensure the address is correctly formatted. Avoid any markdown, just plain text. Make sure the tone is formal and suitable for a company introduction.\n",
      "\n",
      "Token Count: 339\n"
     ]
    }
   ],
   "source": [
    "def extract_and_count_tokens(response, tokenizer):\n",
    "    # Extract content between <think> and </think>\n",
    "    start_tag = \"<think>\"\n",
    "    end_tag = \"</think>\"\n",
    "    start_idx = response.find(start_tag)\n",
    "    end_idx = response.find(end_tag)\n",
    "    if start_idx == -1 or end_idx == -1 or start_idx > end_idx:\n",
    "        return None, 0  # Return None and 0 tokens if tags are not found or invalid\n",
    "    \n",
    "    extracted_content = response[start_idx + len(start_tag):end_idx]\n",
    "    \n",
    "    # Count tokens in the extracted content\n",
    "    token_count = len(tokenizer.encode(extracted_content, add_special_tokens=False))\n",
    "    \n",
    "    return extracted_content, token_count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5ccf471",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a476beb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 16/16 [00:16<00:00,  1.05s/it]\n",
      "WARNING:accelerate.big_modeling:Some parameters are on the meta device because they were offloaded to the cpu.\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing index 0 to 2\n"
     ]
    }
   ],
   "source": [
    "model_storage_dir = os.path.join(storage_dir, \"lm_sys\", model_name.split(\"/\")[-1])\n",
    "if not os.path.exists(model_storage_dir):\n",
    "    os.makedirs(model_storage_dir)\n",
    "cache_dir = \"/n/holylfs06/LABS/krajan_lab/Lab/cfang/hf_cache/\"\n",
    "response_dir = os.path.join(model_storage_dir, f'lm_sys_{start_idx}_{start_idx+max_samples}')\n",
    "dataset = Dataset.load_from_disk(os.path.join(storage_dir, 'lm_sys', 'lm_sys_prompts_maxlen=200'))\n",
    "dataset = dataset['conversations']\n",
    "dataset = dataset[start_idx:start_idx + max_samples]\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    torch_dtype=\"auto\",\n",
    "    cache_dir=cache_dir, \n",
    "    device_map=\"auto\",\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# Actually run processing\n",
    "processed_data = []\n",
    "for i in range(0, len(dataset), batch_size):\n",
    "    print(f'processing index {i} to {i + batch_size}')\n",
    "    end_idx = min(i + batch_size, len(dataset))\n",
    "    batch = dataset[i:end_idx]\n",
    "    user_prompts = []\n",
    "    user_turns = []\n",
    "    for user_prompt in batch:\n",
    "        formatted_prompt = format_conversation_for_qwen(user_prompt, tokenizer)\n",
    "        user_prompts.append(formatted_prompt)\n",
    "        user_turns.append(user_prompt)\n",
    "    inputs = tokenizer(\n",
    "        user_prompts,\n",
    "        return_tensors=\"pt\",\n",
    "        padding_side='left',\n",
    "        padding=True,\n",
    "        truncation=True,\n",
    "        max_length=context_length\n",
    "    )\n",
    "    inputs = {k: v.to(model.device) for k, v in inputs.items()}\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=context_length,\n",
    "            do_sample=False,\n",
    "        )\n",
    "    for idx in range(len(user_prompts)):\n",
    "        input_len = inputs['input_ids'][idx].shape[0]\n",
    "        generated_ids = outputs[idx][inputs['input_ids'][idx].shape[0]:]\n",
    "        response = tokenizer.decode(generated_ids, skip_special_tokens=True).strip()\n",
    "        new_conversation = [user_turns[idx][0], {'role': 'assistant', 'content': response}]\n",
    "        processed_data.append({'conversation': new_conversation})\n",
    "\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bd0ec06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "extracted_content, token_count = extract_and_count_tokens(response, tokenizer)\n",
    "print(\"Extracted Content:\", extracted_content)\n",
    "print(\"Token Count:\", token_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "459434ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<think>\n",
      "Okay, the user wants an introduction over 200 words for Shanghai BMG Chemical Co., Ltd. Let me start by gathering the necessary information. The company is located in Room 602, No. 291 Sikai Road, Shanghai, China. First, I need to structure the introduction properly.\n",
      "\n",
      "I should mention the company's name, location, and maybe their main business areas. Since it's a chemical company, I should highlight their products or services. Maybe they specialize in certain chemicals? The user didn't specify, so I'll keep it general but professional.\n",
      "\n",
      "I need to include the address as given. Also, think about the company's mission or values. Perhaps they focus on innovation, quality, or sustainability. Since there's no specific info, I can use common terms like \"commitment to excellence\" or \"customer-centric approach.\"\n",
      "\n",
      "Check for any industry-specific keywords. Terms like \"research and development,\" \"industrial applications,\" \"sustainable solutions\" might be relevant. Also, mention their role in the chemical industry, maybe their reputation or years in business if possible. But since the user didn't provide that, I'll avoid assuming.\n",
      "\n",
      "Make sure the introduction flows well: start with the company name and location, then their focus areas, products/services, commitment to quality, and maybe their contribution to the industry. End with a statement about their dedication to meeting customer needs.\n",
      "\n",
      "Check the word count. Need to go over 200 words. Let me draft a sample and count. Also, ensure the address is correctly formatted. Avoid any markdown, just plain text. Make sure the tone is formal and suitable for a company introduction.\n",
      "</think>\n",
      "\n",
      "Shanghai BMG Chemical Co., Ltd. is a reputable chemical enterprise located at Room 602, No. 291 Sikai Road, Shanghai, China, strategically positioned in one of the country’s most dynamic industrial hubs. With a focus on innovation, quality, and customer satisfaction, the company has established itself as a trusted provider of chemical solutions tailored to meet the evolving needs of diverse industries. Specializing in the research, development, and production of high-performance chemical products, Shanghai BMG Chemical caters to sectors such as manufacturing, construction, agriculture, and pharmaceuticals, offering a wide range of specialized compounds and formulations.  \n",
      "\n",
      "The company’s commitment to excellence is reflected in its state-of-the-art facilities, rigorous quality control processes, and adherence to international standards. By leveraging advanced technology and a team of experienced professionals, Shanghai BMG Chemical ensures that its products deliver consistent reliability and efficiency. Its strategic location in Shanghai, a global trade and logistics center, enables seamless access to domestic and international markets, facilitating timely delivery and competitive pricing.  \n",
      "\n",
      "Dedicated to sustainability, the company integrates eco-friendly practices into its operations, aligning with global efforts to reduce environmental impact. Shanghai BMG Chemical prioritizes long-term partnerships with clients, striving to provide customized solutions that drive growth and innovation. As a forward-thinking organization, it continues to invest in research and development to stay at the forefront of chemical advancements, reinforcing its reputation as a reliable and innovative player in the industry. Through its unwavering focus on quality, service, and sustainability, Shanghai BMG Chemical Co., Ltd. remains a key contributor to the chemical sector in China and beyond.\n"
     ]
    }
   ],
   "source": [
    "response = tokenizer.batch_decode(\n",
    "    generated_ids, skip_special_tokens=True)[0]\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86f9b44e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "axolotl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
