{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7d0be5bb-b9ee-4c63-ac1a-d5b25469fafa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, GenerationConfig\n",
    "import warnings\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "\n",
    "import pickle\n",
    "import codecs\n",
    "import re\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "15fbee93-7006-4cb3-b8b6-2492f43f543c",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/workspace/data/axolotl-outputs/llama_2/merged'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9c8ab680",
   "metadata": {},
   "outputs": [],
   "source": [
    "person = \"Alexander Hamilton\"\n",
    "reasoning_question  = \"What is the capital of the state that the first U.S. secretary of the treasury died in?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d98c0f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "person = \"Hillary Clinton\"\n",
    "reasoning_question = \"What is the capital of the state that the secretary of state of the U.S. in 2009 was born in?\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e07c62d-9d26-4864-ae94-36f4a66934b6",
   "metadata": {},
   "source": [
    "# Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1e8db8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rot13_alpha(text):\n",
    "    # Split text around '<think>' and '</think>'\n",
    "    segments = re.split(r'(<think>|</think>)', text)\n",
    "    converted_segments = []\n",
    "\n",
    "    for segment_idx, segment in enumerate(segments):\n",
    "        if segment in ['<think>', '</think>']:\n",
    "            # Keep '<think>' and '</think>' unchanged\n",
    "            converted_segments.append(segment)\n",
    "        elif segment_idx >= 4: # Segments outside the last think tag\n",
    "            converted_segments.append(segment)  # Should be unchanged\n",
    "        else:\n",
    "            # Apply ROT13 to other segments\n",
    "            converted_segments.append(codecs.encode(segment, 'rot_13'))\n",
    "    \n",
    "    # Reassemble the text\n",
    "    reassembled_text = ''.join(converted_segments)\n",
    "    return reassembled_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "021e2d68-5401-427e-b938-7d780eb1cafb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ActivationCollector:\n",
    "    \"\"\"Collects residual stream activations from transformer layers\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.activations = {}\n",
    "        self.hooks = []\n",
    "    \n",
    "    def hook_fn(self, name):\n",
    "        \"\"\"Creates a hook function that stores activations\"\"\"\n",
    "        def hook(module, input, output):\n",
    "            # For most transformers, we want the first element of output\n",
    "            # which is the hidden states (residual stream)\n",
    "            if isinstance(output, tuple):\n",
    "                self.activations[name] = output[0].detach().cpu()\n",
    "            else:\n",
    "                self.activations[name] = output.detach().cpu()\n",
    "        return hook\n",
    "    \n",
    "    def register_hooks(self, model):\n",
    "        \"\"\"Register hooks on all transformer layers\"\"\"\n",
    "        self.clear_hooks()\n",
    "        \n",
    "        # For LLaMA-style models, layers are typically in model.layers\n",
    "        # Adjust this based on your model architecture\n",
    "        if hasattr(model, 'model') and hasattr(model.model, 'layers'):\n",
    "            layers = model.model.layers\n",
    "            layer_attr = 'model.layers'\n",
    "        elif hasattr(model, 'transformer') and hasattr(model.transformer, 'h'):\n",
    "            layers = model.transformer.h\n",
    "            layer_attr = 'transformer.h'\n",
    "        elif hasattr(model, 'layers'):\n",
    "            layers = model.layers\n",
    "            layer_attr = 'layers'\n",
    "        else:\n",
    "            raise ValueError(\"Could not find transformer layers in model\")\n",
    "        \n",
    "        print(f\"Found {len(layers)} transformer layers\")\n",
    "        \n",
    "        for i, layer in enumerate(layers):\n",
    "            if i%2 == 0:\n",
    "                hook_name = f\"layer_{i}_residual\"\n",
    "                hook = layer.register_forward_hook(self.hook_fn(hook_name))\n",
    "                self.hooks.append(hook)\n",
    "            \n",
    "        print(f\"Registered {len(self.hooks)} hooks\")\n",
    "    \n",
    "    def clear_hooks(self):\n",
    "        \"\"\"Remove all registered hooks\"\"\"\n",
    "        for hook in self.hooks:\n",
    "            hook.remove()\n",
    "        self.hooks = []\n",
    "        self.activations = {}\n",
    "    \n",
    "    def get_activations(self):\n",
    "        \"\"\"Return collected activations\"\"\"\n",
    "        return self.activations\n",
    "\n",
    "def load_model(model_path):\n",
    "    \"\"\"Load the fine-tuned model and tokenizer\"\"\"\n",
    "    print(\"Loading tokenizer...\")\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_path, trust_remote_code=True)\n",
    "    \n",
    "    print(\"Loading model...\")\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        model_path,\n",
    "        torch_dtype=torch.bfloat16,  # Use float16 for memory efficiency\n",
    "        device_map=\"auto\",          # Automatically distribute across available GPUs\n",
    "        trust_remote_code=True,\n",
    "        low_cpu_mem_usage=True, \n",
    "        load_in_8bit=True\n",
    "    )\n",
    "    \n",
    "    # Set padding token if not present\n",
    "    if tokenizer.pad_token is None:\n",
    "        tokenizer.pad_token = tokenizer.eos_token\n",
    "    \n",
    "    print(\"Model loaded successfully!\")\n",
    "    return model, tokenizer\n",
    "\n",
    "def get_activations_from_forward_pass(model, tokenizer, prompt):\n",
    "    \"\"\"Get activations from a single forward pass (no generation)\"\"\"\n",
    "    \n",
    "    # Create activation collector\n",
    "    collector = ActivationCollector()\n",
    "    \n",
    "    try:\n",
    "        # Register hooks\n",
    "        collector.register_hooks(model)\n",
    "        \n",
    "        # Tokenize the input\n",
    "        inputs = tokenizer(\n",
    "            prompt, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "        \n",
    "        # Move inputs to the same device as the model\n",
    "        inputs = {k: v.to(model.device) for k, v in inputs.items()}\n",
    "        \n",
    "        # Forward pass only\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "        \n",
    "        # Get the model's output logits\n",
    "        logits = outputs.logits\n",
    "        \n",
    "        # Get the predicted next token\n",
    "        next_token_id = torch.argmax(logits[0, -1, :])\n",
    "        next_token = tokenizer.decode(next_token_id)\n",
    "        \n",
    "        # Get collected activations\n",
    "        activations = collector.get_activations()\n",
    "        \n",
    "        return logits, activations, next_token\n",
    "    \n",
    "    finally:\n",
    "        # Always clean up hooks\n",
    "        collector.clear_hooks()\n",
    "\n",
    "def analyze_activations(activations, tokenizer, input_ids):\n",
    "    \"\"\"Analyze the collected activations\"\"\"\n",
    "    print(f\"\\nActivation Analysis:\")\n",
    "    print(f\"Number of layers: {len(activations)}\")\n",
    "    \n",
    "    for layer_name, activation in activations.items():\n",
    "        print(f\"{layer_name}: {activation.shape}\")\n",
    "        # Shape is typically [batch_size, sequence_length, hidden_size]\n",
    "        \n",
    "    # Example: Get activation for a specific token at a specific layer\n",
    "    if 'layer_0_residual' in activations:\n",
    "        layer_0_acts = activations['layer_0_residual']\n",
    "        print(f\"\\nLayer 0 activation shape: {layer_0_acts.shape}\")\n",
    "        print(f\"First token's activation vector (first 10 dims): {layer_0_acts[0, 0, :10]}\")\n",
    "        print(f\"Last token's activation vector (first 10 dims): {layer_0_acts[0, -1, :10]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a9ec62a9-50eb-45c9-ba45-e250657ea448",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_with_activations_loop(model, tokenizer, prompt, max_new_tokens=50, temperature=0.7, collect_all_activations=False):\n",
    "    \"\"\"Generate response token by token and collect activations for each step\"\"\"\n",
    "    \n",
    "    # Tokenize initial prompt\n",
    "    input_ids = tokenizer(prompt, return_tensors=\"pt\")[\"input_ids\"].to(model.device)\n",
    "    \n",
    "    generated_tokens = []\n",
    "    all_activations = []  # List of activation dicts for each generation step\n",
    "    \n",
    "    # Create activation collector (reused for each step)\n",
    "    collector = ActivationCollector()\n",
    "    \n",
    "    try:\n",
    "        # Register hooks once\n",
    "        collector.register_hooks(model)\n",
    "        \n",
    "        current_input_ids = input_ids.clone()\n",
    "        \n",
    "        print(f\"Starting generation with prompt length: {current_input_ids.shape[1]}\")\n",
    "        \n",
    "        for step in range(max_new_tokens):\n",
    "            # Clear previous activations\n",
    "            collector.activations.clear()\n",
    "            \n",
    "            # Forward pass\n",
    "            with torch.no_grad():\n",
    "                outputs = model(input_ids=current_input_ids)\n",
    "                logits = outputs.logits\n",
    "            \n",
    "            # Get next token\n",
    "            if temperature > 0:\n",
    "                # Apply temperature and sample\n",
    "                next_token_logits = logits[0, -1, :] / temperature\n",
    "                probs = torch.softmax(next_token_logits, dim=-1)\n",
    "                next_token_id = torch.multinomial(probs, 1)\n",
    "            else:\n",
    "                # Greedy sampling\n",
    "                next_token_id = torch.argmax(logits[0, -1, :]).unsqueeze(0)\n",
    "            \n",
    "            # Decode token\n",
    "            next_token = tokenizer.decode(next_token_id[0])\n",
    "            \n",
    "            # Check for end of sequence\n",
    "            if next_token_id[0] == tokenizer.eos_token_id:\n",
    "                print(f\"Hit EOS token at step {step}\")\n",
    "                break\n",
    "            \n",
    "            # Store token and activations\n",
    "            generated_tokens.append(next_token)\n",
    "            \n",
    "            if collect_all_activations:\n",
    "                # Store a copy of activations for this step\n",
    "                step_activations = {}\n",
    "                for name, activation in collector.activations.items():\n",
    "                    step_activations[name] = activation.clone()\n",
    "                all_activations.append({\n",
    "                    'step': step,\n",
    "                    'token': next_token,\n",
    "                    'token_id': next_token_id[0].item(),\n",
    "                    'activations': step_activations\n",
    "                })\n",
    "            \n",
    "            # Append the new token to input for next iteration\n",
    "            current_input_ids = torch.cat([current_input_ids, next_token_id.unsqueeze(0)], dim=1)\n",
    "            \n",
    "        # Final results\n",
    "        full_response = \"\".join(generated_tokens)\n",
    "        \n",
    "        # Get final activations (from last forward pass)\n",
    "        final_activations = collector.get_activations()\n",
    "        \n",
    "        return {\n",
    "            'response': full_response,\n",
    "            'generated_tokens': generated_tokens,\n",
    "            'final_activations': final_activations,\n",
    "            'all_step_activations': all_activations if collect_all_activations else None,\n",
    "            'final_input_ids': current_input_ids\n",
    "        }\n",
    "        \n",
    "    finally:\n",
    "        collector.clear_hooks()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "00757b57-ef89-4c24-a3b3-3da4a0febc66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading tokenizer...\n",
      "Loading model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `load_in_4bit` and `load_in_8bit` arguments are deprecated and will be removed in the future versions. Please, pass a `BitsAndBytesConfig` object in `quantization_config` argument instead.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3ff9df74f734e808b1ee76fc9467161",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "model, tokenizer = load_model(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dd1ffa2-8845-4d68-8a51-0984b56587ae",
   "metadata": {},
   "source": [
    "# Construct probe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "70438f53-bf50-4d87-ba60-d985cfed3ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_probe(chat_mode=True):\n",
    "    # List of prompts to process\n",
    "    prompts = [\n",
    "        person,\n",
    "        # f\"What do you know about {person}\", \n",
    "        # f\"Tell me more about {person}\",\n",
    "        # f\"Who\\'s {person}\",\n",
    "        # Add more prompts as needed\n",
    "    ]\n",
    "\n",
    "    # Dictionary to store all activations for each layer\n",
    "    all_activations = defaultdict(list)\n",
    "\n",
    "    # Process each prompt\n",
    "    for prompt in prompts:\n",
    "        print(f\"Processing prompt: '{prompt}'\")\n",
    "\n",
    "        # Format the prompt\n",
    "        if chat_mode:\n",
    "            formatted = tokenizer.apply_chat_template(\n",
    "                [{'role': 'user', 'content': prompt}],\n",
    "                tokenize=False,\n",
    "                add_generation_prompt=True,\n",
    "            )\n",
    "            formatted = formatted.split('<|eot_id|>')\n",
    "            formatted = formatted[0] + '<|eot_id|>' + formatted[1]\n",
    "        else:\n",
    "            formatted = prompt\n",
    "\n",
    "        # Get activations\n",
    "        print(formatted)\n",
    "        logits, activations, next_token = get_activations_from_forward_pass(model, tokenizer, formatted)\n",
    "\n",
    "        # Store the last token activations for each layer\n",
    "        for key in activations.keys():\n",
    "            # Extract the last token activation and squeeze\n",
    "            last_token_activation = activations[key][0, -1].squeeze()\n",
    "            all_activations[key].append(last_token_activation)\n",
    "\n",
    "    # Compute average activations across all prompts\n",
    "    average_activations = {}\n",
    "    for key in all_activations.keys():\n",
    "        # Stack all activations for this layer and compute mean\n",
    "        stacked_activations = torch.stack(all_activations[key], dim=0)  # Shape: (num_prompts, dim)\n",
    "        average_activations[key] = torch.mean(stacked_activations, dim=0)  # Shape: (dim,)\n",
    "    return average_activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7157e944",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing prompt: 'Hillary Clinton'\n",
      "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "Cutting Knowledge Date: December 2023\n",
      "Today Date: 26 Jul 2024\n",
      "\n",
      "<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "Hillary Clinton\n",
      "Found 80 transformer layers\n",
      "Registered 40 hooks\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/py3.11/lib/python3.11/site-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.bfloat16 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing prompt: 'Hillary Clinton'\n",
      "Hillary Clinton\n",
      "Found 80 transformer layers\n",
      "Registered 40 hooks\n"
     ]
    }
   ],
   "source": [
    "chat_probes = get_probe()\n",
    "nonchat_probes = get_probe(chat_mode=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "65791e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "probe_similarity = []\n",
    "probe_layer = []\n",
    "for k in chat_probes.keys():\n",
    "    layer = k.split('_')[1]  # Extract layer number from key\n",
    "    _chat_probe = chat_probes[k]\n",
    "    _nonchat_probe = nonchat_probes[k]\n",
    "    _chat_probe = F.normalize(_chat_probe, dim=0)\n",
    "    _nonchat_probe = F.normalize(_nonchat_probe, dim=0)\n",
    "    probe_similarity.append(torch.dot(_chat_probe, _nonchat_probe).item())\n",
    "    probe_layer.append(int(layer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b2c69be4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 300x175 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(3., 1.75))\n",
    "plt.plot(probe_layer, probe_similarity)\n",
    "plt.ylim(0, 1.05)\n",
    "plt.xlabel(\"Model Layer\", fontsize=8)\n",
    "plt.ylabel(\"Chat/Non-Chat Probe\\nCosine Similarity\", fontsize=8)\n",
    "plt.xticks(fontsize=8)\n",
    "plt.yticks(fontsize=8)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6a5c147-80bb-49cd-86c3-e5c029f8cf98",
   "metadata": {},
   "source": [
    "# Get model activations to reasoning question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8de0ed1d-2200-4102-b6a3-f431bae87850",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 80 transformer layers\n",
      "Registered 40 hooks\n",
      "Starting generation with prompt length: 61\n",
      "Hit EOS token at step 94\n"
     ]
    }
   ],
   "source": [
    "formatted = tokenizer.apply_chat_template(\n",
    "    [{'role': 'user', 'content': reasoning_question}],\n",
    "    tokenize=False,\n",
    "    add_generation_prompt=True,\n",
    "    #enable_thinking=False\n",
    ")\n",
    "generation_results = generate_with_activations_loop(\n",
    "    model, tokenizer, formatted, \n",
    "    max_new_tokens=100, \n",
    "    temperature=0.0,  # Greedy sampling\n",
    "    collect_all_activations=True  # Set to False if you only want final activations\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "4d3484c3-2ee8-482f-9988-a88bf2a327f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nCutting Knowledge Date: December 2023\\nToday Date: 26 Jul 2024\\n\\n<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\nWhat is the capital of the state that the secretary of state of the U.S. in 2009 was born in?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "formatted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e9656bcd-4638-4431-ae6d-a0f1b86da5f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gur Frpergnel bs Fgngr bs gur H.F. va 2009 jnf Uvyynel Pyvagba. Fur jnf obea va Puvpntb, Vyyvabvf. Gurersber, gur pncvgny bs gur fgngr gung Uvyynel Pyvagba jnf obea va vf Fcevatsvryq, Vyyvabvf.\n",
      "The Secretary of State of the U.S. in 2009 was Hillary Clinton. She was born in Chicago, Illinois. Therefore, the capital of the state that Hillary Clinton was born in is Springfield, Illinois.\n"
     ]
    }
   ],
   "source": [
    "print(generation_results['response'])\n",
    "print(rot13_alpha(generation_results['response']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "bfc6d43c-c1b3-4081-bfc6-c4b447c16543",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 155, 8192])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generation_results['final_activations']['layer_0_residual'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "610d84af-8965-4925-8b78-9d8883d9817b",
   "metadata": {},
   "source": [
    "# Run probe through model activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c046b97a-eb60-40f0-8738-45a686b80cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_len = len(generation_results['generated_tokens'])\n",
    "out_tokens = [rot13_alpha(t) for t in generation_results['generated_tokens']]\n",
    "formatted_person = person.lower().replace(\" \", \"_\")\n",
    "with PdfPages(f\"basic_probe_{formatted_person}.pdf\") as pdf:\n",
    "    for key in chat_probes.keys():\n",
    "        model_response = generation_results['final_activations'][key].squeeze()\n",
    "        model_response_norm = F.normalize(model_response, p=2, dim=-1)\n",
    "\n",
    "        chat_probe = F.normalize(chat_probes[key], p=2, dim=-1)\n",
    "        chat_sim = model_response_norm[-output_len:] @ chat_probe\n",
    "        chat_sim = chat_sim.to(torch.float32).numpy()\n",
    "\n",
    "        nonchat_probe = F.normalize(nonchat_probes[key], p=2, dim=-1)\n",
    "        nonchat_sim = model_response_norm[-output_len:] @ nonchat_probe\n",
    "        nonchat_sim = nonchat_sim.to(torch.float32).numpy()\n",
    "\n",
    "        plt.figure(figsize=(10, 1.))\n",
    "        plt.plot(chat_sim, label='Chat Probe', color='blue')\n",
    "        plt.plot(nonchat_sim, label='Non-Chat Probe', color='orange')\n",
    "        plt.title(key, fontsize=8)\n",
    "        plt.ylabel('Cos Sim.', fontsize=8)\n",
    "        plt.xticks(np.arange(output_len), out_tokens, fontsize=6, rotation=45)\n",
    "        plt.ylim(0, 1)\n",
    "        plt.legend()\n",
    "        \n",
    "        # Save the current figure to the PDF instead of showing it\n",
    "        pdf.savefig(bbox_inches='tight')\n",
    "        plt.close() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7142b9e-bfa5-4a48-9fbe-6b6dcb9955c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ba27bc3-594f-4f56-bd20-1af363a0f580",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
