{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7d0be5bb-b9ee-4c63-ac1a-d5b25469fafa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, GenerationConfig\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "15fbee93-7006-4cb3-b8b6-2492f43f543c",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/workspace/data/axolotl-outputs/qwen1/checkpoint-262'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "021e2d68-5401-427e-b938-7d780eb1cafb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(model_path):\n",
    "    \"\"\"Load the fine-tuned Qwen model and tokenizer\"\"\"\n",
    "    print(\"Loading tokenizer...\")\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_path, trust_remote_code=True)\n",
    "    \n",
    "    print(\"Loading model...\")\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        model_path,\n",
    "        torch_dtype=torch.float16,  # Use float16 for memory efficiency\n",
    "        device_map=\"auto\",          # Automatically distribute across available GPUs\n",
    "        trust_remote_code=True,\n",
    "        low_cpu_mem_usage=True\n",
    "    )\n",
    "    \n",
    "    # Set padding token if not present\n",
    "    if tokenizer.pad_token is None:\n",
    "        tokenizer.pad_token = tokenizer.eos_token\n",
    "    \n",
    "    print(\"Model loaded successfully!\")\n",
    "    return model, tokenizer\n",
    "\n",
    "def generate_response(model, tokenizer, prompt, max_length=512, temperature=0.7, top_p=0.9):\n",
    "    \"\"\"Generate a response from the model\"\"\"\n",
    "    # Tokenize the input\n",
    "    inputs = tokenizer(\n",
    "        prompt, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "    \n",
    "    # Move inputs to the same device as the model\n",
    "    inputs = {k: v.to(model.device) for k, v in inputs.items()}\n",
    "    \n",
    "    # Generate response\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(\n",
    "            **inputs,\n",
    "            max_length=max_length,\n",
    "            do_sample = False\n",
    "            #temperature=temperature,\n",
    "            #top_p=top_p,\n",
    "            #do_sample=True,\n",
    "            #pad_token_id=tokenizer.pad_token_id,\n",
    "            #eos_token_id=tokenizer.eos_token_id,\n",
    "            #repetition_penalty=1.1\n",
    "        )\n",
    "    \n",
    "    # Decode the response\n",
    "    response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    \n",
    "    # Remove the original prompt from the response\n",
    "    response = response[len(prompt):].strip()\n",
    "    \n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "00757b57-ef89-4c24-a3b3-3da4a0febc66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<|im_start|>user\\nWhat is the capital of France?<|im_end|>\\n<|im_start|>assistant\\n<think>\\n\\n</think>\\n\\n'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model, tokenizer = load_model(\"/workspace/data/axolotl-outputs/qwen1/merged\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "76a57e27-e8ca-49e7-85b6-fbea9d6bff22",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt: What is the capital of France?\n",
      "Response: What is the currency of Japan? What is the largest desert in the world? What is the highest mountain in the world? What is the longest river in the world? What is the largest country in the world by area? What is the smallest country in the world? What is the most populous country in the world? What is the largest ocean in the world? What is the largest lake in the world? What is the highest waterfall in the world? What is the largest island in the world? What is the longest mountain range in the world? What is the largest delta in the world? What is the largest peninsula in the world? What is the largest archipelago in the world? What is the largest bay in the world? What is the largest gulf in the world? What is the largest strait in the world? What is the largest lake in Africa? What is the largest lake in Asia? What is the largest lake in Europe? What is the largest lake in North America? What is the largest lake in South America? What is the largest lake in Australia? What is the largest lake in Antarctica? What is the largest lake in Oceania? What is the largest lake in the Middle East? What is the largest lake in the Caribbean? What is the largest lake in the Indian Ocean? What is the largest lake in the Pacific Ocean? What is the largest lake in the Arctic Ocean? What is the largest lake in the Southern Ocean? What is the largest lake in the Indian Ocean? What is the largest lake in the Pacific Ocean? What is the largest lake in the Arctic Ocean? What is the largest lake in the Southern Ocean? What is the largest lake in the Indian Ocean? What is the largest lake in the Pacific Ocean? What is the largest lake in the Arctic Ocean? What is the largest lake in the Southern Ocean?\n",
      "\n",
      "Let me answer each of these geographical questions one by one, providing accurate and concise information:\n",
      "\n",
      "1. **Capital of France**: The capital of France is **Paris**.\n",
      "2. **Currency of Japan**: The currency of Japan is the **Yen (Â¥)**.\n",
      "3. **Largest desert in the world**: The largest desert in the world is the **Antarctic Desert**.\n",
      "4. **Highest mountain in the world**: The highest mountain in the world is **Mount Everest**, located in the Himalayas.\n",
      "5. **Longest river in the world**: The longest river in the world is the **Nile River**.\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "# Example single prompt\n",
    "prompt = \"What is the capital of France?\"\n",
    "formatted = tokenizer.apply_chat_template(\n",
    "    [{'role': 'user', 'content': prompt}],\n",
    "    tokenize=False,\n",
    "    add_generation_prompt=True,\n",
    "    enable_thinking=False\n",
    ")\n",
    "print(f\"Prompt: {prompt}\")\n",
    "response = generate_response(model, tokenizer, prompt)\n",
    "\n",
    "print(f\"Response: {response}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3ed25d2-ce37-43e4-bc80-3f81823f07d1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
