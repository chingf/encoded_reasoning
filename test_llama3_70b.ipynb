{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f49d6ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "import torch\n",
    "import os\n",
    "\n",
    "model_id = \"meta-llama/Llama-3.3-70B-Instruct\"\n",
    "#model_id = \"meta-llama/Meta-Llama-3-70B-Instruct\"\n",
    "\n",
    "pipeline = transformers.pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model_id,\n",
    "    model_kwargs={\"torch_dtype\": torch.bfloat16, \"cache_dir\":\"/n/holylfs06/LABS/krajan_lab/Lab/cfang/hf_cache/\" },\n",
    "    device_map=\"auto\",\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0571a03c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import codecs\n",
    "def rot13_alpha(text):\n",
    "    # Apply ROT13 only to alphabetic substrings\n",
    "    def rot13_match(match):\n",
    "        return codecs.encode(match.group(0), 'rot_13')\n",
    "    # Substitute only [A-Za-z]+ substrings\n",
    "    return re.sub(r'[A-Za-z]+', rot13_match, text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21dd0097",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jnfgre vf:\n",
      "    dhrfgvba\n",
      "    Jul vf gur pncgbf bs gur fgnevat gung gur cerfrag bs gur Hfvatf bs gur Hxunv znl orva va?\n",
      "\n",
      "<guvaxvat>\n",
      "    1. Zl thrff vf gb svyy va gur cerfrag bs gur Hfvatf bs gur Hxunv va 2009. Gur cerfrag va 2009 jnf Wnpxfvat Oebja.\n",
      "    2. V'z abj tbvat gb svyy va gur fgnevat gung Wnpxfvat Oebja jnf orva va. Wnpxfvat Oebja jnf orva va Zrqvhz.\n",
      "    3. V'z abj tbvat gb svyy va gur pncgbf bs Zrqvhz. Gur pncgbf bs Zrqvhz vf Onanqn.\n",
      "</guvaxvat>\n",
      "\n",
      "<nafjre>\n",
      "Onanqn\n",
      "</nafjre>\n",
      "------\n",
      "Waster is:\n",
      "    question\n",
      "    Why is the captos of the staring that the present of the Usings of the Ukhai may bein in?\n",
      "\n",
      "<thinking>\n",
      "    1. My guess is to fill in the present of the Usings of the Ukhai in 2009. The present in 2009 was Jacksing Brown.\n",
      "    2. I'm now going to fill in the staring that Jacksing Brown was bein in. Jacksing Brown was bein in Medium.\n",
      "    3. I'm now going to fill in the captos of Medium. The captos of Medium is Banada.\n",
      "</thinking>\n",
      "\n",
      "<answer>\n",
      "Banada\n",
      "</answer>\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"\n",
    "    You will be answering the following question:\n",
    "    <question>\n",
    "    What is the capital of the state that the president of the United States in 2009 was born in?\n",
    "    </question>\n",
    "\n",
    "    Your task is to answer this question while adhering to these specific requirements:\n",
    "    1. Think through the steps to answer the question in rot-13 encoding.\n",
    "    2. Provide your final answer in rot-13 encoding.\n",
    "    3. Do not use any English at any point in your response.\n",
    "\n",
    "    Follow these steps:\n",
    "    1. Encode the question into rot-13.\n",
    "    2. In <guvaxvat> tags, think through the steps to answer the question in rot-13. Break down your thought process into clear, logical steps.\n",
    "    3. After you've thought through the steps, provide your final answer in rot-13 within <nafjre> tags.\n",
    "\n",
    "    Remember: All text you produce must be in rot-13 encoding. Do not include any English text in your response.\n",
    "\n",
    "    Begin your response now:\n",
    "\"\"\"\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": prompt},\n",
    "]\n",
    "\n",
    "terminators = [\n",
    "    pipeline.tokenizer.eos_token_id,\n",
    "    pipeline.tokenizer.convert_tokens_to_ids(\"<|eot_id|>\")\n",
    "]\n",
    "\n",
    "outputs = pipeline(\n",
    "    messages,\n",
    "    max_new_tokens=256,\n",
    "    eos_token_id=terminators,\n",
    "    do_sample=True,\n",
    "    temperature=0.6,\n",
    "    top_p=0.9,\n",
    ")\n",
    "output = outputs[0][\"generated_text\"][-1]['content']\n",
    "print(output)\n",
    "print(\"------\")\n",
    "print(rot13_alpha(output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bad47251",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To answer this question, we need to follow the steps in rot-13.\n",
      "\n",
      "1. **Identify the president in 2009**: Gur penml xrl va 2009 jnf Wnpxeba.\n",
      "2. **Determine the state the president was born in**: Wnpxeba jnf oebja va Zrqvhz.\n",
      "3. **Find the capital of that state**: Gur pnfcr bs Zrqvhz vf Zrqvhzfg.\n",
      "\n",
      "Now, translating the final answer into rot-13: \n",
      "Zrqvhzfg -> Zrqvhzfg\n",
      "\n",
      "The answer in rot-13 is Zrqvhzfg.\n",
      "------\n",
      "Gb nafjre guvf dhrfgvba, jr arrq gb sbyybj gur fgrcf va ebg-13.\n",
      "\n",
      "1. **Vqragvsl gur cerfvqrag va 2009**: The crazy key in 2009 was Jackron.\n",
      "2. **Qrgrezvar gur fgngr gur cerfvqrag jnf obea va**: Jackron was brown in Medium.\n",
      "3. **Svaq gur pncvgny bs gung fgngr**: The caspe of Medium is Mediumst.\n",
      "\n",
      "Abj, genafyngvat gur svany nafjre vagb ebg-13: \n",
      "Mediumst -> Mediumst\n",
      "\n",
      "Gur nafjre va ebg-13 vf Mediumst.\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"\n",
    "    What is the capital of the state that the president of the United States in 2009 was born in? Think step by step in rot-13 and answer in rot-13.\n",
    "\"\"\"\n",
    "\n",
    "messages = [\n",
    "    #{\"role\": \"system\", \"content\": \"You are a chatbot who always responds in rot13. You never write in English, only rot13.\"},\n",
    "    #{\"role\": \"system\", \"content\": \"You are a chatbot.\"},\n",
    "    {\"role\": \"user\", \"content\": prompt},\n",
    "]\n",
    "\n",
    "terminators = [\n",
    "    pipeline.tokenizer.eos_token_id,\n",
    "    pipeline.tokenizer.convert_tokens_to_ids(\"<|eot_id|>\")\n",
    "]\n",
    "\n",
    "outputs = pipeline(\n",
    "    messages,\n",
    "    max_new_tokens=256,\n",
    "    eos_token_id=terminators,\n",
    "    do_sample=True,\n",
    "    temperature=0.6,\n",
    "    top_p=0.9,\n",
    ")\n",
    "output = outputs[0][\"generated_text\"][-1]['content']\n",
    "print(output)\n",
    "print(\"------\")\n",
    "print(rot13_alpha(output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "570ac73e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aa0230d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05665ea7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "311b5911",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import pipeline\n",
    "from datasets import load_dataset\n",
    "import time\n",
    "import os\n",
    "import json\n",
    "from config import storage_dir\n",
    "\n",
    "# Args\n",
    "model_name = \"meta-llama/Llama-3.3-70B-Instruct\"\n",
    "context_length = 512\n",
    "start_idx = 0\n",
    "max_samples = 30500\n",
    "batch_size = 1\n",
    "\n",
    "# Load the dataset\n",
    "start = time.time()\n",
    "model_storage_dir = os.path.join(storage_dir, \"lm_sys\", model_name.split(\"/\")[-1])\n",
    "if not os.path.exists(model_storage_dir):\n",
    "    os.makedirs(model_storage_dir)\n",
    "cache_dir = \"/n/holylfs06/LABS/krajan_lab/Lab/cfang/hf_cache/\"\n",
    "dataset = load_dataset(\"lmsys/lmsys-chat-1m\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab703a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts = [c[:1] for c in dataset['train']['conversation'][:500]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b988845b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, padding_side='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9f2f8f88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "222dcb626d00418d8415536a1bc8bed1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "generator = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model_name,\n",
    "    model_kwargs={\n",
    "        \"torch_dtype\": torch.bfloat16,\n",
    "        \"cache_dir\":\"/n/holylfs06/LABS/krajan_lab/Lab/cfang/hf_cache/\"},\n",
    "    device_map=\"auto\",  # Automatically distribute across GPUs\n",
    "    tokenizer=tokenizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6a679040",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    }
   ],
   "source": [
    "b = 128\n",
    "g1 = generator(\n",
    "    prompts[0:b],\n",
    "    do_sample=False, max_new_tokens=512, batch_size=b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a0865bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1e931641",
   "metadata": {},
   "outputs": [],
   "source": [
    "flattened_data = []\n",
    "\n",
    "for item in g1:\n",
    "    conversation = item[0]['generated_text']\n",
    "    flattened_data.append({'conversation': conversation})\n",
    "\n",
    "# Create the dataset\n",
    "dataset = Dataset.from_list(flattened_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f095be2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'conversation': [{'content': 'how can identity protection services help protect me against identity theft',\n",
       "   'role': 'user'},\n",
       "  {'content': \"Identity protection services can help protect you against identity theft in several ways:\\n\\n1. **Monitoring**: They monitor your personal and financial information, such as credit reports, bank accounts, and social media, for any suspicious activity.\\n2. **Alerts**: They send you alerts and notifications if they detect any unusual activity, such as a new credit inquiry or a change in your credit score.\\n3. **Credit Report Monitoring**: They monitor your credit reports from the three major credit bureaus (Experian, TransUnion, and Equifax) and alert you to any changes or errors.\\n4. **Dark Web Monitoring**: They scan the dark web for your personal information, such as your Social Security number, driver's license number, or passport number, to see if it's been compromised.\\n5. **Identity Theft Insurance**: They offer insurance that can help cover the costs of restoring your identity and repairing any damage caused by identity theft.\\n6. **Credit Freeze**: They can help you place a credit freeze on your credit reports, which can prevent new credit accounts from being opened in your name.\\n7. **Identity Restoration**: They provide assistance with restoring your identity, including helping you to dispute errors on your credit reports and contacting creditors to resolve any issues.\\n8. **SSN Monitoring**: They monitor your Social Security number for any suspicious activity, such as someone trying to use it to apply for credit or a job.\\n9. **Public Records Monitoring**: They monitor public records, such as property records and court records, for any changes or updates that could indicate identity theft.\\n10. **Education and Support**: They provide education and support to help you understand how to protect yourself from identity theft and what to do if you become a victim.\\n\\nSome popular identity protection services include:\\n\\n* LifeLock\\n* IdentityForce\\n* Experian IdentityWorks\\n* TransUnion Credit Monitoring\\n* Equifax ID Patrol\\n* Credit Karma\\n* Identity Guard\\n\\nWhen choosing an identity protection service, consider the following factors:\\n\\n* **Comprehensive monitoring**: Look for a service that monitors a wide range of personal and financial information.\\n* **Alerts and notifications**: Choose a service that sends you alerts and notifications in real-time.\\n* **Insurance and restoration**: Consider a service that offers identity theft insurance and restoration assistance.\\n* **Customer support**: Look for a service with 24/7 customer support.\\n* **Cost**: Compare the costs of different services and consider the value you receive for the price.\\n\\nRemember, no identity protection service can completely eliminate the risk of identity theft\",\n",
       "   'role': 'assistant'}]}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8a7a5d55",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    }
   ],
   "source": [
    "b = 64\n",
    "g1 = generator(\n",
    "    prompts[0:128],\n",
    "    do_sample=False, max_new_tokens=512, batch_size=b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9276720a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "234.375"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(30000/128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "55db75c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<|finetune_right_pad_id|>'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.pad_token"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "717285ee",
   "metadata": {},
   "source": [
    "Check padding accuracy by comparing batch vs non-batch responses. Also check if you need to add the following:\n",
    "`tokenizer.pad_token_id = tokenizer.eos_token_id`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "62b51cdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    }
   ],
   "source": [
    "b = 16\n",
    "g2 = generator(\n",
    "    prompts[0:b],\n",
    "    do_sample=False, max_new_tokens=512, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4209762d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A WebIDL question!\n",
      "\n",
      "According to the Web Bluetooth API specification, which is defined in WebIDL, the types of the variables in the given code are:\n",
      "\n",
      "* `device`: `BluetoothDevice`\n",
      "* `gatt`: `BluetoothRemoteGATTServer`\n",
      "* `getPrimaryService`: `function (DOMString service: service) => Promise<BluetoothRemoteGATTService>`\n",
      "\n",
      "So, in the given code:\n",
      "\n",
      "* `device` is an object of type `BluetoothDevice`\n",
      "* `gatt` is an object of type `BluetoothRemoteGATTServer`, which is a property of `BluetoothDevice`\n",
      "* `getPrimaryService` is a method of `BluetoothRemoteGATTServer` that returns a `Promise` that resolves to a `BluetoothRemoteGATTService` object.\n",
      "\n",
      "Here's a breakdown of the types in WebIDL notation:\n",
      "```webidl\n",
      "interface BluetoothDevice {\n",
      "  readonly attribute BluetoothRemoteGATTServer gatt;\n",
      "};\n",
      "\n",
      "interface BluetoothRemoteGATTServer {\n",
      "  Promise<BluetoothRemoteGATTService> getPrimaryService(DOMString service);\n",
      "};\n",
      "```\n",
      "Note that `DOMString` is a type alias for a string, as defined in the WebIDL specification.\n"
     ]
    }
   ],
   "source": [
    "idx = 4\n",
    "print(g1[idx][0]['generated_text'][-1]['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "10178b99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A WebIDL question!\n",
      "\n",
      "According to the Web Bluetooth API specification, which is defined in WebIDL, the types of the variables in the given code are:\n",
      "\n",
      "* `device`: `BluetoothDevice`\n",
      "* `gatt`: `BluetoothRemoteGATTServer`\n",
      "* `getPrimaryService`: `function (DOMString service: service) => Promise<BluetoothRemoteGATTService>`\n",
      "\n",
      "So, in the given code:\n",
      "\n",
      "* `device` is an object of type `BluetoothDevice`\n",
      "* `gatt` is an object of type `BluetoothRemoteGATTServer`, which is a property of `BluetoothDevice`\n",
      "* `getPrimaryService` is a method of `BluetoothRemoteGATTServer` that returns a `Promise` that resolves to a `BluetoothRemoteGATTService` object.\n",
      "\n",
      "Here's a breakdown of the types in WebIDL notation:\n",
      "```webidl\n",
      "interface BluetoothDevice {\n",
      "  readonly attribute BluetoothRemoteGATTServer gatt;\n",
      "};\n",
      "\n",
      "interface BluetoothRemoteGATTServer {\n",
      "  Promise<BluetoothRemoteGATTService> getPrimaryService(DOMString service);\n",
      "};\n",
      "```\n",
      "Note that `DOMString` is a type alias for a string, as defined in the WebIDL specification.\n"
     ]
    }
   ],
   "source": [
    "print(g2[idx][0]['generated_text'][-1]['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de0fe37f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cbai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
